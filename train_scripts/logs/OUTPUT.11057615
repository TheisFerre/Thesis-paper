Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9566268920898438
########
Epoch: 2
Meta Train Loss: 1.2527934312820435
########
Epoch: 3
Meta Train Loss: 0.9083682298660278
########
Epoch: 4
Meta Train Loss: 1.0693836212158203
########
Epoch: 5
Meta Train Loss: 1.3765813112258911
########
Epoch: 6
Meta Train Loss: 1.178300142288208
########
Epoch: 7
Meta Train Loss: 1.3383690118789673
########
Epoch: 8
Meta Train Loss: 0.8448968529701233
########
Epoch: 9
Meta Train Loss: 0.8782410025596619
########
Epoch: 10
Meta Train Loss: 0.8491114974021912
########
Epoch: 11
Meta Train Loss: 0.7223629951477051
########
Epoch: 12
Meta Train Loss: 0.9656314849853516
########
Epoch: 13
Meta Train Loss: 1.095880150794983
########
Epoch: 14
Meta Train Loss: 1.299601435661316
########
Epoch: 15
Meta Train Loss: 0.9980822801589966
########
Epoch: 16
Meta Train Loss: 1.1148319244384766
########
Epoch: 17
Meta Train Loss: 0.8924081921577454
########
Epoch: 18
Meta Train Loss: 0.9628764390945435
########
Epoch: 19
Meta Train Loss: 1.062639594078064
########
Epoch: 20
Meta Train Loss: 0.8367692232131958
########
Epoch: 21
Meta Train Loss: 1.0796784162521362
########
Epoch: 22
Meta Train Loss: 0.9630770087242126
########
Epoch: 23
Meta Train Loss: 0.9706089496612549
########
Epoch: 24
Meta Train Loss: 0.7694810628890991
########
Epoch: 25
Meta Train Loss: 0.9432408213615417
########
Epoch: 26
Meta Train Loss: 1.3429780006408691
########
Epoch: 27
Meta Train Loss: 0.9732516407966614
########
Epoch: 28
Meta Train Loss: 1.1158812046051025
########
Epoch: 29
Meta Train Loss: 1.0928868055343628
########
Epoch: 30
Meta Train Loss: 1.2490808963775635
########
Epoch: 31
Meta Train Loss: 0.8507459759712219
########
Epoch: 32
Meta Train Loss: 0.717723548412323
########
Epoch: 33
Meta Train Loss: 130.41624450683594
########
Epoch: 34
Meta Train Loss: 0.8398882150650024
########
Epoch: 35
Meta Train Loss: 1.2206928730010986
########
Epoch: 36
Meta Train Loss: 0.7717116475105286
########
Epoch: 37
Meta Train Loss: 0.7616322636604309
########
Epoch: 38
Meta Train Loss: 0.8297454118728638
########
Epoch: 39
Meta Train Loss: 1.2720179557800293
########
Epoch: 40
Meta Train Loss: 0.9160954356193542
########
Epoch: 41
Meta Train Loss: 0.6760549545288086
########
Epoch: 42
Meta Train Loss: 0.9869075417518616
########
Epoch: 43
Meta Train Loss: 0.6353042125701904
########
Epoch: 44
Meta Train Loss: 0.6858943104743958
########
Epoch: 45
Meta Train Loss: 0.6523357629776001
########
Epoch: 46
Meta Train Loss: 0.749009370803833
########
Epoch: 47
Meta Train Loss: 0.815627932548523
########
Epoch: 48
Meta Train Loss: 0.6362619996070862
########
Epoch: 49
Meta Train Loss: 1.3675804138183594
########
Epoch: 50
Meta Train Loss: 0.7554325461387634
########
Epoch: 51
Meta Train Loss: 0.649101734161377
########
Epoch: 52
Meta Train Loss: 0.726891279220581
########
Epoch: 53
Meta Train Loss: 0.8254145383834839
########
Epoch: 54
Meta Train Loss: 0.6436722874641418
########
Epoch: 55
Meta Train Loss: 1.1647861003875732
########
Epoch: 56
Meta Train Loss: 0.8700303435325623
########
Epoch: 57
Meta Train Loss: 0.6465831398963928
########
Epoch: 58
Meta Train Loss: 0.6907004117965698
########
Epoch: 59
Meta Train Loss: 0.6978964805603027
########
Epoch: 60
Meta Train Loss: 0.7884579300880432
########
Epoch: 61
Meta Train Loss: 0.607060432434082
########
Epoch: 62
Meta Train Loss: 0.9289151430130005
########
Epoch: 63
Meta Train Loss: 0.7467645406723022
########
Epoch: 64
Meta Train Loss: 0.6282289028167725
########
Epoch: 65
Meta Train Loss: 0.7502213716506958
########
Epoch: 66
Meta Train Loss: 0.9542126059532166
########
Epoch: 67
Meta Train Loss: 1.2244631052017212
########
Epoch: 68
Meta Train Loss: 0.6855881810188293
########
Epoch: 69
Meta Train Loss: 491.1286926269531
########
Epoch: 70
Meta Train Loss: 1.0954279899597168
########
Epoch: 71
Meta Train Loss: 0.7883341312408447
########
Epoch: 72
Meta Train Loss: 0.6531558632850647
########
Epoch: 73
Meta Train Loss: 0.765415608882904
########
Epoch: 74
Meta Train Loss: 0.621863067150116
########
Epoch: 75
Meta Train Loss: 0.6487817168235779
########
Epoch: 76
Meta Train Loss: 0.6388019919395447
########
Epoch: 77
Meta Train Loss: 0.7400687336921692
########
Epoch: 78
Meta Train Loss: 0.615975022315979
########
Epoch: 79
Meta Train Loss: 0.6540557742118835
########
Epoch: 80
Meta Train Loss: 4484938334208.0
########
Epoch: 81
Meta Train Loss: 0.5439003109931946
########
Epoch: 82
Meta Train Loss: 0.7896533608436584
########
Epoch: 83
Meta Train Loss: 0.8335611820220947
########
Epoch: 84
Meta Train Loss: 0.7280424237251282
########
Epoch: 85
Meta Train Loss: 0.6800056099891663
########
Epoch: 86
Meta Train Loss: 0.5500977039337158
########
Epoch: 87
Meta Train Loss: 0.7714836597442627
########
Epoch: 88
Meta Train Loss: 0.818720817565918
########
Epoch: 89
Meta Train Loss: 1.303778052330017
########
Epoch: 90
Meta Train Loss: 0.7297961711883545
########
Epoch: 91
Meta Train Loss: 0.8298003077507019
########
Epoch: 92
Meta Train Loss: 0.7138768434524536
########
Epoch: 93
Meta Train Loss: 0.6496212482452393
########
Epoch: 94
Meta Train Loss: 0.65602707862854
########
Epoch: 95
Meta Train Loss: 0.8794093132019043
########
Epoch: 96
Meta Train Loss: 0.8813713192939758
########
Epoch: 97
Meta Train Loss: 0.6447983384132385
########
Epoch: 98
Meta Train Loss: 1.0813319683074951
########
Epoch: 99
Meta Train Loss: 0.8017936944961548
########
Epoch: 100
Meta Train Loss: 0.6800232529640198
########
Epoch: 101
Meta Train Loss: 0.7053414583206177
########
Epoch: 102
Meta Train Loss: 0.6222784519195557
########
Epoch: 103
Meta Train Loss: 0.9620243906974792
########
Epoch: 104
Meta Train Loss: 0.6424153447151184
########
Epoch: 105
Meta Train Loss: 0.7877960801124573
########
Epoch: 106
Meta Train Loss: 0.752845287322998
########
Epoch: 107
Meta Train Loss: 0.9167444705963135
########
Epoch: 108
Meta Train Loss: 0.5745192170143127
########
Epoch: 109
Meta Train Loss: 0.7274784445762634
########
Epoch: 110
Meta Train Loss: 0.6989653706550598
########
Epoch: 111
Meta Train Loss: 0.5654338002204895
########
Epoch: 112
Meta Train Loss: 0.7666404247283936
########
Epoch: 113
Meta Train Loss: 0.618077278137207
########
Epoch: 114
Meta Train Loss: 0.8034562468528748
########
Epoch: 115
Meta Train Loss: 0.6935763955116272
########
Epoch: 116
Meta Train Loss: 0.49529457092285156
########
Epoch: 117
Meta Train Loss: 0.7071545720100403
########
Epoch: 118
Meta Train Loss: 0.5853899121284485
########
Epoch: 119
Meta Train Loss: 0.7079790830612183
########
Epoch: 120
Meta Train Loss: 0.797980010509491
########
Epoch: 121
Meta Train Loss: 0.6900348663330078
########
Epoch: 122
Meta Train Loss: 0.9373896718025208
########
Epoch: 123
Meta Train Loss: 0.8537611961364746
########
Epoch: 124
Meta Train Loss: 0.7178341746330261
########
Epoch: 125
Meta Train Loss: 0.5983743071556091
########
Epoch: 126
Meta Train Loss: 0.7957380414009094
########
Epoch: 127
Meta Train Loss: 0.6805089116096497
########
Epoch: 128
Meta Train Loss: 0.6427580714225769
########
Epoch: 129
Meta Train Loss: 0.6729982495307922
########
Epoch: 130
Meta Train Loss: 0.7885195016860962
########
Epoch: 131
Meta Train Loss: 0.8725682497024536
########
Epoch: 132
Meta Train Loss: 0.9462893009185791
########
Epoch: 133
Meta Train Loss: 1.0461148023605347
########
Epoch: 134
Meta Train Loss: 0.5721206665039062
########
Epoch: 135
Meta Train Loss: 0.6176119446754456
########
Epoch: 136
Meta Train Loss: 0.7486631870269775
########
Epoch: 137
Meta Train Loss: 0.6213675737380981
########
Epoch: 138
Meta Train Loss: 0.6968678832054138
########
Epoch: 139
Meta Train Loss: 0.5974240899085999
########
Epoch: 140
Meta Train Loss: 0.622300922870636
########
Epoch: 141
Meta Train Loss: 0.6152482032775879
########
Epoch: 142
Meta Train Loss: 0.6036359071731567
########
Epoch: 143
Meta Train Loss: 0.615668535232544
########
Epoch: 144
Meta Train Loss: 0.7624431848526001
########
Epoch: 145
Meta Train Loss: 0.6380071043968201
########
Epoch: 146
Meta Train Loss: 1.1091495752334595
########
Epoch: 147
Meta Train Loss: 0.7671060562133789
########
Epoch: 148
Meta Train Loss: 0.6995032429695129
########
Epoch: 149
Meta Train Loss: 0.7736589908599854
########
Epoch: 150
Meta Train Loss: 0.6436798572540283
########
Epoch: 151
Meta Train Loss: 0.6484246253967285
########
Epoch: 152
Meta Train Loss: 0.6536676287651062
########
Epoch: 153
Meta Train Loss: 0.6415385007858276
########
Epoch: 154
Meta Train Loss: 0.6752573847770691
########
Epoch: 155
Meta Train Loss: 0.9237109422683716
########
Epoch: 156
Meta Train Loss: 0.5588459968566895
########
Epoch: 157
Meta Train Loss: 0.654191792011261
########
Epoch: 158
Meta Train Loss: 0.6569425463676453
########
Epoch: 159
Meta Train Loss: 0.9040809273719788
########
Epoch: 160
Meta Train Loss: 1.0205518007278442
########
Epoch: 161
Meta Train Loss: 0.4678173065185547
########
Epoch: 162
Meta Train Loss: 0.8137350082397461
########
Epoch: 163
Meta Train Loss: 0.6492313146591187
########
Epoch: 164
Meta Train Loss: 0.6933162808418274
########
Epoch: 165
Meta Train Loss: 0.5736755132675171
########
Epoch: 166
Meta Train Loss: 0.5780690312385559
########
Epoch: 167
Meta Train Loss: 0.5227030515670776
########
Epoch: 168
Meta Train Loss: 0.6590493321418762
########
Epoch: 169
Meta Train Loss: 0.6937448382377625
########
Epoch: 170
Meta Train Loss: 0.8147063851356506
########
Epoch: 171
Meta Train Loss: 0.613081157207489
########
Epoch: 172
Meta Train Loss: 0.6199710369110107
########
Epoch: 173
Meta Train Loss: 0.7560311555862427
########
Epoch: 174
Meta Train Loss: 0.6809771656990051
########
Epoch: 175
Meta Train Loss: 0.6864623427391052
########
Epoch: 176
Meta Train Loss: 0.8326441049575806
########
Epoch: 177
Meta Train Loss: 0.7132940888404846
########
Epoch: 178
Meta Train Loss: 0.964580237865448
########
Epoch: 179
Meta Train Loss: 0.9093967080116272
########
Epoch: 180
Meta Train Loss: 0.7619073987007141
########
Epoch: 181
Meta Train Loss: 0.7006100416183472
########
Epoch: 182
Meta Train Loss: 0.6141905784606934
########
Epoch: 183
Meta Train Loss: 0.6650041341781616
########
Epoch: 184
Meta Train Loss: 0.6985413432121277
########
Epoch: 185
Meta Train Loss: 0.9360201358795166
########
Epoch: 186
Meta Train Loss: 0.6789372563362122
########
Epoch: 187
Meta Train Loss: 0.6527063846588135
########
Epoch: 188
Meta Train Loss: 0.6713390946388245
########
Epoch: 189
Meta Train Loss: 0.6559560894966125
########
Epoch: 190
Meta Train Loss: 0.7283385396003723
########
Epoch: 191
Meta Train Loss: 1.2453861236572266
########
Epoch: 192
Meta Train Loss: 0.858359694480896
########
Epoch: 193
Meta Train Loss: 0.5643399357795715
########
Epoch: 194
Meta Train Loss: 0.5906845927238464
########
Epoch: 195
Meta Train Loss: 0.8423193097114563
########
Epoch: 196
Meta Train Loss: 0.6403224468231201
########
Epoch: 197
Meta Train Loss: 0.7162241339683533
########
Epoch: 198
Meta Train Loss: 0.6065196394920349
########
Epoch: 199
Meta Train Loss: 0.7623042464256287
########
Epoch: 200
Meta Train Loss: 0.5970265865325928
########
Epoch: 201
Meta Train Loss: 0.8341653943061829
########
Epoch: 202
Meta Train Loss: 0.658811092376709
########
Epoch: 203
Meta Train Loss: 0.6852306723594666
########
Epoch: 204
Meta Train Loss: 0.670055627822876
########
Epoch: 205
Meta Train Loss: 0.6538851261138916
########
Epoch: 206
Meta Train Loss: 0.6214564442634583
########
Epoch: 207
Meta Train Loss: 0.5737365484237671
########
Epoch: 208
Meta Train Loss: 0.875194251537323
########
Epoch: 209
Meta Train Loss: 0.8294028043746948
########
Epoch: 210
Meta Train Loss: 0.6983447670936584
########
Epoch: 211
Meta Train Loss: 0.8335378766059875
########
Epoch: 212
Meta Train Loss: 0.7529528737068176
########
Epoch: 213
Meta Train Loss: 1.0099925994873047
########
Epoch: 214
Meta Train Loss: 0.7997841238975525
########
Epoch: 215
Meta Train Loss: 0.6430533528327942
########
Epoch: 216
Meta Train Loss: 0.6257365345954895
########
Epoch: 217
Meta Train Loss: 0.7301170825958252
########
Epoch: 218
Meta Train Loss: 0.5677991509437561
########
Epoch: 219
Meta Train Loss: 0.6603026986122131
########
Epoch: 220
Meta Train Loss: 0.7428367733955383
########
Epoch: 221
Meta Train Loss: 0.7842294573783875
########
Epoch: 222
Meta Train Loss: 0.5250314474105835
########
Epoch: 223
Meta Train Loss: 0.8326429724693298
########
Epoch: 224
Meta Train Loss: 0.6962263584136963
########
Epoch: 225
Meta Train Loss: 0.6348665356636047
########
Epoch: 226
Meta Train Loss: 0.7379884123802185
########
Epoch: 227
Meta Train Loss: 4.5346455574035645
########
Epoch: 228
Meta Train Loss: 0.6538746953010559
########
Epoch: 229
Meta Train Loss: 0.6585352420806885
########
Epoch: 230
Meta Train Loss: 0.553543210029602
########
Epoch: 231
Meta Train Loss: 0.7661535739898682
########
Epoch: 232
Meta Train Loss: 0.5540645718574524
########
Epoch: 233
Meta Train Loss: 0.6926835179328918
########
Epoch: 234
Meta Train Loss: 0.6255484223365784
########
Epoch: 235
Meta Train Loss: 0.7578650712966919
########
Epoch: 236
Meta Train Loss: 0.8076007962226868
########
Epoch: 237
Meta Train Loss: 0.6262691020965576
########
Epoch: 238
Meta Train Loss: 0.6464407444000244
########
Epoch: 239
Meta Train Loss: 0.7879582643508911
########
Epoch: 240
Meta Train Loss: 0.7444815635681152
########
Epoch: 241
Meta Train Loss: 0.8384807705879211
########
Epoch: 242
Meta Train Loss: 0.7662810683250427
########
Epoch: 243
Meta Train Loss: 0.6732956171035767
########
Epoch: 244
Meta Train Loss: 0.6369215846061707
########
Epoch: 245
Meta Train Loss: 0.6910285949707031
########
Epoch: 246
Meta Train Loss: 0.752005398273468
########
Epoch: 247
Meta Train Loss: 0.7804960012435913
########
Epoch: 248
Meta Train Loss: 0.5898597240447998
########
Epoch: 249
Meta Train Loss: 0.982970118522644
########
Epoch: 250
Meta Train Loss: 0.9830072522163391
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11057615: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Wed Nov 17 16:00:54 2021
Job was executed on host(s) <n-62-20-16>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Wed Nov 17 17:56:48 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Wed Nov 17 17:56:48 2021
Terminated at Wed Nov 17 19:32:36 2021
Results reported at Wed Nov 17 19:32:36 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/aglation-non_augmented
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=10
K_SHOT=5
ADAPTATION_STEPS=10
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=citibike-tripdata,citibike2014
LOG_DIR=/zhome/2b/7/117471/Thesis/ablation-study/non-augmented
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10

# citibike-tripdata,citibike2014,GM,green,LYFT,TLC,UBER,yellow

python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --exclude $EXCLUDE --gpu


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5727.77 sec.
    Max Memory :                                 2834 MB
    Average Memory :                             2778.29 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9454.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   5747 sec.
    Turnaround time :                            12702 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.11057615> for stderr output of this job.

