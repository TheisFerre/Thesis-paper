Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9159258008003235
########
Epoch: 2
Meta Train Loss: 1.0935394763946533
########
Epoch: 3
Meta Train Loss: 1.214015245437622
########
Epoch: 4
Meta Train Loss: 0.9782912135124207
########
Epoch: 5
Meta Train Loss: 1.780584692955017
########
Epoch: 6
Meta Train Loss: 0.9564046263694763
########
Epoch: 7
Meta Train Loss: 0.9160216450691223
########
Epoch: 8
Meta Train Loss: 40120901632.0
########
Epoch: 9
Meta Train Loss: 0.9700563549995422
########
Epoch: 10
Meta Train Loss: 0.9206771850585938
########
Epoch: 11
Meta Train Loss: 0.8541449904441833
########
Epoch: 12
Meta Train Loss: 1.2743186950683594
########
Epoch: 13
Meta Train Loss: 1.0948232412338257
########
Epoch: 14
Meta Train Loss: 0.7649256587028503
########
Epoch: 15
Meta Train Loss: 1.0845392942428589
########
Epoch: 16
Meta Train Loss: 1.0926461219787598
########
Epoch: 17
Meta Train Loss: 0.96636962890625
########
Epoch: 18
Meta Train Loss: 1.1638555526733398
########
Epoch: 19
Meta Train Loss: 0.9120025038719177
########
Epoch: 20
Meta Train Loss: 0.9158797264099121
########
Epoch: 21
Meta Train Loss: 1.1336687803268433
########
Epoch: 22
Meta Train Loss: 0.9287684559822083
########
Epoch: 23
Meta Train Loss: 0.9916499257087708
########
Epoch: 24
Meta Train Loss: 1.219515085220337
########
Epoch: 25
Meta Train Loss: 0.7894691228866577
########
Epoch: 26
Meta Train Loss: 0.8009411096572876
########
Epoch: 27
Meta Train Loss: 1.118904948234558
########
Epoch: 28
Meta Train Loss: 1.2447237968444824
########
Epoch: 29
Meta Train Loss: 1.1162556409835815
########
Epoch: 30
Meta Train Loss: 0.9498171210289001
########
Epoch: 31
Meta Train Loss: 0.7950112223625183
########
Epoch: 32
Meta Train Loss: 0.632419764995575
########
Epoch: 33
Meta Train Loss: 1.0369322299957275
########
Epoch: 34
Meta Train Loss: 0.8701547980308533
########
Epoch: 35
Meta Train Loss: 0.7580501437187195
########
Epoch: 36
Meta Train Loss: 0.590948760509491
########
Epoch: 37
Meta Train Loss: 0.6198471188545227
########
Epoch: 38
Meta Train Loss: 0.6717572212219238
########
Epoch: 39
Meta Train Loss: 0.6628278493881226
########
Epoch: 40
Meta Train Loss: 0.6207787394523621
########
Epoch: 41
Meta Train Loss: 0.9452068209648132
########
Epoch: 42
Meta Train Loss: 1.2464901208877563
########
Epoch: 43
Meta Train Loss: 0.8301681876182556
########
Epoch: 44
Meta Train Loss: 0.9796083569526672
########
Epoch: 45
Meta Train Loss: 0.7455332279205322
########
Epoch: 46
Meta Train Loss: 0.4966420829296112
########
Epoch: 47
Meta Train Loss: 0.6254229545593262
########
Epoch: 48
Meta Train Loss: 1.3109089136123657
########
Epoch: 49
Meta Train Loss: 0.7573937773704529
########
Epoch: 50
Meta Train Loss: 1.3345946073532104
########
Epoch: 51
Meta Train Loss: 0.5089038610458374
########
Epoch: 52
Meta Train Loss: 0.683251142501831
########
Epoch: 53
Meta Train Loss: 0.9186834692955017
########
Epoch: 54
Meta Train Loss: 0.6933738589286804
########
Epoch: 55
Meta Train Loss: 0.49193745851516724
########
Epoch: 56
Meta Train Loss: 0.6818692088127136
########
Epoch: 57
Meta Train Loss: 0.5932893753051758
########
Epoch: 58
Meta Train Loss: 0.5407905578613281
########
Epoch: 59
Meta Train Loss: 0.612427294254303
########
Epoch: 60
Meta Train Loss: 0.7462274432182312
########
Epoch: 61
Meta Train Loss: 0.5730218887329102
########
Epoch: 62
Meta Train Loss: 0.7687461972236633
########
Epoch: 63
Meta Train Loss: 1.060765027999878
########
Epoch: 64
Meta Train Loss: 0.4265855848789215
########
Epoch: 65
Meta Train Loss: 0.7218575477600098
########
Epoch: 66
Meta Train Loss: 0.762326180934906
########
Epoch: 67
Meta Train Loss: 0.46104440093040466
########
Epoch: 68
Meta Train Loss: 0.9097802042961121
########
Epoch: 69
Meta Train Loss: 0.8121309280395508
########
Epoch: 70
Meta Train Loss: 0.7321375608444214
########
Epoch: 71
Meta Train Loss: 0.5499137043952942
########
Epoch: 72
Meta Train Loss: 1.1453397274017334
########
Epoch: 73
Meta Train Loss: 0.5407459139823914
########
Epoch: 74
Meta Train Loss: 0.7515079379081726
########
Epoch: 75
Meta Train Loss: 0.7074093222618103
########
Epoch: 76
Meta Train Loss: 0.6479671001434326
########
Epoch: 77
Meta Train Loss: 0.7112335562705994
########
Epoch: 78
Meta Train Loss: 0.6286386251449585
########
Epoch: 79
Meta Train Loss: 1.0950816869735718
########
Epoch: 80
Meta Train Loss: 0.8700114488601685
########
Epoch: 81
Meta Train Loss: 0.5983806848526001
########
Epoch: 82
Meta Train Loss: 0.517440676689148
########
Epoch: 83
Meta Train Loss: 0.6815196871757507
########
Epoch: 84
Meta Train Loss: 0.7341333031654358
########
Epoch: 85
Meta Train Loss: 0.7148498892784119
########
Epoch: 86
Meta Train Loss: 0.5629752278327942
########
Epoch: 87
Meta Train Loss: 0.9537721872329712
########
Epoch: 88
Meta Train Loss: 0.5174247622489929
########
Epoch: 89
Meta Train Loss: 0.6361618041992188
########
Epoch: 90
Meta Train Loss: 0.664345920085907
########
Epoch: 91
Meta Train Loss: 0.6722744107246399
########
Epoch: 92
Meta Train Loss: 0.8250240683555603
########
Epoch: 93
Meta Train Loss: 0.8119921684265137
########
Epoch: 94
Meta Train Loss: 0.5897141695022583
########
Epoch: 95
Meta Train Loss: 0.6438873410224915
########
Epoch: 96
Meta Train Loss: 0.6641547083854675
########
Epoch: 97
Meta Train Loss: 0.6507302522659302
########
Epoch: 98
Meta Train Loss: 0.6251356601715088
########
Epoch: 99
Meta Train Loss: 0.627945601940155
########
Epoch: 100
Meta Train Loss: 0.8780038952827454
########
Epoch: 101
Meta Train Loss: 57586.26953125
########
Epoch: 102
Meta Train Loss: 0.6157397031784058
########
Epoch: 103
Meta Train Loss: 0.865520179271698
########
Epoch: 104
Meta Train Loss: 0.8059162497520447
########
Epoch: 105
Meta Train Loss: 1.1258269548416138
########
Epoch: 106
Meta Train Loss: 0.7543805241584778
########
Epoch: 107
Meta Train Loss: 0.7228230834007263
########
Epoch: 108
Meta Train Loss: 0.7613605260848999
########
Epoch: 109
Meta Train Loss: 0.664442777633667
########
Epoch: 110
Meta Train Loss: 0.5643794536590576
########
Epoch: 111
Meta Train Loss: 0.6328290104866028
########
Epoch: 112
Meta Train Loss: 0.6373363733291626
########
Epoch: 113
Meta Train Loss: 0.8142925500869751
########
Epoch: 114
Meta Train Loss: 0.49200621247291565
########
Epoch: 115
Meta Train Loss: 0.5654460787773132
########
Epoch: 116
Meta Train Loss: 0.5825748443603516
########
Epoch: 117
Meta Train Loss: 0.6802176833152771
########
Epoch: 118
Meta Train Loss: 0.6783156991004944
########
Epoch: 119
Meta Train Loss: 0.7158832550048828
########
Epoch: 120
Meta Train Loss: 0.6478500366210938
########
Epoch: 121
Meta Train Loss: 0.7373403906822205
########
Epoch: 122
Meta Train Loss: 0.85356205701828
########
Epoch: 123
Meta Train Loss: 0.8222635388374329
########
Epoch: 124
Meta Train Loss: 0.8275309801101685
########
Epoch: 125
Meta Train Loss: 0.5489856600761414
########
Epoch: 126
Meta Train Loss: 0.8580276370048523
########
Epoch: 127
Meta Train Loss: 0.4841007888317108
########
Epoch: 128
Meta Train Loss: 0.8530763983726501
########
Epoch: 129
Meta Train Loss: 0.6065599322319031
########
Epoch: 130
Meta Train Loss: 0.4510056674480438
########
Epoch: 131
Meta Train Loss: 0.6450182199478149
########
Epoch: 132
Meta Train Loss: 0.5128545761108398
########
Epoch: 133
Meta Train Loss: 0.6186540126800537
########
Epoch: 134
Meta Train Loss: 0.7002939581871033
########
Epoch: 135
Meta Train Loss: 0.5554176568984985
########
Epoch: 136
Meta Train Loss: 0.7587761878967285
########
Epoch: 137
Meta Train Loss: 0.4872591495513916
########
Epoch: 138
Meta Train Loss: 0.6068239808082581
########
Epoch: 139
Meta Train Loss: 0.6323671340942383
########
Epoch: 140
Meta Train Loss: 0.5863252878189087
########
Epoch: 141
Meta Train Loss: 0.5338486433029175
########
Epoch: 142
Meta Train Loss: 0.7519633769989014
########
Epoch: 143
Meta Train Loss: 0.8886101841926575
########
Epoch: 144
Meta Train Loss: 0.4894707202911377
########
Epoch: 145
Meta Train Loss: 0.7165871858596802
########
Epoch: 146
Meta Train Loss: 0.7694427967071533
########
Epoch: 147
Meta Train Loss: 0.6019368171691895
########
Epoch: 148
Meta Train Loss: 1.094433069229126
########
Epoch: 149
Meta Train Loss: 0.8528262376785278
########
Epoch: 150
Meta Train Loss: 0.7298583388328552
########
Epoch: 151
Meta Train Loss: 0.8383388519287109
########
Epoch: 152
Meta Train Loss: 0.8552059531211853
########
Epoch: 153
Meta Train Loss: 0.65240877866745
########
Epoch: 154
Meta Train Loss: 10012081152.0
########
Epoch: 155
Meta Train Loss: 0.4294315278530121
########
Epoch: 156
Meta Train Loss: 0.5755841135978699
########
Epoch: 157
Meta Train Loss: 0.5437071919441223
########
Epoch: 158
Meta Train Loss: 3937874.5
########
Epoch: 159
Meta Train Loss: 0.5591005682945251
########
Epoch: 160
Meta Train Loss: 0.9401565790176392
########
Epoch: 161
Meta Train Loss: 0.6034417152404785
########
Epoch: 162
Meta Train Loss: 0.8193268179893494
########
Epoch: 163
Meta Train Loss: 0.6366108655929565
########
Epoch: 164
Meta Train Loss: 0.666643500328064
########
Epoch: 165
Meta Train Loss: 0.6013415455818176
########
Epoch: 166
Meta Train Loss: 0.800166130065918
########
Epoch: 167
Meta Train Loss: 0.6799252033233643
########
Epoch: 168
Meta Train Loss: 0.6417818665504456
########
Epoch: 169
Meta Train Loss: 0.4906649589538574
########
Epoch: 170
Meta Train Loss: 0.7163462042808533
########
Epoch: 171
Meta Train Loss: 0.5979964733123779
########
Epoch: 172
Meta Train Loss: 0.7552413940429688
########
Epoch: 173
Meta Train Loss: 0.5790204405784607
########
Epoch: 174
Meta Train Loss: 0.7658481001853943
########
Epoch: 175
Meta Train Loss: 0.5963439345359802
########
Epoch: 176
Meta Train Loss: 0.5809096693992615
########
Epoch: 177
Meta Train Loss: 0.6438745856285095
########
Epoch: 178
Meta Train Loss: 0.5223470330238342
########
Epoch: 179
Meta Train Loss: 0.6058031320571899
########
Epoch: 180
Meta Train Loss: 0.8017749190330505
########
Epoch: 181
Meta Train Loss: 0.6553120017051697
########
Epoch: 182
Meta Train Loss: 0.553200900554657
########
Epoch: 183
Meta Train Loss: 0.5409185290336609
########
Epoch: 184
Meta Train Loss: 0.5736215710639954
########
Epoch: 185
Meta Train Loss: 0.5740575194358826
########
Epoch: 186
Meta Train Loss: 0.525470495223999
########
Epoch: 187
Meta Train Loss: 0.6213820576667786
########
Epoch: 188
Meta Train Loss: 0.6104992032051086
########
Epoch: 189
Meta Train Loss: 0.7322145104408264
########
Epoch: 190
Meta Train Loss: 0.9319009780883789
########
Epoch: 191
Meta Train Loss: 0.672090470790863
########
Epoch: 192
Meta Train Loss: 0.6707949042320251
########
Epoch: 193
Meta Train Loss: 0.8443687558174133
########
Epoch: 194
Meta Train Loss: 0.8023484349250793
########
Epoch: 195
Meta Train Loss: 0.6621490120887756
########
Epoch: 196
Meta Train Loss: 0.637427568435669
########
Epoch: 197
Meta Train Loss: 0.7472268342971802
########
Epoch: 198
Meta Train Loss: 0.665698230266571
########
Epoch: 199
Meta Train Loss: 0.6163085699081421
########
Epoch: 200
Meta Train Loss: 0.896247386932373
########
Epoch: 201
Meta Train Loss: 0.6014878749847412
########
Epoch: 202
Meta Train Loss: 0.5724525451660156
########
Epoch: 203
Meta Train Loss: 0.5448660254478455
########
Epoch: 204
Meta Train Loss: 0.5912002325057983
########
Epoch: 205
Meta Train Loss: 0.6593702435493469
########
Epoch: 206
Meta Train Loss: 0.6738288998603821
########
Epoch: 207
Meta Train Loss: 0.6858360171318054
########
Epoch: 208
Meta Train Loss: 0.6992760300636292
########
Epoch: 209
Meta Train Loss: 0.6519269943237305
########
Epoch: 210
Meta Train Loss: 0.5302634239196777
########
Epoch: 211
Meta Train Loss: 0.6586008667945862
########
Epoch: 212
Meta Train Loss: 0.6808409094810486
########
Epoch: 213
Meta Train Loss: 0.5851411819458008
########
Epoch: 214
Meta Train Loss: 0.5964799523353577
########
Epoch: 215
Meta Train Loss: 0.6864497661590576
########
Epoch: 216
Meta Train Loss: 0.8273431658744812
########
Epoch: 217
Meta Train Loss: 0.48251181840896606
########
Epoch: 218
Meta Train Loss: 0.874910295009613
########
Epoch: 219
Meta Train Loss: 0.8473354578018188
########
Epoch: 220
Meta Train Loss: 0.6638902425765991
########
Epoch: 221
Meta Train Loss: 0.5933939814567566
########
Epoch: 222
Meta Train Loss: 0.5926800966262817
########
Epoch: 223
Meta Train Loss: 0.5555126070976257
########
Epoch: 224
Meta Train Loss: 0.7437843680381775
########
Epoch: 225
Meta Train Loss: 0.7429645657539368
########
Epoch: 226
Meta Train Loss: 0.4314051568508148
########
Epoch: 227
Meta Train Loss: 0.5612792372703552
########
Epoch: 228
Meta Train Loss: 0.5510889291763306
########
Epoch: 229
Meta Train Loss: 0.8695432543754578
########
Epoch: 230
Meta Train Loss: 0.7378218770027161
########
Epoch: 231
Meta Train Loss: 0.6111790537834167
########
Epoch: 232
Meta Train Loss: 0.5568796396255493
########
Epoch: 233
Meta Train Loss: 1.0610636472702026
########
Epoch: 234
Meta Train Loss: 0.6773651242256165
########
Epoch: 235
Meta Train Loss: 0.5462332963943481
########
Epoch: 236
Meta Train Loss: 0.9187579154968262
########
Epoch: 237
Meta Train Loss: 0.6256636381149292
########
Epoch: 238
Meta Train Loss: 0.8629187941551208
########
Epoch: 239
Meta Train Loss: 0.5991896986961365
########
Epoch: 240
Meta Train Loss: 0.6082046031951904
########
Epoch: 241
Meta Train Loss: 0.6581811904907227
########
Epoch: 242
Meta Train Loss: 0.7639815211296082
########
Epoch: 243
Meta Train Loss: 0.49943628907203674
########
Epoch: 244
Meta Train Loss: 0.6490759253501892
########
Epoch: 245
Meta Train Loss: 0.6364133358001709
########
Epoch: 246
Meta Train Loss: 0.7940560579299927
########
Epoch: 247
Meta Train Loss: 0.5498828291893005
########
Epoch: 248
Meta Train Loss: 0.778165340423584
########
Epoch: 249
Meta Train Loss: 0.5906939506530762
########
Epoch: 250
Meta Train Loss: 0.7209897041320801
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11096677: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Thu Nov 18 15:04:08 2021
Job was executed on host(s) <n-62-11-15>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Sun Nov 21 16:06:56 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Sun Nov 21 16:06:56 2021
Terminated at Sun Nov 21 17:58:58 2021
Results reported at Sun Nov 21 17:58:58 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/aglation-non_augmented
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=10
K_SHOT=5
ADAPTATION_STEPS=10
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=citibike-tripdata-GRID,TLC2018-REGION,citibike2014-GRID,GM
LOG_DIR=/zhome/2b/7/117471/Thesis/ablation-study/non-augmented
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10

# citibike-tripdata-GRID,TLC2018-REGION,citibike2014-GRID,GM,yellow-taxi2020-nov-REGION,green,UBER2015-jan-june-GRID,LYFT,TLC2018-GRID,citibike2014-REGION,UBER2015-jan-june-GRID,yellow-taxi2020-nov-GRID

python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --exclude $EXCLUDE --gpu


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   6699.34 sec.
    Max Memory :                                 3318 MB
    Average Memory :                             3266.89 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               8970.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   6721 sec.
    Turnaround time :                            269690 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.11096677> for stderr output of this job.

