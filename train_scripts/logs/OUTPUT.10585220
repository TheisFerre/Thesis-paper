Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 1.3008579015731812
########
Epoch: 2
Meta Train Loss: 1.0707341432571411
########
Epoch: 3
Meta Train Loss: 0.8888745903968811
########
Epoch: 4
Meta Train Loss: 1.0621808767318726
########
Epoch: 5
Meta Train Loss: 12.332536697387695
########
Epoch: 6
Meta Train Loss: 1.206101894378662
########
Epoch: 7
Meta Train Loss: 0.9936183094978333
########
Epoch: 8
Meta Train Loss: 1.0646307468414307
########
Epoch: 9
Meta Train Loss: 1.2147135734558105
########
Epoch: 10
Meta Train Loss: 0.8141994476318359
########
Epoch: 11
Meta Train Loss: 0.933608889579773
########
Epoch: 12
Meta Train Loss: 1.0204166173934937
########
Epoch: 13
Meta Train Loss: 0.8553389310836792
########
Epoch: 14
Meta Train Loss: 0.8683856725692749
########
Epoch: 15
Meta Train Loss: 1.1180570125579834
########
Epoch: 16
Meta Train Loss: 1.047751545906067
########
Epoch: 17
Meta Train Loss: 1.0161597728729248
########
Epoch: 18
Meta Train Loss: 1.0726468563079834
########
Epoch: 19
Meta Train Loss: 0.986364483833313
########
Epoch: 20
Meta Train Loss: 0.9965841770172119
########
Epoch: 21
Meta Train Loss: 1.027775764465332
########
Epoch: 22
Meta Train Loss: 0.8381181955337524
########
Epoch: 23
Meta Train Loss: 0.859002947807312
########
Epoch: 24
Meta Train Loss: 1.0309392213821411
########
Epoch: 25
Meta Train Loss: 0.7439128160476685
########
Epoch: 26
Meta Train Loss: 1.0092555284500122
########
Epoch: 27
Meta Train Loss: 0.8232600688934326
########
Epoch: 28
Meta Train Loss: 0.7633135318756104
########
Epoch: 29
Meta Train Loss: 1.0897525548934937
########
Epoch: 30
Meta Train Loss: 0.9183151721954346
########
Epoch: 31
Meta Train Loss: 0.7233635187149048
########
Epoch: 32
Meta Train Loss: 0.8787179589271545
########
Epoch: 33
Meta Train Loss: 1.0614674091339111
########
Epoch: 34
Meta Train Loss: 1.0757360458374023
########
Epoch: 35
Meta Train Loss: 0.9412149786949158
########
Epoch: 36
Meta Train Loss: 0.9590947031974792
########
Epoch: 37
Meta Train Loss: 0.8243696689605713
########
Epoch: 38
Meta Train Loss: 0.78502357006073
########
Epoch: 39
Meta Train Loss: 0.7959895133972168
########
Epoch: 40
Meta Train Loss: 0.6477406024932861
########
Epoch: 41
Meta Train Loss: 0.8215910196304321
########
Epoch: 42
Meta Train Loss: 0.5441597104072571
########
Epoch: 43
Meta Train Loss: 0.7584090828895569
########
Epoch: 44
Meta Train Loss: 0.6497207880020142
########
Epoch: 45
Meta Train Loss: 1.1047837734222412
########
Epoch: 46
Meta Train Loss: 0.7722506523132324
########
Epoch: 47
Meta Train Loss: 0.6423227787017822
########
Epoch: 48
Meta Train Loss: 0.8049056529998779
########
Epoch: 49
Meta Train Loss: 0.6183281540870667
########
Epoch: 50
Meta Train Loss: 0.595730185508728
########
Epoch: 51
Meta Train Loss: 0.7265377640724182
########
Epoch: 52
Meta Train Loss: 0.8691437840461731
########
Epoch: 53
Meta Train Loss: 0.5674245953559875
########
Epoch: 54
Meta Train Loss: 0.6077855825424194
########
Epoch: 55
Meta Train Loss: 0.8766310811042786
########
Epoch: 56
Meta Train Loss: 0.8488479852676392
########
Epoch: 57
Meta Train Loss: 0.6464487314224243
########
Epoch: 58
Meta Train Loss: 0.8620280027389526
########
Epoch: 59
Meta Train Loss: 0.765515148639679
########
Epoch: 60
Meta Train Loss: 0.6234991550445557
########
Epoch: 61
Meta Train Loss: 0.5713926553726196
########
Epoch: 62
Meta Train Loss: 1.2967338562011719
########
Epoch: 63
Meta Train Loss: 1.067442536354065
########
Epoch: 64
Meta Train Loss: 0.91843181848526
########
Epoch: 65
Meta Train Loss: 0.6010348200798035
########
Epoch: 66
Meta Train Loss: 0.6409969329833984
########
Epoch: 67
Meta Train Loss: 0.5745130181312561
########
Epoch: 68
Meta Train Loss: 1.0158042907714844
########
Epoch: 69
Meta Train Loss: 0.6539397239685059
########
Epoch: 70
Meta Train Loss: 0.861181914806366
########
Epoch: 71
Meta Train Loss: 0.6033057570457458
########
Epoch: 72
Meta Train Loss: 0.6514069437980652
########
Epoch: 73
Meta Train Loss: 0.6304457187652588
########
Epoch: 74
Meta Train Loss: 0.8220775127410889
########
Epoch: 75
Meta Train Loss: 0.7635645270347595
########
Epoch: 76
Meta Train Loss: 0.6749452948570251
########
Epoch: 77
Meta Train Loss: 0.87092125415802
########
Epoch: 78
Meta Train Loss: 0.5309457182884216
########
Epoch: 79
Meta Train Loss: 0.6524423360824585
########
Epoch: 80
Meta Train Loss: 0.6247281432151794
########
Epoch: 81
Meta Train Loss: 0.667444109916687
########
Epoch: 82
Meta Train Loss: 0.8407822251319885
########
Epoch: 83
Meta Train Loss: 0.5987485647201538
########
Epoch: 84
Meta Train Loss: 0.8877016305923462
########
Epoch: 85
Meta Train Loss: 0.4985475242137909
########
Epoch: 86
Meta Train Loss: 0.5472109913825989
########
Epoch: 87
Meta Train Loss: 0.6153236627578735
########
Epoch: 88
Meta Train Loss: 1.1341060400009155
########
Epoch: 89
Meta Train Loss: 0.5411220788955688
########
Epoch: 90
Meta Train Loss: 0.6210698485374451
########
Epoch: 91
Meta Train Loss: 0.7643176317214966
########
Epoch: 92
Meta Train Loss: 0.9685864448547363
########
Epoch: 93
Meta Train Loss: 0.7324141263961792
########
Epoch: 94
Meta Train Loss: 0.6052787899971008
########
Epoch: 95
Meta Train Loss: 0.7722569108009338
########
Epoch: 96
Meta Train Loss: 0.6422010660171509
########
Epoch: 97
Meta Train Loss: 0.7904776334762573
########
Epoch: 98
Meta Train Loss: 0.9239227175712585
########
Epoch: 99
Meta Train Loss: 0.5830968618392944
########
Epoch: 100
Meta Train Loss: 0.7632371187210083
########
Epoch: 101
Meta Train Loss: 0.6294602155685425
########
Epoch: 102
Meta Train Loss: 0.7472066879272461
########
Epoch: 103
Meta Train Loss: 0.5572342276573181
########
Epoch: 104
Meta Train Loss: 0.5530376434326172
########
Epoch: 105
Meta Train Loss: 0.731977105140686
########
Epoch: 106
Meta Train Loss: 0.4146828055381775
########
Epoch: 107
Meta Train Loss: 0.6045609712600708
########
Epoch: 108
Meta Train Loss: 0.6603305339813232
########
Epoch: 109
Meta Train Loss: 0.7613716125488281
########
Epoch: 110
Meta Train Loss: 4.171833515167236
########
Epoch: 111
Meta Train Loss: 0.7733671069145203
########
Epoch: 112
Meta Train Loss: 0.6327321529388428
########
Epoch: 113
Meta Train Loss: 1.1547743082046509
########
Epoch: 114
Meta Train Loss: 0.6485586762428284
########
Epoch: 115
Meta Train Loss: 0.6320119500160217
########
Epoch: 116
Meta Train Loss: 0.7256685495376587
########
Epoch: 117
Meta Train Loss: 0.6094191670417786
########
Epoch: 118
Meta Train Loss: 0.6070548295974731
########
Epoch: 119
Meta Train Loss: 0.7375168800354004
########
Epoch: 120
Meta Train Loss: 0.555720329284668
########
Epoch: 121
Meta Train Loss: 0.586567759513855
########
Epoch: 122
Meta Train Loss: 0.6317979097366333
########
Epoch: 123
Meta Train Loss: 0.7035806179046631
########
Epoch: 124
Meta Train Loss: 0.6603168845176697
########
Epoch: 125
Meta Train Loss: 0.5865922570228577
########
Epoch: 126
Meta Train Loss: 0.804297685623169
########
Epoch: 127
Meta Train Loss: 0.6556783318519592
########
Epoch: 128
Meta Train Loss: 0.757235050201416
########
Epoch: 129
Meta Train Loss: 0.7445626854896545
########
Epoch: 130
Meta Train Loss: 0.6294487118721008
########
Epoch: 131
Meta Train Loss: 0.513458788394928
########
Epoch: 132
Meta Train Loss: 0.7675866484642029
########
Epoch: 133
Meta Train Loss: 0.695421040058136
########
Epoch: 134
Meta Train Loss: 0.5071874856948853
########
Epoch: 135
Meta Train Loss: 0.628893256187439
########
Epoch: 136
Meta Train Loss: 0.760292649269104
########
Epoch: 137
Meta Train Loss: 0.4826784133911133
########
Epoch: 138
Meta Train Loss: 0.6620949506759644
########
Epoch: 139
Meta Train Loss: 0.97251296043396
########
Epoch: 140
Meta Train Loss: 206.60678100585938
########
Epoch: 141
Meta Train Loss: 0.59014493227005
########
Epoch: 142
Meta Train Loss: 0.7241451144218445
########
Epoch: 143
Meta Train Loss: 0.8166466951370239
########
Epoch: 144
Meta Train Loss: 0.6029520034790039
########
Epoch: 145
Meta Train Loss: 0.9400020837783813
########
Epoch: 146
Meta Train Loss: 0.6539830565452576
########
Epoch: 147
Meta Train Loss: 0.7143049836158752
########
Epoch: 148
Meta Train Loss: 0.6639530062675476
########
Epoch: 149
Meta Train Loss: 0.6412289142608643
########
Epoch: 150
Meta Train Loss: 13364.2080078125
########
Epoch: 151
Meta Train Loss: 0.6132058501243591
########
Epoch: 152
Meta Train Loss: 0.7500783205032349
########
Epoch: 153
Meta Train Loss: 0.6102296113967896
########
Epoch: 154
Meta Train Loss: 0.8596515655517578
########
Epoch: 155
Meta Train Loss: 0.5431731939315796
########
Epoch: 156
Meta Train Loss: 0.7082179188728333
########
Epoch: 157
Meta Train Loss: 0.6961017847061157
########
Epoch: 158
Meta Train Loss: 0.711405336856842
########
Epoch: 159
Meta Train Loss: 0.6649303436279297
########
Epoch: 160
Meta Train Loss: 0.6206406950950623
########
Epoch: 161
Meta Train Loss: 0.7241885662078857
########
Epoch: 162
Meta Train Loss: 0.6934893131256104
########
Epoch: 163
Meta Train Loss: 0.5247447490692139
########
Epoch: 164
Meta Train Loss: 0.9829312562942505
########
Epoch: 165
Meta Train Loss: 0.5266196727752686
########
Epoch: 166
Meta Train Loss: 0.7966706156730652
########
Epoch: 167
Meta Train Loss: 0.70853191614151
########
Epoch: 168
Meta Train Loss: 0.6921836137771606
########
Epoch: 169
Meta Train Loss: 1.167275071144104
########
Epoch: 170
Meta Train Loss: 0.768781840801239
########
Epoch: 171
Meta Train Loss: 0.6801295280456543
########
Epoch: 172
Meta Train Loss: 0.7403643131256104
########
Epoch: 173
Meta Train Loss: 0.745481014251709
########
Epoch: 174
Meta Train Loss: 0.5347740650177002
########
Epoch: 175
Meta Train Loss: 0.5984564423561096
########
Epoch: 176
Meta Train Loss: 0.50078946352005
########
Epoch: 177
Meta Train Loss: 0.7151299715042114
########
Epoch: 178
Meta Train Loss: 0.6172582507133484
########
Epoch: 179
Meta Train Loss: 0.5423145294189453
########
Epoch: 180
Meta Train Loss: 0.6780925989151001
########
Epoch: 181
Meta Train Loss: 0.7728418111801147
########
Epoch: 182
Meta Train Loss: 0.628059983253479
########
Epoch: 183
Meta Train Loss: 0.8355101346969604
########
Epoch: 184
Meta Train Loss: 0.6228955388069153
########
Epoch: 185
Meta Train Loss: 0.6429870128631592
########
Epoch: 186
Meta Train Loss: 0.6769170761108398
########
Epoch: 187
Meta Train Loss: 0.8863908648490906
########
Epoch: 188
Meta Train Loss: 0.6246815919876099
########
Epoch: 189
Meta Train Loss: 0.6470548510551453
########
Epoch: 190
Meta Train Loss: 0.7538784742355347
########
Epoch: 191
Meta Train Loss: 0.5641759037971497
########
Epoch: 192
Meta Train Loss: 0.7271214723587036
########
Epoch: 193
Meta Train Loss: 0.5436723232269287
########
Epoch: 194
Meta Train Loss: 0.6627209186553955
########
Epoch: 195
Meta Train Loss: 0.5467701554298401
########
Epoch: 196
Meta Train Loss: 0.42646434903144836
########
Epoch: 197
Meta Train Loss: 0.6188952922821045
########
Epoch: 198
Meta Train Loss: 0.5310929417610168
########
Epoch: 199
Meta Train Loss: 0.7929403185844421
########
Epoch: 200
Meta Train Loss: 0.5520734190940857
########
Epoch: 201
Meta Train Loss: 0.6317299008369446
########
Epoch: 202
Meta Train Loss: 0.766571044921875
########
Epoch: 203
Meta Train Loss: 0.9975665211677551
########
Epoch: 204
Meta Train Loss: 0.39943698048591614
########
Epoch: 205
Meta Train Loss: 0.7928075790405273
########
Epoch: 206
Meta Train Loss: 0.6971303224563599
########
Epoch: 207
Meta Train Loss: 0.5403234958648682
########
Epoch: 208
Meta Train Loss: 0.8074000477790833
########
Epoch: 209
Meta Train Loss: 0.7492574453353882
########
Epoch: 210
Meta Train Loss: 0.8546344041824341
########
Epoch: 211
Meta Train Loss: 0.6450486183166504
########
Epoch: 212
Meta Train Loss: 0.6509791612625122
########
Epoch: 213
Meta Train Loss: 0.45722126960754395
########
Epoch: 214
Meta Train Loss: 0.7724299430847168
########
Epoch: 215
Meta Train Loss: 0.5010173916816711
########
Epoch: 216
Meta Train Loss: 0.5131862759590149
########
Epoch: 217
Meta Train Loss: 0.5410959124565125
########
Epoch: 218
Meta Train Loss: 0.4647243320941925
########
Epoch: 219
Meta Train Loss: 0.6512846350669861
########
Epoch: 220
Meta Train Loss: 0.8090657591819763
########
Epoch: 221
Meta Train Loss: 0.6053109765052795
########
Epoch: 222
Meta Train Loss: 0.6072911620140076
########
Epoch: 223
Meta Train Loss: 0.5417363047599792
########
Epoch: 224
Meta Train Loss: 0.43216657638549805
########
Epoch: 225
Meta Train Loss: 0.5558907985687256
########
Epoch: 226
Meta Train Loss: 0.6593080759048462
########
Epoch: 227
Meta Train Loss: 0.6798078417778015
########
Epoch: 228
Meta Train Loss: 0.6577634811401367
########
Epoch: 229
Meta Train Loss: 0.5964472889900208
########
Epoch: 230
Meta Train Loss: 0.7410182952880859
########
Epoch: 231
Meta Train Loss: 0.5537471175193787
########
Epoch: 232
Meta Train Loss: 0.6625611782073975
########
Epoch: 233
Meta Train Loss: 0.685904324054718
########
Epoch: 234
Meta Train Loss: 0.6178306341171265
########
Epoch: 235
Meta Train Loss: 0.5326051115989685
########
Epoch: 236
Meta Train Loss: 0.6884158253669739
########
Epoch: 237
Meta Train Loss: 0.6321812868118286
########
Epoch: 238
Meta Train Loss: 0.7175028920173645
########
Epoch: 239
Meta Train Loss: 0.6076706647872925
########
Epoch: 240
Meta Train Loss: 1.0293933153152466
########
Epoch: 241
Meta Train Loss: 0.6985322833061218
########
Epoch: 242
Meta Train Loss: 1.070876121520996
########
Epoch: 243
Meta Train Loss: 0.6025060415267944
########
Epoch: 244
Meta Train Loss: 0.7364189624786377
########
Epoch: 245
Meta Train Loss: 0.5268980264663696
########
Epoch: 246
Meta Train Loss: 1.1043394804000854
########
Epoch: 247
Meta Train Loss: 0.6529142260551453
########
Epoch: 248
Meta Train Loss: 0.6601042747497559
########
Epoch: 249
Meta Train Loss: 0.7686956524848938
########
Epoch: 250
Meta Train Loss: 0.6321878433227539
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10585220: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Sun Oct 10 15:30:16 2021
Job was executed on host(s) <n-62-20-12>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Sun Oct 10 15:30:18 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Sun Oct 10 15:30:18 2021
Terminated at Sun Oct 10 20:16:06 2021
Results reported at Sun Oct 10 20:16:06 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/metalearning
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=8
K_SHOT=5
ADAPTATION_STEPS=5
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=yellow
LOG_DIR=/zhome/2b/7/117471/Thesis/metalearning
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10


python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR --exclude $EXCLUDE \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --gpu






------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17088.22 sec.
    Max Memory :                                 4126 MB
    Average Memory :                             4096.60 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               8162.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   17226 sec.
    Turnaround time :                            17150 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10585220> for stderr output of this job.

