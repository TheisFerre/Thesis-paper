Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 1.173046588897705
########
Epoch: 2
Meta Train Loss: 0.9463186860084534
########
Epoch: 3
Meta Train Loss: 1.2385553121566772
########
Epoch: 4
Meta Train Loss: 0.8826145529747009
########
Epoch: 5
Meta Train Loss: 1.1410597562789917
########
Epoch: 6
Meta Train Loss: 1.1736184358596802
########
Epoch: 7
Meta Train Loss: 0.9309200048446655
########
Epoch: 8
Meta Train Loss: 1.0183706283569336
########
Epoch: 9
Meta Train Loss: 0.8173539042472839
########
Epoch: 10
Meta Train Loss: 0.9411953687667847
########
Epoch: 11
Meta Train Loss: 1.0592032670974731
########
Epoch: 12
Meta Train Loss: 0.947373628616333
########
Epoch: 13
Meta Train Loss: 1.0776207447052002
########
Epoch: 14
Meta Train Loss: 0.9909329414367676
########
Epoch: 15
Meta Train Loss: 1.2642804384231567
########
Epoch: 16
Meta Train Loss: 0.9356127977371216
########
Epoch: 17
Meta Train Loss: 0.7406178712844849
########
Epoch: 18
Meta Train Loss: 1.074526309967041
########
Epoch: 19
Meta Train Loss: 0.8130805492401123
########
Epoch: 20
Meta Train Loss: 1.181501865386963
########
Epoch: 21
Meta Train Loss: 1.1316720247268677
########
Epoch: 22
Meta Train Loss: 0.920974850654602
########
Epoch: 23
Meta Train Loss: 0.7399025559425354
########
Epoch: 24
Meta Train Loss: 1.0952974557876587
########
Epoch: 25
Meta Train Loss: 0.949449360370636
########
Epoch: 26
Meta Train Loss: 0.7547889947891235
########
Epoch: 27
Meta Train Loss: 1.4111626148223877
########
Epoch: 28
Meta Train Loss: 0.8813259601593018
########
Epoch: 29
Meta Train Loss: 0.9865337610244751
########
Epoch: 30
Meta Train Loss: 1.0451323986053467
########
Epoch: 31
Meta Train Loss: 1.0785378217697144
########
Epoch: 32
Meta Train Loss: 0.7363667488098145
########
Epoch: 33
Meta Train Loss: 0.6220148205757141
########
Epoch: 34
Meta Train Loss: 0.983063817024231
########
Epoch: 35
Meta Train Loss: 0.7889202237129211
########
Epoch: 36
Meta Train Loss: 0.8145225048065186
########
Epoch: 37
Meta Train Loss: 0.6015977263450623
########
Epoch: 38
Meta Train Loss: 0.746482253074646
########
Epoch: 39
Meta Train Loss: 0.61473548412323
########
Epoch: 40
Meta Train Loss: 0.7323917746543884
########
Epoch: 41
Meta Train Loss: 0.7293123602867126
########
Epoch: 42
Meta Train Loss: 1.5642668008804321
########
Epoch: 43
Meta Train Loss: 0.9939804077148438
########
Epoch: 44
Meta Train Loss: 0.8046857118606567
########
Epoch: 45
Meta Train Loss: 0.595314085483551
########
Epoch: 46
Meta Train Loss: 0.7911937832832336
########
Epoch: 47
Meta Train Loss: 0.6207367777824402
########
Epoch: 48
Meta Train Loss: 0.6823247075080872
########
Epoch: 49
Meta Train Loss: 0.7443555593490601
########
Epoch: 50
Meta Train Loss: 0.5694112181663513
########
Epoch: 51
Meta Train Loss: 0.9418248534202576
########
Epoch: 52
Meta Train Loss: 0.866365909576416
########
Epoch: 53
Meta Train Loss: 0.7000647783279419
########
Epoch: 54
Meta Train Loss: 0.6832702159881592
########
Epoch: 55
Meta Train Loss: 0.6335480809211731
########
Epoch: 56
Meta Train Loss: 0.6269018054008484
########
Epoch: 57
Meta Train Loss: 0.6777740120887756
########
Epoch: 58
Meta Train Loss: 0.7644068002700806
########
Epoch: 59
Meta Train Loss: 0.7717610001564026
########
Epoch: 60
Meta Train Loss: 0.6435908675193787
########
Epoch: 61
Meta Train Loss: 0.9018316268920898
########
Epoch: 62
Meta Train Loss: 0.8010642528533936
########
Epoch: 63
Meta Train Loss: 0.7631971836090088
########
Epoch: 64
Meta Train Loss: 0.7638835310935974
########
Epoch: 65
Meta Train Loss: 0.654816210269928
########
Epoch: 66
Meta Train Loss: 0.6532648205757141
########
Epoch: 67
Meta Train Loss: 0.9435887336730957
########
Epoch: 68
Meta Train Loss: 0.3843599259853363
########
Epoch: 69
Meta Train Loss: 0.512114405632019
########
Epoch: 70
Meta Train Loss: 0.9202969074249268
########
Epoch: 71
Meta Train Loss: 0.756649911403656
########
Epoch: 72
Meta Train Loss: 0.7832358479499817
########
Epoch: 73
Meta Train Loss: 0.70119708776474
########
Epoch: 74
Meta Train Loss: 0.9111162424087524
########
Epoch: 75
Meta Train Loss: 0.7658065557479858
########
Epoch: 76
Meta Train Loss: 0.6811142563819885
########
Epoch: 77
Meta Train Loss: 0.8079226016998291
########
Epoch: 78
Meta Train Loss: 0.5898820757865906
########
Epoch: 79
Meta Train Loss: 0.8715322017669678
########
Epoch: 80
Meta Train Loss: 0.5428356528282166
########
Epoch: 81
Meta Train Loss: 0.7773866653442383
########
Epoch: 82
Meta Train Loss: 0.6379887461662292
########
Epoch: 83
Meta Train Loss: 0.7092188000679016
########
Epoch: 84
Meta Train Loss: 0.8097994327545166
########
Epoch: 85
Meta Train Loss: 0.6416906118392944
########
Epoch: 86
Meta Train Loss: 0.8937469720840454
########
Epoch: 87
Meta Train Loss: 1.1489508152008057
########
Epoch: 88
Meta Train Loss: 0.6404843926429749
########
Epoch: 89
Meta Train Loss: 0.7542824149131775
########
Epoch: 90
Meta Train Loss: 0.7152476906776428
########
Epoch: 91
Meta Train Loss: 0.5638250708580017
########
Epoch: 92
Meta Train Loss: 0.6626856327056885
########
Epoch: 93
Meta Train Loss: 0.9606854319572449
########
Epoch: 94
Meta Train Loss: 0.7022500038146973
########
Epoch: 95
Meta Train Loss: 0.8021283745765686
########
Epoch: 96
Meta Train Loss: 0.5440537929534912
########
Epoch: 97
Meta Train Loss: 0.6918849945068359
########
Epoch: 98
Meta Train Loss: 0.642295241355896
########
Epoch: 99
Meta Train Loss: 0.9558508992195129
########
Epoch: 100
Meta Train Loss: 0.7085098028182983
########
Epoch: 101
Meta Train Loss: 0.6066341996192932
########
Epoch: 102
Meta Train Loss: 0.5846070647239685
########
Epoch: 103
Meta Train Loss: 1.1514607667922974
########
Epoch: 104
Meta Train Loss: 0.7394645810127258
########
Epoch: 105
Meta Train Loss: 0.9293646216392517
########
Epoch: 106
Meta Train Loss: 0.6275572180747986
########
Epoch: 107
Meta Train Loss: 0.6352500915527344
########
Epoch: 108
Meta Train Loss: 0.7501980662345886
########
Epoch: 109
Meta Train Loss: 0.701310932636261
########
Epoch: 110
Meta Train Loss: 0.572067379951477
########
Epoch: 111
Meta Train Loss: 1.3564845323562622
########
Epoch: 112
Meta Train Loss: 0.7140616774559021
########
Epoch: 113
Meta Train Loss: 0.8797907829284668
########
Epoch: 114
Meta Train Loss: 0.7130436301231384
########
Epoch: 115
Meta Train Loss: 0.562913715839386
########
Epoch: 116
Meta Train Loss: 0.5753068327903748
########
Epoch: 117
Meta Train Loss: 0.6831309795379639
########
Epoch: 118
Meta Train Loss: 0.707177996635437
########
Epoch: 119
Meta Train Loss: 0.5973266363143921
########
Epoch: 120
Meta Train Loss: 0.6530485153198242
########
Epoch: 121
Meta Train Loss: 0.8211789131164551
########
Epoch: 122
Meta Train Loss: 0.6509191989898682
########
Epoch: 123
Meta Train Loss: 0.804959774017334
########
Epoch: 124
Meta Train Loss: 0.5038127899169922
########
Epoch: 125
Meta Train Loss: 0.949652910232544
########
Epoch: 126
Meta Train Loss: 0.511709988117218
########
Epoch: 127
Meta Train Loss: 0.4284220337867737
########
Epoch: 128
Meta Train Loss: 0.4376162588596344
########
Epoch: 129
Meta Train Loss: 0.8499729633331299
########
Epoch: 130
Meta Train Loss: 0.7141042947769165
########
Epoch: 131
Meta Train Loss: 0.6427040100097656
########
Epoch: 132
Meta Train Loss: 0.6059749722480774
########
Epoch: 133
Meta Train Loss: 0.5795332193374634
########
Epoch: 134
Meta Train Loss: 0.6392033100128174
########
Epoch: 135
Meta Train Loss: 0.697395384311676
########
Epoch: 136
Meta Train Loss: 0.5280624628067017
########
Epoch: 137
Meta Train Loss: 0.560860812664032
########
Epoch: 138
Meta Train Loss: 0.4210359454154968
########
Epoch: 139
Meta Train Loss: 0.7401309013366699
########
Epoch: 140
Meta Train Loss: 0.6688219904899597
########
Epoch: 141
Meta Train Loss: 0.9100908041000366
########
Epoch: 142
Meta Train Loss: 0.7724475264549255
########
Epoch: 143
Meta Train Loss: 0.7092306613922119
########
Epoch: 144
Meta Train Loss: 0.6226656436920166
########
Epoch: 145
Meta Train Loss: 0.5943455696105957
########
Epoch: 146
Meta Train Loss: 0.48251235485076904
########
Epoch: 147
Meta Train Loss: 0.6514825820922852
########
Epoch: 148
Meta Train Loss: 0.5890083312988281
########
Epoch: 149
Meta Train Loss: 0.6034825444221497
########
Epoch: 150
Meta Train Loss: 0.5028150081634521
########
Epoch: 151
Meta Train Loss: 0.6056197285652161
########
Epoch: 152
Meta Train Loss: 0.7705380916595459
########
Epoch: 153
Meta Train Loss: 1.3509801626205444
########
Epoch: 154
Meta Train Loss: 0.5563317537307739
########
Epoch: 155
Meta Train Loss: 0.4834831953048706
########
Epoch: 156
Meta Train Loss: 0.7130239009857178
########
Epoch: 157
Meta Train Loss: 0.6523476243019104
########
Epoch: 158
Meta Train Loss: 0.7908262014389038
########
Epoch: 159
Meta Train Loss: 0.5688315629959106
########
Epoch: 160
Meta Train Loss: 0.6784673929214478
########
Epoch: 161
Meta Train Loss: 0.6240101456642151
########
Epoch: 162
Meta Train Loss: 0.5478114485740662
########
Epoch: 163
Meta Train Loss: 0.7441800236701965
########
Epoch: 164
Meta Train Loss: 0.451947420835495
########
Epoch: 165
Meta Train Loss: 0.6504958868026733
########
Epoch: 166
Meta Train Loss: 0.6206130981445312
########
Epoch: 167
Meta Train Loss: 0.516044557094574
########
Epoch: 168
Meta Train Loss: 0.8831430673599243
########
Epoch: 169
Meta Train Loss: 0.3934536576271057
########
Epoch: 170
Meta Train Loss: 0.9300368428230286
########
Epoch: 171
Meta Train Loss: 0.7905978560447693
########
Epoch: 172
Meta Train Loss: 0.6005034446716309
########
Epoch: 173
Meta Train Loss: 0.5646475553512573
########
Epoch: 174
Meta Train Loss: 0.6001018285751343
########
Epoch: 175
Meta Train Loss: 0.6208925843238831
########
Epoch: 176
Meta Train Loss: 0.8053843975067139
########
Epoch: 177
Meta Train Loss: 0.6831908226013184
########
Epoch: 178
Meta Train Loss: 0.5084876418113708
########
Epoch: 179
Meta Train Loss: 0.6413248777389526
########
Epoch: 180
Meta Train Loss: 0.4850151538848877
########
Epoch: 181
Meta Train Loss: 0.5268852710723877
########
Epoch: 182
Meta Train Loss: 0.7527728080749512
########
Epoch: 183
Meta Train Loss: 0.4856443703174591
########
Epoch: 184
Meta Train Loss: 0.5834683179855347
########
Epoch: 185
Meta Train Loss: 0.6067835688591003
########
Epoch: 186
Meta Train Loss: 0.48872536420822144
########
Epoch: 187
Meta Train Loss: 0.5882052779197693
########
Epoch: 188
Meta Train Loss: 0.6657137870788574
########
Epoch: 189
Meta Train Loss: 0.4985194504261017
########
Epoch: 190
Meta Train Loss: 0.6659505367279053
########
Epoch: 191
Meta Train Loss: 0.7463460564613342
########
Epoch: 192
Meta Train Loss: 0.489214152097702
########
Epoch: 193
Meta Train Loss: 0.44785186648368835
########
Epoch: 194
Meta Train Loss: 0.6401489973068237
########
Epoch: 195
Meta Train Loss: 0.43243709206581116
########
Epoch: 196
Meta Train Loss: 0.8071215152740479
########
Epoch: 197
Meta Train Loss: 0.6284244060516357
########
Epoch: 198
Meta Train Loss: 0.6187726259231567
########
Epoch: 199
Meta Train Loss: 0.7520293593406677
########
Epoch: 200
Meta Train Loss: 0.6664220690727234
########
Epoch: 201
Meta Train Loss: 1.0259956121444702
########
Epoch: 202
Meta Train Loss: 0.5536872744560242
########
Epoch: 203
Meta Train Loss: 1.1198221445083618
########
Epoch: 204
Meta Train Loss: 0.4503083825111389
########
Epoch: 205
Meta Train Loss: 0.7179185152053833
########
Epoch: 206
Meta Train Loss: 0.42853131890296936
########
Epoch: 207
Meta Train Loss: 0.5946953892707825
########
Epoch: 208
Meta Train Loss: 0.687472403049469
########
Epoch: 209
Meta Train Loss: 0.8478643894195557
########
Epoch: 210
Meta Train Loss: 0.6262719035148621
########
Epoch: 211
Meta Train Loss: 0.6324291825294495
########
Epoch: 212
Meta Train Loss: 0.607306718826294
########
Epoch: 213
Meta Train Loss: 0.6923874020576477
########
Epoch: 214
Meta Train Loss: 0.669848620891571
########
Epoch: 215
Meta Train Loss: 0.46841198205947876
########
Epoch: 216
Meta Train Loss: 0.6923335790634155
########
Epoch: 217
Meta Train Loss: 0.5549235939979553
########
Epoch: 218
Meta Train Loss: 0.5959932208061218
########
Epoch: 219
Meta Train Loss: 0.8725952506065369
########
Epoch: 220
Meta Train Loss: 0.8633254170417786
########
Epoch: 221
Meta Train Loss: 0.7173688411712646
########
Epoch: 222
Meta Train Loss: 0.5632444024085999
########
Epoch: 223
Meta Train Loss: 0.498250812292099
########
Epoch: 224
Meta Train Loss: 0.6241095662117004
########
Epoch: 225
Meta Train Loss: 0.5023757815361023
########
Epoch: 226
Meta Train Loss: 0.5763645172119141
########
Epoch: 227
Meta Train Loss: 0.6320194602012634
########
Epoch: 228
Meta Train Loss: 0.5612192153930664
########
Epoch: 229
Meta Train Loss: 0.7643274664878845
########
Epoch: 230
Meta Train Loss: 0.6398136019706726
########
Epoch: 231
Meta Train Loss: 0.7228929400444031
########
Epoch: 232
Meta Train Loss: 0.768786609172821
########
Epoch: 233
Meta Train Loss: 0.7641929388046265
########
Epoch: 234
Meta Train Loss: 0.6328269243240356
########
Epoch: 235
Meta Train Loss: 0.6233248114585876
########
Epoch: 236
Meta Train Loss: 0.9305922985076904
########
Epoch: 237
Meta Train Loss: 0.6133352518081665
########
Epoch: 238
Meta Train Loss: 0.7030547857284546
########
Epoch: 239
Meta Train Loss: 0.6233277916908264
########
Epoch: 240
Meta Train Loss: 0.4947289824485779
########
Epoch: 241
Meta Train Loss: 0.5597060918807983
########
Epoch: 242
Meta Train Loss: 0.5228891372680664
########
Epoch: 243
Meta Train Loss: 0.545889139175415
########
Epoch: 244
Meta Train Loss: 0.5514472126960754
########
Epoch: 245
Meta Train Loss: 0.52135169506073
########
Epoch: 246
Meta Train Loss: 0.6633215546607971
########
Epoch: 247
Meta Train Loss: 0.5119448900222778
########
Epoch: 248
Meta Train Loss: 0.9060421586036682
########
Epoch: 249
Meta Train Loss: 0.5710865259170532
########
Epoch: 250
Meta Train Loss: 0.6011807322502136
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10557194: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Mon Oct  4 13:45:04 2021
Job was executed on host(s) <n-62-11-16>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Mon Oct  4 13:45:05 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Mon Oct  4 13:45:05 2021
Terminated at Mon Oct  4 14:10:58 2021
Results reported at Mon Oct  4 14:10:58 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/metalearning
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=8
K_SHOT=5
ADAPTATION_STEPS=5
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=citibike-tripdata
LOG_DIR=/zhome/2b/7/117471/Thesis/metalearning
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10


python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR --exclude $EXCLUDE \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --gpu






------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1542.30 sec.
    Max Memory :                                 3414 MB
    Average Memory :                             3192.07 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               8874.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   1553 sec.
    Turnaround time :                            1554 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10557194> for stderr output of this job.

