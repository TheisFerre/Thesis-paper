Starting:
/zhome/2b/7/117471/Thesis/data/processed/metalearning/GM2017-july-sep-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49017229676246643
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48468077182769775
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47472286224365234
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47000548243522644
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5015093088150024
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.45792290568351746
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5268295407295227
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49049586057662964
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5225096940994263
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47600463032722473
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48346707224845886
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48340898752212524
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4743730425834656
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47802409529685974
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4777967035770416
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.511479914188385
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5206958055496216
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48673707246780396
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.50029456615448
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49835389852523804
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4787641167640686
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4613126814365387
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4795505106449127
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48463815450668335
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48252132534980774
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47750580310821533
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.480193555355072
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4802429676055908
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4938352108001709
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4736267328262329
Baseline loss: 0.1409626454114914
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.3872157633304596
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49877116084098816
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.3915470242500305
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47307538986206055
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.3939054608345032
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5134550333023071
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.4059733748435974
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4659588038921356
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.42082643508911133
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48775747418403625
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.2982938289642334
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48143020272254944
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.39911559224128723
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4862273335456848
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.39433765411376953
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4992206394672394
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.3960031270980835
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4805254638195038
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.40278950333595276
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5282882452011108
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.42100265622138977
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4891129434108734
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.3825943171977997
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4726654589176178
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.40393438935279846
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5004547834396362
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.3773747980594635
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4847627282142639
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.4029586911201477
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5025301575660706
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.3985308110713959
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4651482105255127
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.4126589596271515
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5200613141059875
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.32106614112854004
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4810735583305359
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.3948740065097809
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4845251739025116
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.4076516330242157
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49420365691185
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.3861585557460785
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48099321126937866
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.3844050168991089
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4806952476501465
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.3956628739833832
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4907013475894928
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.3991435170173645
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4806206226348877
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.38929253816604614
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48456746339797974
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.4310135841369629
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4826308488845825
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.39384278655052185
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4699253737926483
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.3919681906700134
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4967055320739746
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.4112519919872284
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5378560423851013
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.4797762632369995
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4701945185661316
Baseline loss: 0.1409626454114914
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.38996031880378723
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5126878023147583
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.3867785632610321
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49449384212493896
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.41454797983169556
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5114917755126953
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.3962070047855377
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.46433010697364807
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.3724464178085327
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48844850063323975
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.38196617364883423
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4812367856502533
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.4097723364830017
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4829212725162506
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.3821958303451538
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49727296829223633
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.3762175142765045
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47334006428718567
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.37847086787223816
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5035505890846252
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.42243823409080505
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49399232864379883
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.3966585099697113
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4786875545978546
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.41473859548568726
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5032151937484741
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.3489764630794525
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48455438017845154
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.39173755049705505
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5043931603431702
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.37836953997612
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.46529850363731384
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.4397837817668915
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5199589133262634
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.3786134719848633
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4781145751476288
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.37699076533317566
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4798564314842224
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.3799598515033722
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4901978671550751
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.38304761052131653
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48250648379325867
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.37770965695381165
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48842376470565796
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.40624260902404785
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4904199540615082
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.39486005902290344
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4803016483783722
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.393491268157959
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4906827509403229
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.39145076274871826
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.483929842710495
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.4117629826068878
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.46783167123794556
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.4028792381286621
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49324679374694824
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.4102856516838074
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5178250670433044
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.40677037835121155
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4812476634979248
Baseline loss: 0.1409626454114914
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/yellow-taxi2020-nov-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0367395877838135
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0925356149673462
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0577064752578735
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.06373929977417
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1150602102279663
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0464973449707031
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0627977848052979
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0525848865509033
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0459184646606445
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0344713926315308
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0597131252288818
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0344856977462769
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.037110686302185
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0706461668014526
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0345360040664673
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0421946048736572
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0594987869262695
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0885181427001953
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0594022274017334
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0573724508285522
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0453699827194214
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.071377158164978
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.035895586013794
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0463122129440308
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0550577640533447
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0443254709243774
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0731196403503418
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0485042333602905
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0451321601867676
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.052748203277588
Baseline loss: 1.3998377323150635
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.8405974507331848
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0550535917282104
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.8465512990951538
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.5167441368103027
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.8335510492324829
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0592554807662964
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.8376668095588684
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0690261125564575
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.8886460065841675
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.097166895866394
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.838998019695282
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0416845083236694
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.8611292839050293
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1053632497787476
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.8890166282653809
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1382558345794678
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.8356859087944031
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.071251630783081
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.8670830130577087
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0482174158096313
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.834139883518219
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0698988437652588
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.8596174120903015
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0896518230438232
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.8434280157089233
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0398236513137817
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.8897433280944824
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0423189401626587
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.8688708543777466
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0372066497802734
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.8794997930526733
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0887629985809326
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.8416903614997864
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.104514479637146
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.8624768257141113
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0455347299575806
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.8438394665718079
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0487650632858276
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.8400499820709229
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.059910535812378
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.8378952741622925
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0467432737350464
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.8576445579528809
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0861892700195312
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.9184080362319946
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0684661865234375
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.8691735863685608
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0453280210494995
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.8717553019523621
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0499026775360107
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.8388792872428894
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0842037200927734
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.8354547619819641
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0353175401687622
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.8496824502944946
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0493757724761963
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.8386527299880981
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0500696897506714
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.8336785435676575
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0681676864624023
Baseline loss: 1.3998377323150635
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.8476066589355469
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0809800624847412
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.8335773348808289
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0552446842193604
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.8408809304237366
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.042864441871643
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.8406916856765747
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.040724754333496
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.8510318398475647
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0936628580093384
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.8331131935119629
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0382810831069946
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.8543789982795715
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0290476083755493
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.8351009488105774
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1210813522338867
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.8515941500663757
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0771502256393433
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.8546188473701477
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0711621046066284
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.8370874524116516
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0638563632965088
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.8460128903388977
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0473960638046265
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.8807416558265686
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0673466920852661
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.8501140475273132
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.043848991394043
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.8612861037254333
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0569740533828735
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.8627772927284241
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0636283159255981
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.8400277495384216
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0834784507751465
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.8503058552742004
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0666955709457397
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.8500158190727234
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1163530349731445
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.8630353808403015
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0454869270324707
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.844287097454071
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0484473705291748
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.8375318050384521
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0480382442474365
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.8481915593147278
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0329407453536987
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.8374108076095581
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0426522493362427
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.8387138843536377
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0681577920913696
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.8587260246276855
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0614867210388184
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.8358442187309265
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0620516538619995
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.8550090789794922
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0437016487121582
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.8391431570053101
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0410797595977783
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.8330880999565125
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0458682775497437
Baseline loss: 1.3998377323150635
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/LYFT2014-july-sep-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.351136565208435
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.364587426185608
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3620916604995728
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3517546653747559
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3812215328216553
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.351784348487854
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.372826099395752
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3584662675857544
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.392983317375183
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3519669771194458
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3598724603652954
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3530893325805664
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3497776985168457
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.352480173110962
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3481740951538086
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3970847129821777
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.387257695198059
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3743022680282593
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.386022925376892
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3681336641311646
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3543410301208496
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3466107845306396
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.349501132965088
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3599059581756592
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3558595180511475
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3462951183319092
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3597713708877563
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.359640121459961
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3626939058303833
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3463332653045654
Baseline loss: 1.6722253561019897
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1866496801376343
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.4630424976348877
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.1886957883834839
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.5045241117477417
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.1775845289230347
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3621416091918945
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.180707335472107
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3520368337631226
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.180321455001831
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3751190900802612
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1758646965026855
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.356095790863037
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1814746856689453
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3787310123443604
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1903682947158813
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.386190414428711
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.1772178411483765
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3696192502975464
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.1863179206848145
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.350421667098999
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1735275983810425
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.354491949081421
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.1765363216400146
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3465276956558228
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.2190673351287842
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3752427101135254
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1743048429489136
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3386539220809937
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.1924039125442505
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3791424036026
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1721739768981934
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3594557046890259
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.187519907951355
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3638969659805298
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1902203559875488
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.37740159034729
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1726760864257812
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3813773393630981
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1830062866210938
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3773229122161865
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.1784191131591797
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3663640022277832
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1808017492294312
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3576003313064575
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1724660396575928
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.371535062789917
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.181105136871338
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3731589317321777
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1780246496200562
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3602852821350098
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.1762943267822266
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3528040647506714
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 2.2739007472991943
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.343813419342041
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1795332431793213
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.38218092918396
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1754310131072998
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3945938348770142
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1859945058822632
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3613184690475464
Baseline loss: 1.6722253561019897
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1726152896881104
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3770314455032349
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.188683271408081
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.4178249835968018
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.182715892791748
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3741531372070312
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.1818987131118774
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3488333225250244
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.1700489521026611
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.375807285308838
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1692103147506714
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3566068410873413
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1791054010391235
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3550424575805664
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1924618482589722
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.387000560760498
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.2219990491867065
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3618980646133423
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.172458529472351
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3623502254486084
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1847705841064453
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3541810512542725
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.1699182987213135
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3462326526641846
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.1952069997787476
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3626900911331177
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1942775249481201
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3383350372314453
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.176550269126892
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3636683225631714
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1815770864486694
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3522698879241943
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.1800236701965332
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.362234354019165
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1784160137176514
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3605856895446777
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1853549480438232
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.369855284690857
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1699398756027222
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3763970136642456
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.1756789684295654
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3643898963928223
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1801419258117676
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3625304698944092
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1721181869506836
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3689197301864624
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.1738733053207397
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.35868501663208
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1732256412506104
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.362076997756958
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.17402184009552
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.351067304611206
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 1.16994047164917
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3398915529251099
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1704139709472656
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3817707300186157
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1719999313354492
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.374392032623291
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1712008714675903
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.349432110786438
Baseline loss: 1.6722253561019897
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/UBER2015-jan-june-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1094002723693848
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1082464456558228
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1170425415039062
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0970484018325806
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1170803308486938
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1079479455947876
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1239495277404785
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.116360068321228
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.143099069595337
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0959763526916504
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1031986474990845
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0998107194900513
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1118310689926147
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1136574745178223
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0977327823638916
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1084295511245728
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1154847145080566
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1150368452072144
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1178457736968994
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.110300898551941
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1019232273101807
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.104276180267334
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0957742929458618
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1134897470474243
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.117621660232544
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1022162437438965
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1115645170211792
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1216938495635986
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1047388315200806
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0958901643753052
Baseline loss: 0.9849832057952881
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7464540600776672
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.2082481384277344
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7523477673530579
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.3918737173080444
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7374118566513062
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.121272325515747
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 4.868797302246094
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1069326400756836
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7411990761756897
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1255491971969604
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.740938663482666
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1030471324920654
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7411461472511292
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.108771800994873
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7491415739059448
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1351268291473389
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7456675171852112
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1021031141281128
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7405640482902527
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1113665103912354
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7423410415649414
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1298840045928955
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7539328336715698
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.099697470664978
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7527146339416504
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1076260805130005
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7399412989616394
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.094366431236267
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7417717576026917
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1053751707077026
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7669736742973328
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1111345291137695
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7358948588371277
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1314516067504883
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7364103198051453
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0953055620193481
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7423930764198303
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1462944746017456
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.8432031869888306
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.098870873451233
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.7599378228187561
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1041998863220215
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7416644096374512
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1050351858139038
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7418162226676941
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1058766841888428
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7379341125488281
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1011008024215698
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7751688957214355
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1004749536514282
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7386525273323059
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1099830865859985
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7645403146743774
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0881364345550537
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.785437285900116
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1179226636886597
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7678610682487488
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1054515838623047
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7801697850227356
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0986000299453735
Baseline loss: 0.9849832057952881
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7457913756370544
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1166772842407227
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7343871593475342
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.122565746307373
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7375801801681519
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1106126308441162
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 0.7441854476928711
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1058330535888672
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7422087788581848
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1162651777267456
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.7495810985565186
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.111710548400879
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7541530132293701
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1122885942459106
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7621745467185974
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1230882406234741
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7418184876441956
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0996447801589966
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7394078373908997
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1115305423736572
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7608311772346497
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1258469820022583
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7349145412445068
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0974220037460327
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7313789129257202
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.100821852684021
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7419418692588806
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0955733060836792
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7351241707801819
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1068569421768188
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7618462443351746
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.109782099723816
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7364850640296936
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1149626970291138
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7443094253540039
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0969065427780151
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7478917241096497
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1213780641555786
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.751947820186615
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1003941297531128
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.7320335507392883
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.102467656135559
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7312830686569214
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.099643349647522
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7440291047096252
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1065093278884888
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7479890584945679
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0993497371673584
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7704651355743408
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0973917245864868
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7395240664482117
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.109781265258789
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7578989863395691
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0899338722229004
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.7480869889259338
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1204098463058472
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7458372116088867
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.108425498008728
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7540631294250488
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0961180925369263
Baseline loss: 0.9849832057952881
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/TLC2018-FHV-aug-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9376985430717468
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9456560611724854
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9484923481941223
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9548320174217224
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0030452013015747
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9553759098052979
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0115059614181519
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9924414753913879
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0275096893310547
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9550331830978394
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9645947217941284
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9517157673835754
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9801419377326965
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9699686765670776
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9436296224594116
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9776069521903992
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0482620000839233
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.97818922996521
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0306373834609985
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9534464478492737
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9468361735343933
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9421424269676208
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.948642373085022
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9673512578010559
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9707230925559998
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9678338766098022
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9787893295288086
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9615800976753235
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9569540023803711
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9459384083747864
Baseline loss: 0.44635626673698425
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.48548221588134766
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.1634166240692139
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.6076323390007019
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.6659659147262573
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.7347047924995422
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0480287075042725
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.5861476063728333
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9398606419563293
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.4294244945049286
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9550673365592957
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.6826165914535522
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.965360701084137
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.581882655620575
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9509850740432739
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.8012454509735107
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0135180950164795
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.6762933135032654
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0089393854141235
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.44229447841644287
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.951797366142273
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.7746529579162598
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9922735095024109
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.652418315410614
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9726737141609192
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.5104092955589294
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.990964412689209
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.5031205415725708
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9445204734802246
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.4678572714328766
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.993283212184906
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.4920821487903595
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9638487696647644
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.5468093752861023
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.961573600769043
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.4112476706504822
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.967115044593811
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.6025229692459106
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.033969521522522
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.49029842019081116
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9620233178138733
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.5006634593009949
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9684577584266663
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.48121634125709534
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0056325197219849
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.4308548867702484
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9621095061302185
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.4740791618824005
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9490589499473572
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.4122791588306427
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9567437767982483
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.5008763670921326
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9476877450942993
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.4238465130329132
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9357256293296814
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.4683949649333954
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9804133176803589
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.5165044665336609
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.040377140045166
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.6284025311470032
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9611321687698364
Baseline loss: 0.44635626673698425
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4273303747177124
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0167369842529297
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.4881395995616913
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0062897205352783
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.5168956518173218
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0049793720245361
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.47408992052078247
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9473339915275574
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.4274325966835022
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0449223518371582
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.4332427382469177
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9543829560279846
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.4735393226146698
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9404500722885132
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.5283859968185425
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9540181159973145
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.48038601875305176
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9459859132766724
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.4426327347755432
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9713848829269409
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.562657356262207
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9646061062812805
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.5391495227813721
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9571526050567627
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.46614497900009155
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9727488160133362
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.5758832693099976
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9834458231925964
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.420457661151886
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.968285322189331
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.5856953263282776
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0042365789413452
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.500646710395813
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.943162202835083
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.500320315361023
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9831402897834778
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.534610390663147
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9749258756637573
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.4430762827396393
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9561451077461243
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.41510576009750366
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9470775127410889
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.4699985980987549
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9616640210151672
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.4778293967247009
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9796544313430786
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.4523910880088806
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9479051828384399
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.4591597616672516
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9748313426971436
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.5449724197387695
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.96656334400177
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.47279343008995056
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9608524441719055
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.43219661712646484
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9634482860565186
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.43173518776893616
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9850602149963379
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.5854426622390747
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.964184045791626
Baseline loss: 0.44635626673698425
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/T-Drive-taxi-pickups-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0882344245910645
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0953550338745117
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0905945301055908
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0958781242370605
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1076310873031616
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.095656156539917
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0908740758895874
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0945639610290527
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0902705192565918
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0949831008911133
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0948439836502075
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0897184610366821
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1024367809295654
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1110785007476807
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0954254865646362
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1225769519805908
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0995169878005981
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.093998670578003
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.088780403137207
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1116056442260742
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1104191541671753
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.098863124847412
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1044684648513794
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0996330976486206
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1075698137283325
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0952157974243164
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1193848848342896
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0897400379180908
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1217654943466187
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0968173742294312
Baseline loss: 2.267239809036255
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.107548475265503
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1268386840820312
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.0889837741851807
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1435502767562866
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.1139354705810547
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1422853469848633
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.0928443670272827
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1414093971252441
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.098685622215271
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1807223558425903
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.0960466861724854
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1113930940628052
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.1698697805404663
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0943506956100464
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.1084719896316528
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1107125282287598
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.1435374021530151
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.088630199432373
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.089564561843872
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1131603717803955
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.1057581901550293
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0908639430999756
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.1423101425170898
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.10078763961792
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.0959774255752563
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1047663688659668
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.081754446029663
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.088086485862732
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.089475393295288
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.158198595046997
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.1182544231414795
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1010500192642212
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.0968856811523438
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1062968969345093
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.1138039827346802
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1240227222442627
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.1179709434509277
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0997117757797241
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.104364275932312
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1207051277160645
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.1277559995651245
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1158628463745117
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.1161648035049438
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1208022832870483
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.0923476219177246
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1041985750198364
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.0907583236694336
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0839602947235107
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.1527858972549438
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0937933921813965
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.1606658697128296
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.122739553451538
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.152225375175476
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0915368795394897
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.0890660285949707
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.205994963645935
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.0980675220489502
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.110926628112793
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.1152985095977783
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0962979793548584
Baseline loss: 2.267239809036255
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.096221685409546
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.095345377922058
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.088585615158081
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1391658782958984
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.0957164764404297
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1165398359298706
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.0928677320480347
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1131563186645508
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.096471905708313
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1163017749786377
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.0839264392852783
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1366585493087769
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.0928103923797607
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0960736274719238
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.0900180339813232
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1105613708496094
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.0882561206817627
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0868538618087769
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.090810775756836
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.109000563621521
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.0913889408111572
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0884088277816772
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.091802954673767
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1030316352844238
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.0910096168518066
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0925345420837402
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.0948799848556519
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.084969162940979
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.097840428352356
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1270427703857422
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.0980507135391235
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.106986403465271
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.101690411567688
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0895668268203735
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.0986106395721436
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.126460313796997
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.0976251363754272
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0999846458435059
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.097161889076233
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1170214414596558
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.0953834056854248
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1092873811721802
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.1065868139266968
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0913671255111694
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.0896728038787842
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1091582775115967
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.0891976356506348
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0834227800369263
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.1113433837890625
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0926282405853271
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.0908465385437012
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1140841245651245
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.1256953477859497
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0906596183776855
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.08634352684021
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1524014472961426
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.084560513496399
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1120939254760742
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.094590187072754
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0981119871139526
Baseline loss: 2.267239809036255
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/GM2017-july-sep-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.099570393562317
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1149252653121948
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1041107177734375
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0980936288833618
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.117270588874817
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0930697917938232
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1336179971694946
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1110997200012207
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.145999789237976
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0989538431167603
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.105137586593628
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1046712398529053
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.095217227935791
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1006029844284058
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0945173501968384
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1323504447937012
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1281001567840576
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1082134246826172
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.122503638267517
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1143656969070435
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1095802783966064
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0941896438598633
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0971653461456299
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1100536584854126
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1027902364730835
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0998166799545288
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0977116823196411
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.108788251876831
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.114214539527893
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0996463298797607
Baseline loss: 2.165649890899658
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0821833610534668
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1342592239379883
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0536620616912842
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1137100458145142
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0595734119415283
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1569150686264038
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0613117218017578
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0965209007263184
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.049174427986145
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1146228313446045
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0997637510299683
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1250135898590088
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0546993017196655
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1042028665542603
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0798367261886597
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1201907396316528
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0725749731063843
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.109058141708374
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.06338369846344
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.154278039932251
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0637449026107788
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1186463832855225
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.0565046072006226
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0886439085006714
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0477540493011475
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1290119886398315
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.070165991783142
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.100745677947998
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.046871304512024
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1277177333831787
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0823853015899658
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0961260795593262
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.061536192893982
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1367660760879517
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.0527372360229492
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1104044914245605
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.0523937940597534
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1098556518554688
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0606833696365356
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1283080577850342
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.057618260383606
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1063748598098755
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0472626686096191
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1008145809173584
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.056876540184021
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1179602146148682
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.130118727684021
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1156702041625977
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0525929927825928
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1032909154891968
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.068150281906128
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1054089069366455
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0667082071304321
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.091249704360962
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.0504299402236938
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1280497312545776
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.0728036165237427
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1782639026641846
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0736130475997925
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1000518798828125
Baseline loss: 2.165649890899658
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0743296146392822
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1321734189987183
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0501919984817505
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1219819784164429
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0571197271347046
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1076523065567017
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0586637258529663
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0997425317764282
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.05374014377594
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1085957288742065
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0535597801208496
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1093223094940186
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0537172555923462
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1111787557601929
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0527080297470093
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1093443632125854
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0528759956359863
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1015548706054688
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.0565941333770752
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1165692806243896
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0627915859222412
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1397199630737305
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.064412236213684
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.093827486038208
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0559818744659424
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1043556928634644
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.0521318912506104
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.112141489982605
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.0507608652114868
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.095380425453186
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0526405572891235
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1112223863601685
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.064095139503479
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1598074436187744
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.0512254238128662
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0929354429244995
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.054050326347351
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.101125717163086
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0512651205062866
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1084672212600708
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.059548020362854
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.100903868675232
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0585620403289795
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0996177196502686
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.0556787252426147
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1066113710403442
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.0604350566864014
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1025753021240234
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0535975694656372
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1046792268753052
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.0590401887893677
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.120725393295288
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0697963237762451
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0945326089859009
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.055637001991272
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1085169315338135
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.0617778301239014
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.103326678276062
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0570462942123413
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0955324172973633
Baseline loss: 2.165649890899658
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/UBER2015-jan-june-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0602219104766846
Baseline loss: 1.0902918577194214
########
Epoch: 2
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0635286569595337
Baseline loss: 1.0902918577194214
########
Epoch: 3
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0673248767852783
Baseline loss: 1.0902918577194214
########
Epoch: 4
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0491584539413452
Baseline loss: 1.0902918577194214
########
Epoch: 5
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0651414394378662
Baseline loss: 1.0902918577194214
########
Epoch: 6
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0560117959976196
Baseline loss: 1.0902918577194214
########
Epoch: 7
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0719897747039795
Baseline loss: 1.0902918577194214
########
Epoch: 8
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0656933784484863
Baseline loss: 1.0902918577194214
########
Epoch: 9
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0909703969955444
Baseline loss: 1.0902918577194214
########
Epoch: 10
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0466629266738892
Baseline loss: 1.0902918577194214
########
Epoch: 11
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0514912605285645
Baseline loss: 1.0902918577194214
########
Epoch: 12
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0483909845352173
Baseline loss: 1.0902918577194214
########
Epoch: 13
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0586568117141724
Baseline loss: 1.0902918577194214
########
Epoch: 14
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0631028413772583
Baseline loss: 1.0902918577194214
########
Epoch: 15
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.047770619392395
Baseline loss: 1.0902918577194214
########
Epoch: 16
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0585514307022095
Baseline loss: 1.0902918577194214
########
Epoch: 17
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0659854412078857
Baseline loss: 1.0902918577194214
########
Epoch: 18
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0643349885940552
Baseline loss: 1.0902918577194214
########
Epoch: 19
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0680580139160156
Baseline loss: 1.0902918577194214
########
Epoch: 20
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0599486827850342
Baseline loss: 1.0902918577194214
########
Epoch: 21
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0526329278945923
Baseline loss: 1.0902918577194214
########
Epoch: 22
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0536969900131226
Baseline loss: 1.0902918577194214
########
Epoch: 23
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0457385778427124
Baseline loss: 1.0902918577194214
########
Epoch: 24
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0652945041656494
Baseline loss: 1.0902918577194214
########
Epoch: 25
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.067639946937561
Baseline loss: 1.0902918577194214
########
Epoch: 26
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0492609739303589
Baseline loss: 1.0902918577194214
########
Epoch: 27
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0616167783737183
Baseline loss: 1.0902918577194214
########
Epoch: 28
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0744086503982544
Baseline loss: 1.0902918577194214
########
Epoch: 29
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0536696910858154
Baseline loss: 1.0902918577194214
########
Epoch: 30
Meta Train Loss: 0.7527664303779602
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0458639860153198
Baseline loss: 1.0902918577194214
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7695360779762268
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0951292514801025
Baseline loss: 1.0902918577194214
########
Epoch: 2
Meta Train Loss: 0.7891549468040466
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.431565284729004
Baseline loss: 1.0902918577194214
########
Epoch: 3
Meta Train Loss: 0.7556909322738647
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0758153200149536
Baseline loss: 1.0902918577194214
########
Epoch: 4
Meta Train Loss: 0.7552600502967834
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0555644035339355
Baseline loss: 1.0902918577194214
########
Epoch: 5
Meta Train Loss: 0.7542182803153992
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0733169317245483
Baseline loss: 1.0902918577194214
########
Epoch: 6
Meta Train Loss: 0.7537789940834045
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0526436567306519
Baseline loss: 1.0902918577194214
########
Epoch: 7
Meta Train Loss: 0.7561211585998535
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0561028718948364
Baseline loss: 1.0902918577194214
########
Epoch: 8
Meta Train Loss: 0.7518582940101624
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0801671743392944
Baseline loss: 1.0902918577194214
########
Epoch: 9
Meta Train Loss: 0.7602806091308594
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0556280612945557
Baseline loss: 1.0902918577194214
########
Epoch: 10
Meta Train Loss: 0.7496705651283264
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0572274923324585
Baseline loss: 1.0902918577194214
########
Epoch: 11
Meta Train Loss: 0.7503301501274109
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0828938484191895
Baseline loss: 1.0902918577194214
########
Epoch: 12
Meta Train Loss: 0.7533316016197205
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0516533851623535
Baseline loss: 1.0902918577194214
########
Epoch: 13
Meta Train Loss: 0.7643177509307861
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0582563877105713
Baseline loss: 1.0902918577194214
########
Epoch: 14
Meta Train Loss: 0.7773575782775879
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.045663595199585
Baseline loss: 1.0902918577194214
########
Epoch: 15
Meta Train Loss: 0.7812002301216125
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0568536520004272
Baseline loss: 1.0902918577194214
########
Epoch: 16
Meta Train Loss: 0.7865203619003296
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.060472846031189
Baseline loss: 1.0902918577194214
########
Epoch: 17
Meta Train Loss: 0.7522814273834229
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.082948088645935
Baseline loss: 1.0902918577194214
########
Epoch: 18
Meta Train Loss: 0.7497303485870361
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0463478565216064
Baseline loss: 1.0902918577194214
########
Epoch: 19
Meta Train Loss: 0.755642831325531
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0916732549667358
Baseline loss: 1.0902918577194214
########
Epoch: 20
Meta Train Loss: 0.7838981747627258
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0520373582839966
Baseline loss: 1.0902918577194214
########
Epoch: 21
Meta Train Loss: 0.7791138887405396
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0546749830245972
Baseline loss: 1.0902918577194214
########
Epoch: 22
Meta Train Loss: 0.7584682703018188
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0528281927108765
Baseline loss: 1.0902918577194214
########
Epoch: 23
Meta Train Loss: 0.7519448399543762
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0582585334777832
Baseline loss: 1.0902918577194214
########
Epoch: 24
Meta Train Loss: 0.7554278373718262
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0480395555496216
Baseline loss: 1.0902918577194214
########
Epoch: 25
Meta Train Loss: 0.7529206275939941
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0489953756332397
Baseline loss: 1.0902918577194214
########
Epoch: 26
Meta Train Loss: 0.748448371887207
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.064041018486023
Baseline loss: 1.0902918577194214
########
Epoch: 27
Meta Train Loss: 0.7735782861709595
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0388365983963013
Baseline loss: 1.0902918577194214
########
Epoch: 28
Meta Train Loss: 0.7971953749656677
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0673415660858154
Baseline loss: 1.0902918577194214
########
Epoch: 29
Meta Train Loss: 0.7518766522407532
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0591435432434082
Baseline loss: 1.0902918577194214
########
Epoch: 30
Meta Train Loss: 0.7658934593200684
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0486191511154175
Baseline loss: 1.0902918577194214
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7738558650016785
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0679891109466553
Baseline loss: 1.0902918577194214
########
Epoch: 2
Meta Train Loss: 0.7495463490486145
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.048690915107727
Baseline loss: 1.0902918577194214
########
Epoch: 3
Meta Train Loss: 0.7475763559341431
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0427148342132568
Baseline loss: 1.0902918577194214
########
Epoch: 4
Meta Train Loss: 0.7549659609794617
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0578298568725586
Baseline loss: 1.0902918577194214
########
Epoch: 5
Meta Train Loss: 0.7606383562088013
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0753155946731567
Baseline loss: 1.0902918577194214
########
Epoch: 6
Meta Train Loss: 0.7555605173110962
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0418449640274048
Baseline loss: 1.0902918577194214
########
Epoch: 7
Meta Train Loss: 0.7576557993888855
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0414447784423828
Baseline loss: 1.0902918577194214
########
Epoch: 8
Meta Train Loss: 0.7655200362205505
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0626875162124634
Baseline loss: 1.0902918577194214
########
Epoch: 9
Meta Train Loss: 0.7555826902389526
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0603301525115967
Baseline loss: 1.0902918577194214
########
Epoch: 10
Meta Train Loss: 0.7491189241409302
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.070446491241455
Baseline loss: 1.0902918577194214
########
Epoch: 11
Meta Train Loss: 0.771784245967865
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.062058925628662
Baseline loss: 1.0902918577194214
########
Epoch: 12
Meta Train Loss: 0.7496249675750732
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0490435361862183
Baseline loss: 1.0902918577194214
########
Epoch: 13
Meta Train Loss: 0.750265896320343
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.05271577835083
Baseline loss: 1.0902918577194214
########
Epoch: 14
Meta Train Loss: 0.7466657161712646
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0669660568237305
Baseline loss: 1.0902918577194214
########
Epoch: 15
Meta Train Loss: 0.7507866621017456
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0513595342636108
Baseline loss: 1.0902918577194214
########
Epoch: 16
Meta Train Loss: 0.7812831401824951
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0634171962738037
Baseline loss: 1.0902918577194214
########
Epoch: 17
Meta Train Loss: 0.7509413361549377
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0507067441940308
Baseline loss: 1.0902918577194214
########
Epoch: 18
Meta Train Loss: 0.751289427280426
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0592327117919922
Baseline loss: 1.0902918577194214
########
Epoch: 19
Meta Train Loss: 0.7541250586509705
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0793015956878662
Baseline loss: 1.0902918577194214
########
Epoch: 20
Meta Train Loss: 0.7624146342277527
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0552144050598145
Baseline loss: 1.0902918577194214
########
Epoch: 21
Meta Train Loss: 0.7514449954032898
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0481600761413574
Baseline loss: 1.0902918577194214
########
Epoch: 22
Meta Train Loss: 0.7512688636779785
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0488144159317017
Baseline loss: 1.0902918577194214
########
Epoch: 23
Meta Train Loss: 0.7576669454574585
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0574276447296143
Baseline loss: 1.0902918577194214
########
Epoch: 24
Meta Train Loss: 0.7596147060394287
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0570344924926758
Baseline loss: 1.0902918577194214
########
Epoch: 25
Meta Train Loss: 0.7517039775848389
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.050862193107605
Baseline loss: 1.0902918577194214
########
Epoch: 26
Meta Train Loss: 0.7479735016822815
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0509603023529053
Baseline loss: 1.0902918577194214
########
Epoch: 27
Meta Train Loss: 0.7750765681266785
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.067692518234253
Baseline loss: 1.0902918577194214
########
Epoch: 28
Meta Train Loss: 0.7654155492782593
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0556167364120483
Baseline loss: 1.0902918577194214
########
Epoch: 29
Meta Train Loss: 0.7554627656936646
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.069396734237671
Baseline loss: 1.0902918577194214
########
Epoch: 30
Meta Train Loss: 0.7686852216720581
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0884361267089844
Baseline loss: 1.0902918577194214
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/green-taxi2020-dec-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9963375926017761
Baseline loss: 1.3143926858901978
########
Epoch: 2
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0008710622787476
Baseline loss: 1.3143926858901978
########
Epoch: 3
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9975753426551819
Baseline loss: 1.3143926858901978
########
Epoch: 4
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9658287763595581
Baseline loss: 1.3143926858901978
########
Epoch: 5
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.01213800907135
Baseline loss: 1.3143926858901978
########
Epoch: 6
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0063847303390503
Baseline loss: 1.3143926858901978
########
Epoch: 7
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9867820739746094
Baseline loss: 1.3143926858901978
########
Epoch: 8
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.005786418914795
Baseline loss: 1.3143926858901978
########
Epoch: 9
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9729074835777283
Baseline loss: 1.3143926858901978
########
Epoch: 10
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9676046371459961
Baseline loss: 1.3143926858901978
########
Epoch: 11
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9713563919067383
Baseline loss: 1.3143926858901978
########
Epoch: 12
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9743136167526245
Baseline loss: 1.3143926858901978
########
Epoch: 13
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9745839238166809
Baseline loss: 1.3143926858901978
########
Epoch: 14
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.977840781211853
Baseline loss: 1.3143926858901978
########
Epoch: 15
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9615957736968994
Baseline loss: 1.3143926858901978
########
Epoch: 16
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9786071181297302
Baseline loss: 1.3143926858901978
########
Epoch: 17
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9753668308258057
Baseline loss: 1.3143926858901978
########
Epoch: 18
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9882600903511047
Baseline loss: 1.3143926858901978
########
Epoch: 19
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9886925220489502
Baseline loss: 1.3143926858901978
########
Epoch: 20
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9784843325614929
Baseline loss: 1.3143926858901978
########
Epoch: 21
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9852612614631653
Baseline loss: 1.3143926858901978
########
Epoch: 22
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9676543474197388
Baseline loss: 1.3143926858901978
########
Epoch: 23
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9845811724662781
Baseline loss: 1.3143926858901978
########
Epoch: 24
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9769603610038757
Baseline loss: 1.3143926858901978
########
Epoch: 25
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9714055061340332
Baseline loss: 1.3143926858901978
########
Epoch: 26
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9762606024742126
Baseline loss: 1.3143926858901978
########
Epoch: 27
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9866335988044739
Baseline loss: 1.3143926858901978
########
Epoch: 28
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0026133060455322
Baseline loss: 1.3143926858901978
########
Epoch: 29
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9691370725631714
Baseline loss: 1.3143926858901978
########
Epoch: 30
Meta Train Loss: 0.7277271151542664
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9745845794677734
Baseline loss: 1.3143926858901978
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7213869690895081
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9698472023010254
Baseline loss: 1.3143926858901978
########
Epoch: 2
Meta Train Loss: 0.7226720452308655
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.7326232194900513
Baseline loss: 1.3143926858901978
########
Epoch: 3
Meta Train Loss: 0.7345890998840332
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0038655996322632
Baseline loss: 1.3143926858901978
########
Epoch: 4
Meta Train Loss: 0.7657725811004639
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9666661620140076
Baseline loss: 1.3143926858901978
########
Epoch: 5
Meta Train Loss: 0.7206544280052185
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.987764298915863
Baseline loss: 1.3143926858901978
########
Epoch: 6
Meta Train Loss: 0.720037043094635
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9845135807991028
Baseline loss: 1.3143926858901978
########
Epoch: 7
Meta Train Loss: 0.7424802780151367
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0000996589660645
Baseline loss: 1.3143926858901978
########
Epoch: 8
Meta Train Loss: 15.936379432678223
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9954583048820496
Baseline loss: 1.3143926858901978
########
Epoch: 9
Meta Train Loss: 0.7232559323310852
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9810611605644226
Baseline loss: 1.3143926858901978
########
Epoch: 10
Meta Train Loss: 0.7115176320075989
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9789468050003052
Baseline loss: 1.3143926858901978
########
Epoch: 11
Meta Train Loss: 0.7199938297271729
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.018496036529541
Baseline loss: 1.3143926858901978
########
Epoch: 12
Meta Train Loss: 0.7321534752845764
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.976320207118988
Baseline loss: 1.3143926858901978
########
Epoch: 13
Meta Train Loss: 0.713536262512207
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9734885692596436
Baseline loss: 1.3143926858901978
########
Epoch: 14
Meta Train Loss: 0.7242764234542847
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9732759594917297
Baseline loss: 1.3143926858901978
########
Epoch: 15
Meta Train Loss: 0.7378690838813782
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9779838919639587
Baseline loss: 1.3143926858901978
########
Epoch: 16
Meta Train Loss: 0.7091627717018127
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9855583906173706
Baseline loss: 1.3143926858901978
########
Epoch: 17
Meta Train Loss: 0.7237985134124756
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0038458108901978
Baseline loss: 1.3143926858901978
########
Epoch: 18
Meta Train Loss: 0.7464669942855835
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9672925472259521
Baseline loss: 1.3143926858901978
########
Epoch: 19
Meta Train Loss: 0.7226656079292297
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.003267765045166
Baseline loss: 1.3143926858901978
########
Epoch: 20
Meta Train Loss: 0.7260233163833618
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9943073987960815
Baseline loss: 1.3143926858901978
########
Epoch: 21
Meta Train Loss: 0.6984323263168335
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0350983142852783
Baseline loss: 1.3143926858901978
########
Epoch: 22
Meta Train Loss: 0.7176064252853394
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.984898567199707
Baseline loss: 1.3143926858901978
########
Epoch: 23
Meta Train Loss: 0.7493712306022644
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9951721429824829
Baseline loss: 1.3143926858901978
########
Epoch: 24
Meta Train Loss: 0.7322962880134583
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9722312688827515
Baseline loss: 1.3143926858901978
########
Epoch: 25
Meta Train Loss: 0.7181759476661682
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9920761585235596
Baseline loss: 1.3143926858901978
########
Epoch: 26
Meta Train Loss: 0.7532140016555786
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0195900201797485
Baseline loss: 1.3143926858901978
########
Epoch: 27
Meta Train Loss: 0.7320291996002197
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9587814211845398
Baseline loss: 1.3143926858901978
########
Epoch: 28
Meta Train Loss: 0.7131388783454895
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9900293946266174
Baseline loss: 1.3143926858901978
########
Epoch: 29
Meta Train Loss: 0.734982430934906
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.014455795288086
Baseline loss: 1.3143926858901978
########
Epoch: 30
Meta Train Loss: 0.7346609234809875
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9861131310462952
Baseline loss: 1.3143926858901978
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7000227570533752
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9746739864349365
Baseline loss: 1.3143926858901978
########
Epoch: 2
Meta Train Loss: 0.6877783536911011
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.99222731590271
Baseline loss: 1.3143926858901978
########
Epoch: 3
Meta Train Loss: 0.6934908032417297
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9776467084884644
Baseline loss: 1.3143926858901978
########
Epoch: 4
Meta Train Loss: 0.7182058095932007
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9708762764930725
Baseline loss: 1.3143926858901978
########
Epoch: 5
Meta Train Loss: 0.6951672434806824
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9994328022003174
Baseline loss: 1.3143926858901978
########
Epoch: 6
Meta Train Loss: 0.6956053376197815
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9692992568016052
Baseline loss: 1.3143926858901978
########
Epoch: 7
Meta Train Loss: 0.7221111059188843
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9903506636619568
Baseline loss: 1.3143926858901978
########
Epoch: 8
Meta Train Loss: 0.706489622592926
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9786064028739929
Baseline loss: 1.3143926858901978
########
Epoch: 9
Meta Train Loss: 0.71394944190979
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9822123646736145
Baseline loss: 1.3143926858901978
########
Epoch: 10
Meta Train Loss: 0.7062013745307922
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9937639832496643
Baseline loss: 1.3143926858901978
########
Epoch: 11
Meta Train Loss: 0.7247660160064697
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.010830283164978
Baseline loss: 1.3143926858901978
########
Epoch: 12
Meta Train Loss: 0.7280170917510986
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9757152199745178
Baseline loss: 1.3143926858901978
########
Epoch: 13
Meta Train Loss: 0.7144372463226318
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9786300659179688
Baseline loss: 1.3143926858901978
########
Epoch: 14
Meta Train Loss: 0.7287508845329285
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9722766280174255
Baseline loss: 1.3143926858901978
########
Epoch: 15
Meta Train Loss: 0.7236624956130981
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9811649918556213
Baseline loss: 1.3143926858901978
########
Epoch: 16
Meta Train Loss: 0.6928489208221436
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9905176758766174
Baseline loss: 1.3143926858901978
########
Epoch: 17
Meta Train Loss: 0.7035074830055237
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.994384765625
Baseline loss: 1.3143926858901978
########
Epoch: 18
Meta Train Loss: 0.7045438289642334
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9664269089698792
Baseline loss: 1.3143926858901978
########
Epoch: 19
Meta Train Loss: 0.7146440744400024
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0008875131607056
Baseline loss: 1.3143926858901978
########
Epoch: 20
Meta Train Loss: 0.699045717716217
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9748432040214539
Baseline loss: 1.3143926858901978
########
Epoch: 21
Meta Train Loss: 0.693148136138916
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0012279748916626
Baseline loss: 1.3143926858901978
########
Epoch: 22
Meta Train Loss: 0.7414671778678894
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9904221296310425
Baseline loss: 1.3143926858901978
########
Epoch: 23
Meta Train Loss: 0.7003028392791748
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9913852214813232
Baseline loss: 1.3143926858901978
########
Epoch: 24
Meta Train Loss: 0.7042986750602722
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9721620678901672
Baseline loss: 1.3143926858901978
########
Epoch: 25
Meta Train Loss: 0.6961984038352966
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.004201054573059
Baseline loss: 1.3143926858901978
########
Epoch: 26
Meta Train Loss: 0.6907786130905151
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0009920597076416
Baseline loss: 1.3143926858901978
########
Epoch: 27
Meta Train Loss: 0.709739089012146
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9586719870567322
Baseline loss: 1.3143926858901978
########
Epoch: 28
Meta Train Loss: 0.7000324726104736
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9895741939544678
Baseline loss: 1.3143926858901978
########
Epoch: 29
Meta Train Loss: 0.6913720369338989
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9873079061508179
Baseline loss: 1.3143926858901978
########
Epoch: 30
Meta Train Loss: 0.7027830481529236
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9774157404899597
Baseline loss: 1.3143926858901978
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/TLC2018-FHV-aug-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9453107118606567
Baseline loss: 0.40216851234436035
########
Epoch: 2
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.955443263053894
Baseline loss: 0.40216851234436035
########
Epoch: 3
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.957753598690033
Baseline loss: 0.40216851234436035
########
Epoch: 4
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9668060541152954
Baseline loss: 0.40216851234436035
########
Epoch: 5
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0172234773635864
Baseline loss: 0.40216851234436035
########
Epoch: 6
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9688103795051575
Baseline loss: 0.40216851234436035
########
Epoch: 7
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0260710716247559
Baseline loss: 0.40216851234436035
########
Epoch: 8
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.007433533668518
Baseline loss: 0.40216851234436035
########
Epoch: 9
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0427510738372803
Baseline loss: 0.40216851234436035
########
Epoch: 10
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9663025736808777
Baseline loss: 0.40216851234436035
########
Epoch: 11
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9725473523139954
Baseline loss: 0.40216851234436035
########
Epoch: 12
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9607909917831421
Baseline loss: 0.40216851234436035
########
Epoch: 13
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9931562542915344
Baseline loss: 0.40216851234436035
########
Epoch: 14
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9811091423034668
Baseline loss: 0.40216851234436035
########
Epoch: 15
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9547618627548218
Baseline loss: 0.40216851234436035
########
Epoch: 16
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9873046875
Baseline loss: 0.40216851234436035
########
Epoch: 17
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.063571572303772
Baseline loss: 0.40216851234436035
########
Epoch: 18
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.990180492401123
Baseline loss: 0.40216851234436035
########
Epoch: 19
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0473181009292603
Baseline loss: 0.40216851234436035
########
Epoch: 20
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9582319259643555
Baseline loss: 0.40216851234436035
########
Epoch: 21
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9565716981887817
Baseline loss: 0.40216851234436035
########
Epoch: 22
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9552108645439148
Baseline loss: 0.40216851234436035
########
Epoch: 23
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9545943140983582
Baseline loss: 0.40216851234436035
########
Epoch: 24
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9844356179237366
Baseline loss: 0.40216851234436035
########
Epoch: 25
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9829942584037781
Baseline loss: 0.40216851234436035
########
Epoch: 26
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.98363196849823
Baseline loss: 0.40216851234436035
########
Epoch: 27
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9903957843780518
Baseline loss: 0.40216851234436035
########
Epoch: 28
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9781564474105835
Baseline loss: 0.40216851234436035
########
Epoch: 29
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9625502228736877
Baseline loss: 0.40216851234436035
########
Epoch: 30
Meta Train Loss: 0.4326223134994507
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9554677605628967
Baseline loss: 0.40216851234436035
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4678148031234741
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.2228343486785889
Baseline loss: 0.40216851234436035
########
Epoch: 2
Meta Train Loss: 0.5787250995635986
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.7495062351226807
Baseline loss: 0.40216851234436035
########
Epoch: 3
Meta Train Loss: 0.6779929995536804
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.065148115158081
Baseline loss: 0.40216851234436035
########
Epoch: 4
Meta Train Loss: 0.5573462247848511
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9491864442825317
Baseline loss: 0.40216851234436035
########
Epoch: 5
Meta Train Loss: 0.41301605105400085
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9645485281944275
Baseline loss: 0.40216851234436035
########
Epoch: 6
Meta Train Loss: 0.6634877920150757
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9729584455490112
Baseline loss: 0.40216851234436035
########
Epoch: 7
Meta Train Loss: 0.5340431332588196
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9582865238189697
Baseline loss: 0.40216851234436035
########
Epoch: 8
Meta Train Loss: 0.7417507767677307
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0234557390213013
Baseline loss: 0.40216851234436035
########
Epoch: 9
Meta Train Loss: 0.6454363465309143
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0242040157318115
Baseline loss: 0.40216851234436035
########
Epoch: 10
Meta Train Loss: 0.41030916571617126
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9634360671043396
Baseline loss: 0.40216851234436035
########
Epoch: 11
Meta Train Loss: 0.747565746307373
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0097929239273071
Baseline loss: 0.40216851234436035
########
Epoch: 12
Meta Train Loss: 0.6226996183395386
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9907452464103699
Baseline loss: 0.40216851234436035
########
Epoch: 13
Meta Train Loss: 0.4897649884223938
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0053678750991821
Baseline loss: 0.40216851234436035
########
Epoch: 14
Meta Train Loss: 0.5306001305580139
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9558189511299133
Baseline loss: 0.40216851234436035
########
Epoch: 15
Meta Train Loss: 0.4688774347305298
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0101454257965088
Baseline loss: 0.40216851234436035
########
Epoch: 16
Meta Train Loss: 0.45599234104156494
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9763352870941162
Baseline loss: 0.40216851234436035
########
Epoch: 17
Meta Train Loss: 0.4973601996898651
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9664711356163025
Baseline loss: 0.40216851234436035
########
Epoch: 18
Meta Train Loss: 0.4180144965648651
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9766889810562134
Baseline loss: 0.40216851234436035
########
Epoch: 19
Meta Train Loss: 0.5616520047187805
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0493627786636353
Baseline loss: 0.40216851234436035
########
Epoch: 20
Meta Train Loss: 0.45882755517959595
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9732471108436584
Baseline loss: 0.40216851234436035
########
Epoch: 21
Meta Train Loss: 0.45042985677719116
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9839330315589905
Baseline loss: 0.40216851234436035
########
Epoch: 22
Meta Train Loss: 0.4315323829650879
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.022099256515503
Baseline loss: 0.40216851234436035
########
Epoch: 23
Meta Train Loss: 0.40783071517944336
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9718247652053833
Baseline loss: 0.40216851234436035
########
Epoch: 24
Meta Train Loss: 0.43686240911483765
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9635957479476929
Baseline loss: 0.40216851234436035
########
Epoch: 25
Meta Train Loss: 0.4076162576675415
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9665582180023193
Baseline loss: 0.40216851234436035
########
Epoch: 26
Meta Train Loss: 0.46825337409973145
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9549832940101624
Baseline loss: 0.40216851234436035
########
Epoch: 27
Meta Train Loss: 0.40669992566108704
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.945662796497345
Baseline loss: 0.40216851234436035
########
Epoch: 28
Meta Train Loss: 0.4511486887931824
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9906821846961975
Baseline loss: 0.40216851234436035
########
Epoch: 29
Meta Train Loss: 0.4744624197483063
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0550328493118286
Baseline loss: 0.40216851234436035
########
Epoch: 30
Meta Train Loss: 0.5909436345100403
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9742008447647095
Baseline loss: 0.40216851234436035
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.42301854491233826
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0329853296279907
Baseline loss: 0.40216851234436035
########
Epoch: 2
Meta Train Loss: 0.4350351095199585
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0732994079589844
Baseline loss: 0.40216851234436035
########
Epoch: 3
Meta Train Loss: 0.4988210201263428
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.012579083442688
Baseline loss: 0.40216851234436035
########
Epoch: 4
Meta Train Loss: 0.44972309470176697
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9471980929374695
Baseline loss: 0.40216851234436035
########
Epoch: 5
Meta Train Loss: 0.4079952538013458
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.973917543888092
Baseline loss: 0.40216851234436035
########
Epoch: 6
Meta Train Loss: 0.418271005153656
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9562434554100037
Baseline loss: 0.40216851234436035
########
Epoch: 7
Meta Train Loss: 0.4374740421772003
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9598063826560974
Baseline loss: 0.40216851234436035
########
Epoch: 8
Meta Train Loss: 0.5052711367607117
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9953357577323914
Baseline loss: 0.40216851234436035
########
Epoch: 9
Meta Train Loss: 0.4350695013999939
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9895509481430054
Baseline loss: 0.40216851234436035
########
Epoch: 10
Meta Train Loss: 0.41265928745269775
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9715547561645508
Baseline loss: 0.40216851234436035
########
Epoch: 11
Meta Train Loss: 0.5310134887695312
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9797496795654297
Baseline loss: 0.40216851234436035
########
Epoch: 12
Meta Train Loss: 0.5167967081069946
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9872668981552124
Baseline loss: 0.40216851234436035
########
Epoch: 13
Meta Train Loss: 0.4397164583206177
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.017103910446167
Baseline loss: 0.40216851234436035
########
Epoch: 14
Meta Train Loss: 0.5290045142173767
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9563425779342651
Baseline loss: 0.40216851234436035
########
Epoch: 15
Meta Train Loss: 0.40976712107658386
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9859769940376282
Baseline loss: 0.40216851234436035
########
Epoch: 16
Meta Train Loss: 0.5159159302711487
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9650464057922363
Baseline loss: 0.40216851234436035
########
Epoch: 17
Meta Train Loss: 0.4626215100288391
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9688016772270203
Baseline loss: 0.40216851234436035
########
Epoch: 18
Meta Train Loss: 0.4675957262516022
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9678815007209778
Baseline loss: 0.40216851234436035
########
Epoch: 19
Meta Train Loss: 0.4957347512245178
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0285927057266235
Baseline loss: 0.40216851234436035
########
Epoch: 20
Meta Train Loss: 0.41756975650787354
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9683214426040649
Baseline loss: 0.40216851234436035
########
Epoch: 21
Meta Train Loss: 0.40089428424835205
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9808151125907898
Baseline loss: 0.40216851234436035
########
Epoch: 22
Meta Train Loss: 0.4482549726963043
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0264027118682861
Baseline loss: 0.40216851234436035
########
Epoch: 23
Meta Train Loss: 0.43648862838745117
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9709852933883667
Baseline loss: 0.40216851234436035
########
Epoch: 24
Meta Train Loss: 0.4244401752948761
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9636752009391785
Baseline loss: 0.40216851234436035
########
Epoch: 25
Meta Train Loss: 0.44076526165008545
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.984776496887207
Baseline loss: 0.40216851234436035
########
Epoch: 26
Meta Train Loss: 0.5398529171943665
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9533808827400208
Baseline loss: 0.40216851234436035
########
Epoch: 27
Meta Train Loss: 0.44244059920310974
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9483551383018494
Baseline loss: 0.40216851234436035
########
Epoch: 28
Meta Train Loss: 0.4265536665916443
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9874849915504456
Baseline loss: 0.40216851234436035
########
Epoch: 29
Meta Train Loss: 0.40994980931282043
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.029316782951355
Baseline loss: 0.40216851234436035
########
Epoch: 30
Meta Train Loss: 0.5734513401985168
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9771209359169006
Baseline loss: 0.40216851234436035
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/citibike-tripdata-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9310452938079834
Baseline loss: 0.48034629225730896
########
Epoch: 2
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9543944597244263
Baseline loss: 0.48034629225730896
########
Epoch: 3
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9399284720420837
Baseline loss: 0.48034629225730896
########
Epoch: 4
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9353618025779724
Baseline loss: 0.48034629225730896
########
Epoch: 5
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9563382863998413
Baseline loss: 0.48034629225730896
########
Epoch: 6
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.937732458114624
Baseline loss: 0.48034629225730896
########
Epoch: 7
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9549800157546997
Baseline loss: 0.48034629225730896
########
Epoch: 8
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9369591474533081
Baseline loss: 0.48034629225730896
########
Epoch: 9
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 1.0009446144104004
Baseline loss: 0.48034629225730896
########
Epoch: 10
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9294389486312866
Baseline loss: 0.48034629225730896
########
Epoch: 11
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9454647898674011
Baseline loss: 0.48034629225730896
########
Epoch: 12
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9289617538452148
Baseline loss: 0.48034629225730896
########
Epoch: 13
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9283324480056763
Baseline loss: 0.48034629225730896
########
Epoch: 14
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9505253434181213
Baseline loss: 0.48034629225730896
########
Epoch: 15
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9270576238632202
Baseline loss: 0.48034629225730896
########
Epoch: 16
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9419501423835754
Baseline loss: 0.48034629225730896
########
Epoch: 17
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9441587328910828
Baseline loss: 0.48034629225730896
########
Epoch: 18
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9619842171669006
Baseline loss: 0.48034629225730896
########
Epoch: 19
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9456859230995178
Baseline loss: 0.48034629225730896
########
Epoch: 20
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9554364085197449
Baseline loss: 0.48034629225730896
########
Epoch: 21
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9376471638679504
Baseline loss: 0.48034629225730896
########
Epoch: 22
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9399755597114563
Baseline loss: 0.48034629225730896
########
Epoch: 23
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9363372325897217
Baseline loss: 0.48034629225730896
########
Epoch: 24
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.949735701084137
Baseline loss: 0.48034629225730896
########
Epoch: 25
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9437191486358643
Baseline loss: 0.48034629225730896
########
Epoch: 26
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9314925670623779
Baseline loss: 0.48034629225730896
########
Epoch: 27
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9396601915359497
Baseline loss: 0.48034629225730896
########
Epoch: 28
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9452577829360962
Baseline loss: 0.48034629225730896
########
Epoch: 29
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9340540170669556
Baseline loss: 0.48034629225730896
########
Epoch: 30
Meta Train Loss: 0.41858604550361633
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9296905398368835
Baseline loss: 0.48034629225730896
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.40633222460746765
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 1.0639379024505615
Baseline loss: 0.48034629225730896
########
Epoch: 2
Meta Train Loss: 0.3943619728088379
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9540975093841553
Baseline loss: 0.48034629225730896
########
Epoch: 3
Meta Train Loss: 0.5034315586090088
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 1.027422547340393
Baseline loss: 0.48034629225730896
########
Epoch: 4
Meta Train Loss: 0.4136964678764343
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.929602861404419
Baseline loss: 0.48034629225730896
########
Epoch: 5
Meta Train Loss: 0.4095744788646698
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.973371684551239
Baseline loss: 0.48034629225730896
########
Epoch: 6
Meta Train Loss: 0.3947409391403198
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9647092223167419
Baseline loss: 0.48034629225730896
########
Epoch: 7
Meta Train Loss: 0.41204866766929626
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.936892569065094
Baseline loss: 0.48034629225730896
########
Epoch: 8
Meta Train Loss: 0.3748241364955902
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9525218605995178
Baseline loss: 0.48034629225730896
########
Epoch: 9
Meta Train Loss: 0.472017765045166
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9608015418052673
Baseline loss: 0.48034629225730896
########
Epoch: 10
Meta Train Loss: 0.43215981125831604
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9694002866744995
Baseline loss: 0.48034629225730896
########
Epoch: 11
Meta Train Loss: 0.5044236183166504
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9508774280548096
Baseline loss: 0.48034629225730896
########
Epoch: 12
Meta Train Loss: 0.3625822365283966
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9531974792480469
Baseline loss: 0.48034629225730896
########
Epoch: 13
Meta Train Loss: 0.8088049292564392
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9400114417076111
Baseline loss: 0.48034629225730896
########
Epoch: 14
Meta Train Loss: 0.3794587552547455
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9434060454368591
Baseline loss: 0.48034629225730896
########
Epoch: 15
Meta Train Loss: 0.3705727458000183
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9378471374511719
Baseline loss: 0.48034629225730896
########
Epoch: 16
Meta Train Loss: 0.37802228331565857
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9440928101539612
Baseline loss: 0.48034629225730896
########
Epoch: 17
Meta Train Loss: 0.4783009886741638
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9764577150344849
Baseline loss: 0.48034629225730896
########
Epoch: 18
Meta Train Loss: 0.36899808049201965
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.959233283996582
Baseline loss: 0.48034629225730896
########
Epoch: 19
Meta Train Loss: 0.4061007797718048
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9345855712890625
Baseline loss: 0.48034629225730896
########
Epoch: 20
Meta Train Loss: 0.370257705450058
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9366188049316406
Baseline loss: 0.48034629225730896
########
Epoch: 21
Meta Train Loss: 0.3681870996952057
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9309946894645691
Baseline loss: 0.48034629225730896
########
Epoch: 22
Meta Train Loss: 0.381347119808197
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9388294816017151
Baseline loss: 0.48034629225730896
########
Epoch: 23
Meta Train Loss: 0.42695629596710205
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.947376549243927
Baseline loss: 0.48034629225730896
########
Epoch: 24
Meta Train Loss: 0.39922234416007996
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9296786785125732
Baseline loss: 0.48034629225730896
########
Epoch: 25
Meta Train Loss: 0.5051106810569763
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9418478608131409
Baseline loss: 0.48034629225730896
########
Epoch: 26
Meta Train Loss: 0.4471684396266937
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9515329599380493
Baseline loss: 0.48034629225730896
########
Epoch: 27
Meta Train Loss: 0.4214131236076355
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9239850044250488
Baseline loss: 0.48034629225730896
########
Epoch: 28
Meta Train Loss: 0.3779652714729309
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9611458778381348
Baseline loss: 0.48034629225730896
########
Epoch: 29
Meta Train Loss: 0.4415145814418793
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9735842347145081
Baseline loss: 0.48034629225730896
########
Epoch: 30
Meta Train Loss: 0.37151312828063965
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.944986879825592
Baseline loss: 0.48034629225730896
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4131309986114502
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9713170528411865
Baseline loss: 0.48034629225730896
########
Epoch: 2
Meta Train Loss: 0.3755651116371155
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9731579422950745
Baseline loss: 0.48034629225730896
########
Epoch: 3
Meta Train Loss: 0.42039597034454346
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9543716907501221
Baseline loss: 0.48034629225730896
########
Epoch: 4
Meta Train Loss: 0.4556018114089966
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.935751736164093
Baseline loss: 0.48034629225730896
########
Epoch: 5
Meta Train Loss: 0.369417667388916
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9563039541244507
Baseline loss: 0.48034629225730896
########
Epoch: 6
Meta Train Loss: 0.4153469204902649
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9414067268371582
Baseline loss: 0.48034629225730896
########
Epoch: 7
Meta Train Loss: 0.4329657554626465
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9376816153526306
Baseline loss: 0.48034629225730896
########
Epoch: 8
Meta Train Loss: 0.4243490695953369
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9497607350349426
Baseline loss: 0.48034629225730896
########
Epoch: 9
Meta Train Loss: 0.40309518575668335
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9356362819671631
Baseline loss: 0.48034629225730896
########
Epoch: 10
Meta Train Loss: 0.4596426784992218
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9590803384780884
Baseline loss: 0.48034629225730896
########
Epoch: 11
Meta Train Loss: 0.4408212900161743
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9470339417457581
Baseline loss: 0.48034629225730896
########
Epoch: 12
Meta Train Loss: 0.3917810618877411
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9416759610176086
Baseline loss: 0.48034629225730896
########
Epoch: 13
Meta Train Loss: 0.3822820484638214
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9354618191719055
Baseline loss: 0.48034629225730896
########
Epoch: 14
Meta Train Loss: 0.3879861533641815
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9320601224899292
Baseline loss: 0.48034629225730896
########
Epoch: 15
Meta Train Loss: 0.41131454706192017
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9440923929214478
Baseline loss: 0.48034629225730896
########
Epoch: 16
Meta Train Loss: 0.44158801436424255
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.943408191204071
Baseline loss: 0.48034629225730896
########
Epoch: 17
Meta Train Loss: 0.4118141531944275
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9726224541664124
Baseline loss: 0.48034629225730896
########
Epoch: 18
Meta Train Loss: 0.43879225850105286
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9402418732643127
Baseline loss: 0.48034629225730896
########
Epoch: 19
Meta Train Loss: 0.3881033957004547
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9345609545707703
Baseline loss: 0.48034629225730896
########
Epoch: 20
Meta Train Loss: 0.4158475995063782
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9411081075668335
Baseline loss: 0.48034629225730896
########
Epoch: 21
Meta Train Loss: 0.611396849155426
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9350535273551941
Baseline loss: 0.48034629225730896
########
Epoch: 22
Meta Train Loss: 0.3761201798915863
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.942227840423584
Baseline loss: 0.48034629225730896
########
Epoch: 23
Meta Train Loss: 0.4178260564804077
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9480940699577332
Baseline loss: 0.48034629225730896
########
Epoch: 24
Meta Train Loss: 0.38497573137283325
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9293603301048279
Baseline loss: 0.48034629225730896
########
Epoch: 25
Meta Train Loss: 0.4572718143463135
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9395520091056824
Baseline loss: 0.48034629225730896
########
Epoch: 26
Meta Train Loss: 0.38920432329177856
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9536590576171875
Baseline loss: 0.48034629225730896
########
Epoch: 27
Meta Train Loss: 0.3775656521320343
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9248316287994385
Baseline loss: 0.48034629225730896
########
Epoch: 28
Meta Train Loss: 0.40039753913879395
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9494903087615967
Baseline loss: 0.48034629225730896
########
Epoch: 29
Meta Train Loss: 0.4542178213596344
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9571391940116882
Baseline loss: 0.48034629225730896
########
Epoch: 30
Meta Train Loss: 0.40522345900535583
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9532210230827332
Baseline loss: 0.48034629225730896
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/yellow-taxi2020-nov-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0366718769073486
Baseline loss: 1.2131158113479614
########
Epoch: 2
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.086625576019287
Baseline loss: 1.2131158113479614
########
Epoch: 3
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0550134181976318
Baseline loss: 1.2131158113479614
########
Epoch: 4
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0583361387252808
Baseline loss: 1.2131158113479614
########
Epoch: 5
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.1054106950759888
Baseline loss: 1.2131158113479614
########
Epoch: 6
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0326271057128906
Baseline loss: 1.2131158113479614
########
Epoch: 7
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0537967681884766
Baseline loss: 1.2131158113479614
########
Epoch: 8
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0418413877487183
Baseline loss: 1.2131158113479614
########
Epoch: 9
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0327776670455933
Baseline loss: 1.2131158113479614
########
Epoch: 10
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.024689793586731
Baseline loss: 1.2131158113479614
########
Epoch: 11
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0565038919448853
Baseline loss: 1.2131158113479614
########
Epoch: 12
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0345754623413086
Baseline loss: 1.2131158113479614
########
Epoch: 13
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0326541662216187
Baseline loss: 1.2131158113479614
########
Epoch: 14
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0636926889419556
Baseline loss: 1.2131158113479614
########
Epoch: 15
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.025874137878418
Baseline loss: 1.2131158113479614
########
Epoch: 16
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0404787063598633
Baseline loss: 1.2131158113479614
########
Epoch: 17
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0526257753372192
Baseline loss: 1.2131158113479614
########
Epoch: 18
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0778603553771973
Baseline loss: 1.2131158113479614
########
Epoch: 19
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0475460290908813
Baseline loss: 1.2131158113479614
########
Epoch: 20
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0529223680496216
Baseline loss: 1.2131158113479614
########
Epoch: 21
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0387156009674072
Baseline loss: 1.2131158113479614
########
Epoch: 22
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0610191822052002
Baseline loss: 1.2131158113479614
########
Epoch: 23
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0263702869415283
Baseline loss: 1.2131158113479614
########
Epoch: 24
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0465264320373535
Baseline loss: 1.2131158113479614
########
Epoch: 25
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0421459674835205
Baseline loss: 1.2131158113479614
########
Epoch: 26
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0430538654327393
Baseline loss: 1.2131158113479614
########
Epoch: 27
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0570627450942993
Baseline loss: 1.2131158113479614
########
Epoch: 28
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0341860055923462
Baseline loss: 1.2131158113479614
########
Epoch: 29
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0310735702514648
Baseline loss: 1.2131158113479614
########
Epoch: 30
Meta Train Loss: 0.7864629030227661
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0448055267333984
Baseline loss: 1.2131158113479614
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.748188853263855
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.05934476852417
Baseline loss: 1.2131158113479614
########
Epoch: 2
Meta Train Loss: 0.748656153678894
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.5240657329559326
Baseline loss: 1.2131158113479614
########
Epoch: 3
Meta Train Loss: 0.7529058456420898
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0362101793289185
Baseline loss: 1.2131158113479614
########
Epoch: 4
Meta Train Loss: 0.7764702439308167
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.086622714996338
Baseline loss: 1.2131158113479614
########
Epoch: 5
Meta Train Loss: 0.7693936824798584
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.090636134147644
Baseline loss: 1.2131158113479614
########
Epoch: 6
Meta Train Loss: 0.7593335509300232
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.029465913772583
Baseline loss: 1.2131158113479614
########
Epoch: 7
Meta Train Loss: 0.7605047225952148
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0880118608474731
Baseline loss: 1.2131158113479614
########
Epoch: 8
Meta Train Loss: 0.7753800749778748
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.1190776824951172
Baseline loss: 1.2131158113479614
########
Epoch: 9
Meta Train Loss: 0.7641055583953857
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.064953327178955
Baseline loss: 1.2131158113479614
########
Epoch: 10
Meta Train Loss: 0.7593966722488403
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0360000133514404
Baseline loss: 1.2131158113479614
########
Epoch: 11
Meta Train Loss: 0.7802901268005371
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.071730136871338
Baseline loss: 1.2131158113479614
########
Epoch: 12
Meta Train Loss: 0.7665364146232605
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0766996145248413
Baseline loss: 1.2131158113479614
########
Epoch: 13
Meta Train Loss: 0.7605422735214233
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0349762439727783
Baseline loss: 1.2131158113479614
########
Epoch: 14
Meta Train Loss: 0.7552655935287476
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0350254774093628
Baseline loss: 1.2131158113479614
########
Epoch: 15
Meta Train Loss: 0.7669262886047363
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.016732096672058
Baseline loss: 1.2131158113479614
########
Epoch: 16
Meta Train Loss: 0.8135780692100525
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0800888538360596
Baseline loss: 1.2131158113479614
########
Epoch: 17
Meta Train Loss: 0.7621001601219177
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0918183326721191
Baseline loss: 1.2131158113479614
########
Epoch: 18
Meta Train Loss: 0.7544727325439453
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0309702157974243
Baseline loss: 1.2131158113479614
########
Epoch: 19
Meta Train Loss: 0.7844597101211548
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0320000648498535
Baseline loss: 1.2131158113479614
########
Epoch: 20
Meta Train Loss: 0.7499493956565857
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0496525764465332
Baseline loss: 1.2131158113479614
########
Epoch: 21
Meta Train Loss: 0.7561955451965332
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0357989072799683
Baseline loss: 1.2131158113479614
########
Epoch: 22
Meta Train Loss: 0.7975550293922424
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0750479698181152
Baseline loss: 1.2131158113479614
########
Epoch: 23
Meta Train Loss: 0.7847033143043518
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0661920309066772
Baseline loss: 1.2131158113479614
########
Epoch: 24
Meta Train Loss: 0.7825384140014648
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0444514751434326
Baseline loss: 1.2131158113479614
########
Epoch: 25
Meta Train Loss: 0.7879090905189514
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0352556705474854
Baseline loss: 1.2131158113479614
########
Epoch: 26
Meta Train Loss: 0.7628443837165833
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.084226131439209
Baseline loss: 1.2131158113479614
########
Epoch: 27
Meta Train Loss: 0.7545005679130554
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0211584568023682
Baseline loss: 1.2131158113479614
########
Epoch: 28
Meta Train Loss: 0.7578701376914978
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.036592721939087
Baseline loss: 1.2131158113479614
########
Epoch: 29
Meta Train Loss: 0.7561967372894287
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.050614356994629
Baseline loss: 1.2131158113479614
########
Epoch: 30
Meta Train Loss: 0.7530753016471863
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.068342685699463
Baseline loss: 1.2131158113479614
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7533121109008789
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0691179037094116
Baseline loss: 1.2131158113479614
########
Epoch: 2
Meta Train Loss: 0.7539911866188049
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0872313976287842
Baseline loss: 1.2131158113479614
########
Epoch: 3
Meta Train Loss: 0.756681501865387
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0268348455429077
Baseline loss: 1.2131158113479614
########
Epoch: 4
Meta Train Loss: 0.7764754295349121
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.040842890739441
Baseline loss: 1.2131158113479614
########
Epoch: 5
Meta Train Loss: 0.7779728770256042
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.1068981885910034
Baseline loss: 1.2131158113479614
########
Epoch: 6
Meta Train Loss: 0.7502172589302063
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.027034878730774
Baseline loss: 1.2131158113479614
########
Epoch: 7
Meta Train Loss: 0.7804247140884399
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0535839796066284
Baseline loss: 1.2131158113479614
########
Epoch: 8
Meta Train Loss: 0.7501673698425293
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0518404245376587
Baseline loss: 1.2131158113479614
########
Epoch: 9
Meta Train Loss: 0.7649105191230774
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0615853071212769
Baseline loss: 1.2131158113479614
########
Epoch: 10
Meta Train Loss: 0.7504299879074097
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0372782945632935
Baseline loss: 1.2131158113479614
########
Epoch: 11
Meta Train Loss: 0.7516471743583679
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0676467418670654
Baseline loss: 1.2131158113479614
########
Epoch: 12
Meta Train Loss: 0.7667174339294434
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.078593134880066
Baseline loss: 1.2131158113479614
########
Epoch: 13
Meta Train Loss: 0.7783111333847046
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0356680154800415
Baseline loss: 1.2131158113479614
########
Epoch: 14
Meta Train Loss: 0.758899986743927
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.032686710357666
Baseline loss: 1.2131158113479614
########
Epoch: 15
Meta Train Loss: 0.7718296051025391
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0353288650512695
Baseline loss: 1.2131158113479614
########
Epoch: 16
Meta Train Loss: 0.7831806540489197
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0798025131225586
Baseline loss: 1.2131158113479614
########
Epoch: 17
Meta Train Loss: 0.7619789838790894
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.090423345565796
Baseline loss: 1.2131158113479614
########
Epoch: 18
Meta Train Loss: 0.7751288414001465
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.040511131286621
Baseline loss: 1.2131158113479614
########
Epoch: 19
Meta Train Loss: 0.7545501589775085
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.027483344078064
Baseline loss: 1.2131158113479614
########
Epoch: 20
Meta Train Loss: 0.7657307386398315
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0440349578857422
Baseline loss: 1.2131158113479614
########
Epoch: 21
Meta Train Loss: 0.7519364356994629
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0354763269424438
Baseline loss: 1.2131158113479614
########
Epoch: 22
Meta Train Loss: 0.7530279755592346
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0424273014068604
Baseline loss: 1.2131158113479614
########
Epoch: 23
Meta Train Loss: 0.7579723000526428
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0643162727355957
Baseline loss: 1.2131158113479614
########
Epoch: 24
Meta Train Loss: 0.7525854706764221
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0344359874725342
Baseline loss: 1.2131158113479614
########
Epoch: 25
Meta Train Loss: 0.7536536455154419
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0280503034591675
Baseline loss: 1.2131158113479614
########
Epoch: 26
Meta Train Loss: 0.7525456547737122
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0761247873306274
Baseline loss: 1.2131158113479614
########
Epoch: 27
Meta Train Loss: 0.7533716559410095
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.018494963645935
Baseline loss: 1.2131158113479614
########
Epoch: 28
Meta Train Loss: 0.7614830136299133
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0366543531417847
Baseline loss: 1.2131158113479614
########
Epoch: 29
Meta Train Loss: 0.7487666606903076
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0576106309890747
Baseline loss: 1.2131158113479614
########
Epoch: 30
Meta Train Loss: 0.7518526911735535
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0660942792892456
Baseline loss: 1.2131158113479614
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/green-taxi2020-dec-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0454151630401611
Baseline loss: 1.7573487758636475
########
Epoch: 2
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.054240107536316
Baseline loss: 1.7573487758636475
########
Epoch: 3
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0490802526474
Baseline loss: 1.7573487758636475
########
Epoch: 4
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.025342345237732
Baseline loss: 1.7573487758636475
########
Epoch: 5
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.059691071510315
Baseline loss: 1.7573487758636475
########
Epoch: 6
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.059974193572998
Baseline loss: 1.7573487758636475
########
Epoch: 7
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.040667176246643
Baseline loss: 1.7573487758636475
########
Epoch: 8
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0529286861419678
Baseline loss: 1.7573487758636475
########
Epoch: 9
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.032329797744751
Baseline loss: 1.7573487758636475
########
Epoch: 10
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0260262489318848
Baseline loss: 1.7573487758636475
########
Epoch: 11
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.033437728881836
Baseline loss: 1.7573487758636475
########
Epoch: 12
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0338691473007202
Baseline loss: 1.7573487758636475
########
Epoch: 13
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0330017805099487
Baseline loss: 1.7573487758636475
########
Epoch: 14
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0356338024139404
Baseline loss: 1.7573487758636475
########
Epoch: 15
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0225048065185547
Baseline loss: 1.7573487758636475
########
Epoch: 16
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0403941869735718
Baseline loss: 1.7573487758636475
########
Epoch: 17
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0312072038650513
Baseline loss: 1.7573487758636475
########
Epoch: 18
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0488308668136597
Baseline loss: 1.7573487758636475
########
Epoch: 19
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0478335618972778
Baseline loss: 1.7573487758636475
########
Epoch: 20
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.03096604347229
Baseline loss: 1.7573487758636475
########
Epoch: 21
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0344651937484741
Baseline loss: 1.7573487758636475
########
Epoch: 22
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0205072164535522
Baseline loss: 1.7573487758636475
########
Epoch: 23
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0444375276565552
Baseline loss: 1.7573487758636475
########
Epoch: 24
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0281164646148682
Baseline loss: 1.7573487758636475
########
Epoch: 25
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.027720332145691
Baseline loss: 1.7573487758636475
########
Epoch: 26
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0263112783432007
Baseline loss: 1.7573487758636475
########
Epoch: 27
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0487480163574219
Baseline loss: 1.7573487758636475
########
Epoch: 28
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0532889366149902
Baseline loss: 1.7573487758636475
########
Epoch: 29
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.033581256866455
Baseline loss: 1.7573487758636475
########
Epoch: 30
Meta Train Loss: 0.959661066532135
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0334233045578003
Baseline loss: 1.7573487758636475
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9439001083374023
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0229920148849487
Baseline loss: 1.7573487758636475
########
Epoch: 2
Meta Train Loss: 0.9596731066703796
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.3734452724456787
Baseline loss: 1.7573487758636475
########
Epoch: 3
Meta Train Loss: 0.9611572623252869
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.058022141456604
Baseline loss: 1.7573487758636475
########
Epoch: 4
Meta Train Loss: 0.9629278779029846
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0238676071166992
Baseline loss: 1.7573487758636475
########
Epoch: 5
Meta Train Loss: 0.9414865970611572
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0489318370819092
Baseline loss: 1.7573487758636475
########
Epoch: 6
Meta Train Loss: 0.946387529373169
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0383870601654053
Baseline loss: 1.7573487758636475
########
Epoch: 7
Meta Train Loss: 0.9658421277999878
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0578017234802246
Baseline loss: 1.7573487758636475
########
Epoch: 8
Meta Train Loss: 15.441834449768066
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.046687126159668
Baseline loss: 1.7573487758636475
########
Epoch: 9
Meta Train Loss: 0.9604685306549072
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.035338044166565
Baseline loss: 1.7573487758636475
########
Epoch: 10
Meta Train Loss: 0.9430918097496033
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0339943170547485
Baseline loss: 1.7573487758636475
########
Epoch: 11
Meta Train Loss: 0.9567544460296631
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0657823085784912
Baseline loss: 1.7573487758636475
########
Epoch: 12
Meta Train Loss: 0.9641944766044617
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0321290493011475
Baseline loss: 1.7573487758636475
########
Epoch: 13
Meta Train Loss: 0.9450377821922302
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.031964898109436
Baseline loss: 1.7573487758636475
########
Epoch: 14
Meta Train Loss: 0.942523181438446
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0282249450683594
Baseline loss: 1.7573487758636475
########
Epoch: 15
Meta Train Loss: 0.9434471130371094
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0363842248916626
Baseline loss: 1.7573487758636475
########
Epoch: 16
Meta Train Loss: 0.9466812610626221
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.041320562362671
Baseline loss: 1.7573487758636475
########
Epoch: 17
Meta Train Loss: 0.9528883099555969
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0598641633987427
Baseline loss: 1.7573487758636475
########
Epoch: 18
Meta Train Loss: 0.9619710445404053
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0232954025268555
Baseline loss: 1.7573487758636475
########
Epoch: 19
Meta Train Loss: 0.9589772820472717
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0551085472106934
Baseline loss: 1.7573487758636475
########
Epoch: 20
Meta Train Loss: 0.9597713351249695
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.04715096950531
Baseline loss: 1.7573487758636475
########
Epoch: 21
Meta Train Loss: 0.9541307687759399
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0869864225387573
Baseline loss: 1.7573487758636475
########
Epoch: 22
Meta Train Loss: 0.9451663494110107
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0372705459594727
Baseline loss: 1.7573487758636475
########
Epoch: 23
Meta Train Loss: 0.9407734274864197
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0452157258987427
Baseline loss: 1.7573487758636475
########
Epoch: 24
Meta Train Loss: 0.9498821496963501
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0303446054458618
Baseline loss: 1.7573487758636475
########
Epoch: 25
Meta Train Loss: 0.9487767219543457
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0536848306655884
Baseline loss: 1.7573487758636475
########
Epoch: 26
Meta Train Loss: 1.0044394731521606
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0774762630462646
Baseline loss: 1.7573487758636475
########
Epoch: 27
Meta Train Loss: 0.9598460793495178
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0144835710525513
Baseline loss: 1.7573487758636475
########
Epoch: 28
Meta Train Loss: 0.9345187544822693
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0469368696212769
Baseline loss: 1.7573487758636475
########
Epoch: 29
Meta Train Loss: 0.963015615940094
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.056772232055664
Baseline loss: 1.7573487758636475
########
Epoch: 30
Meta Train Loss: 0.9670138955116272
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0369060039520264
Baseline loss: 1.7573487758636475
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9336915016174316
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.036478042602539
Baseline loss: 1.7573487758636475
########
Epoch: 2
Meta Train Loss: 0.9332631826400757
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0501874685287476
Baseline loss: 1.7573487758636475
########
Epoch: 3
Meta Train Loss: 0.9363110065460205
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0333709716796875
Baseline loss: 1.7573487758636475
########
Epoch: 4
Meta Train Loss: 0.9426813721656799
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0374577045440674
Baseline loss: 1.7573487758636475
########
Epoch: 5
Meta Train Loss: 0.9329583048820496
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0579856634140015
Baseline loss: 1.7573487758636475
########
Epoch: 6
Meta Train Loss: 0.9347769021987915
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.024692416191101
Baseline loss: 1.7573487758636475
########
Epoch: 7
Meta Train Loss: 0.9564796090126038
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0220202207565308
Baseline loss: 1.7573487758636475
########
Epoch: 8
Meta Train Loss: 0.9350483417510986
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0457727909088135
Baseline loss: 1.7573487758636475
########
Epoch: 9
Meta Train Loss: 0.943981945514679
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0335978269577026
Baseline loss: 1.7573487758636475
########
Epoch: 10
Meta Train Loss: 0.9361593127250671
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0405367612838745
Baseline loss: 1.7573487758636475
########
Epoch: 11
Meta Train Loss: 0.9546231627464294
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0586975812911987
Baseline loss: 1.7573487758636475
########
Epoch: 12
Meta Train Loss: 0.954096794128418
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0360066890716553
Baseline loss: 1.7573487758636475
########
Epoch: 13
Meta Train Loss: 0.945808470249176
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0409950017929077
Baseline loss: 1.7573487758636475
########
Epoch: 14
Meta Train Loss: 0.9544856548309326
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0504112243652344
Baseline loss: 1.7573487758636475
########
Epoch: 15
Meta Train Loss: 0.9485882520675659
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0346813201904297
Baseline loss: 1.7573487758636475
########
Epoch: 16
Meta Train Loss: 0.9366685748100281
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0504297018051147
Baseline loss: 1.7573487758636475
########
Epoch: 17
Meta Train Loss: 0.9413629770278931
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.034042477607727
Baseline loss: 1.7573487758636475
########
Epoch: 18
Meta Train Loss: 0.9386208653450012
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0368787050247192
Baseline loss: 1.7573487758636475
########
Epoch: 19
Meta Train Loss: 0.9474858641624451
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.1099923849105835
Baseline loss: 1.7573487758636475
########
Epoch: 20
Meta Train Loss: 0.9345893263816833
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0402417182922363
Baseline loss: 1.7573487758636475
########
Epoch: 21
Meta Train Loss: 0.9369910955429077
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0228729248046875
Baseline loss: 1.7573487758636475
########
Epoch: 22
Meta Train Loss: 0.9499397873878479
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0376920700073242
Baseline loss: 1.7573487758636475
########
Epoch: 23
Meta Train Loss: 0.9377662539482117
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0269442796707153
Baseline loss: 1.7573487758636475
########
Epoch: 24
Meta Train Loss: 0.9388242959976196
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0392221212387085
Baseline loss: 1.7573487758636475
########
Epoch: 25
Meta Train Loss: 0.9358313679695129
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0322434902191162
Baseline loss: 1.7573487758636475
########
Epoch: 26
Meta Train Loss: 0.9371134638786316
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.046634316444397
Baseline loss: 1.7573487758636475
########
Epoch: 27
Meta Train Loss: 0.9406492710113525
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.051025629043579
Baseline loss: 1.7573487758636475
########
Epoch: 28
Meta Train Loss: 0.9328481554985046
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0247782468795776
Baseline loss: 1.7573487758636475
########
Epoch: 29
Meta Train Loss: 0.9342227578163147
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0429798364639282
Baseline loss: 1.7573487758636475
########
Epoch: 30
Meta Train Loss: 0.9415821433067322
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0237175226211548
Baseline loss: 1.7573487758636475
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/citibike2014-tripdata-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.072902798652649
Baseline loss: 0.6341790556907654
########
Epoch: 2
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0806068181991577
Baseline loss: 0.6341790556907654
########
Epoch: 3
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.080249547958374
Baseline loss: 0.6341790556907654
########
Epoch: 4
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0710878372192383
Baseline loss: 0.6341790556907654
########
Epoch: 5
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0902965068817139
Baseline loss: 0.6341790556907654
########
Epoch: 6
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0752339363098145
Baseline loss: 0.6341790556907654
########
Epoch: 7
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1122311353683472
Baseline loss: 0.6341790556907654
########
Epoch: 8
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0897045135498047
Baseline loss: 0.6341790556907654
########
Epoch: 9
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1298496723175049
Baseline loss: 0.6341790556907654
########
Epoch: 10
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.073251485824585
Baseline loss: 0.6341790556907654
########
Epoch: 11
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0795921087265015
Baseline loss: 0.6341790556907654
########
Epoch: 12
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0770881175994873
Baseline loss: 0.6341790556907654
########
Epoch: 13
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.07351815700531
Baseline loss: 0.6341790556907654
########
Epoch: 14
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0834213495254517
Baseline loss: 0.6341790556907654
########
Epoch: 15
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.067530870437622
Baseline loss: 0.6341790556907654
########
Epoch: 16
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.090651273727417
Baseline loss: 0.6341790556907654
########
Epoch: 17
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0967669486999512
Baseline loss: 0.6341790556907654
########
Epoch: 18
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0925719738006592
Baseline loss: 0.6341790556907654
########
Epoch: 19
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.097568392753601
Baseline loss: 0.6341790556907654
########
Epoch: 20
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0912007093429565
Baseline loss: 0.6341790556907654
########
Epoch: 21
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0760492086410522
Baseline loss: 0.6341790556907654
########
Epoch: 22
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.067887783050537
Baseline loss: 0.6341790556907654
########
Epoch: 23
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0735021829605103
Baseline loss: 0.6341790556907654
########
Epoch: 24
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0833814144134521
Baseline loss: 0.6341790556907654
########
Epoch: 25
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.084457278251648
Baseline loss: 0.6341790556907654
########
Epoch: 26
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.069076657295227
Baseline loss: 0.6341790556907654
########
Epoch: 27
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0827915668487549
Baseline loss: 0.6341790556907654
########
Epoch: 28
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0840718746185303
Baseline loss: 0.6341790556907654
########
Epoch: 29
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.077873706817627
Baseline loss: 0.6341790556907654
########
Epoch: 30
Meta Train Loss: 0.5050252079963684
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.067356824874878
Baseline loss: 0.6341790556907654
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.5611751675605774
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.310204267501831
Baseline loss: 0.6341790556907654
########
Epoch: 2
Meta Train Loss: 0.5156754851341248
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1548898220062256
Baseline loss: 0.6341790556907654
########
Epoch: 3
Meta Train Loss: 1.9471592903137207
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.095882534980774
Baseline loss: 0.6341790556907654
########
Epoch: 4
Meta Train Loss: 0.51133793592453
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0747708082199097
Baseline loss: 0.6341790556907654
########
Epoch: 5
Meta Train Loss: 0.5048435926437378
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.121586561203003
Baseline loss: 0.6341790556907654
########
Epoch: 6
Meta Train Loss: 0.5041684508323669
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1162619590759277
Baseline loss: 0.6341790556907654
########
Epoch: 7
Meta Train Loss: 0.5104343891143799
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0844447612762451
Baseline loss: 0.6341790556907654
########
Epoch: 8
Meta Train Loss: 0.5107044577598572
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1039267778396606
Baseline loss: 0.6341790556907654
########
Epoch: 9
Meta Train Loss: 0.5216899514198303
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0954480171203613
Baseline loss: 0.6341790556907654
########
Epoch: 10
Meta Train Loss: 0.5046181082725525
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1141828298568726
Baseline loss: 0.6341790556907654
########
Epoch: 11
Meta Train Loss: 0.6720667481422424
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.096816062927246
Baseline loss: 0.6341790556907654
########
Epoch: 12
Meta Train Loss: 0.8668904900550842
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0750950574874878
Baseline loss: 0.6341790556907654
########
Epoch: 13
Meta Train Loss: 0.5053600668907166
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0822325944900513
Baseline loss: 0.6341790556907654
########
Epoch: 14
Meta Train Loss: 0.5091100931167603
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0652902126312256
Baseline loss: 0.6341790556907654
########
Epoch: 15
Meta Train Loss: 0.5329950451850891
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0718181133270264
Baseline loss: 0.6341790556907654
########
Epoch: 16
Meta Train Loss: 0.5047542452812195
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0762126445770264
Baseline loss: 0.6341790556907654
########
Epoch: 17
Meta Train Loss: 0.5090890526771545
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0835280418395996
Baseline loss: 0.6341790556907654
########
Epoch: 18
Meta Train Loss: 0.5995161533355713
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0761898756027222
Baseline loss: 0.6341790556907654
########
Epoch: 19
Meta Train Loss: 0.510637104511261
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.104337453842163
Baseline loss: 0.6341790556907654
########
Epoch: 20
Meta Train Loss: 0.6034973859786987
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0959041118621826
Baseline loss: 0.6341790556907654
########
Epoch: 21
Meta Train Loss: 0.5037638545036316
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.090636968612671
Baseline loss: 0.6341790556907654
########
Epoch: 22
Meta Train Loss: 0.7342971563339233
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0778725147247314
Baseline loss: 0.6341790556907654
########
Epoch: 23
Meta Train Loss: 0.5910499691963196
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0824947357177734
Baseline loss: 0.6341790556907654
########
Epoch: 24
Meta Train Loss: 0.5082099437713623
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0674176216125488
Baseline loss: 0.6341790556907654
########
Epoch: 25
Meta Train Loss: 0.500625729560852
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0743142366409302
Baseline loss: 0.6341790556907654
########
Epoch: 26
Meta Train Loss: 0.5069773197174072
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0905436277389526
Baseline loss: 0.6341790556907654
########
Epoch: 27
Meta Train Loss: 0.5118386149406433
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0610542297363281
Baseline loss: 0.6341790556907654
########
Epoch: 28
Meta Train Loss: 0.5803045630455017
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0903041362762451
Baseline loss: 0.6341790556907654
########
Epoch: 29
Meta Train Loss: 0.567918598651886
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.089272379875183
Baseline loss: 0.6341790556907654
########
Epoch: 30
Meta Train Loss: 0.5079928636550903
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0910643339157104
Baseline loss: 0.6341790556907654
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.5342611074447632
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1101771593093872
Baseline loss: 0.6341790556907654
########
Epoch: 2
Meta Train Loss: 0.5002351403236389
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1171504259109497
Baseline loss: 0.6341790556907654
########
Epoch: 3
Meta Train Loss: 0.5236742496490479
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0804251432418823
Baseline loss: 0.6341790556907654
########
Epoch: 4
Meta Train Loss: 0.5438938736915588
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0738416910171509
Baseline loss: 0.6341790556907654
########
Epoch: 5
Meta Train Loss: 0.5278061032295227
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0861754417419434
Baseline loss: 0.6341790556907654
########
Epoch: 6
Meta Train Loss: 0.503446638584137
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0760174989700317
Baseline loss: 0.6341790556907654
########
Epoch: 7
Meta Train Loss: 0.5084373354911804
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.078260064125061
Baseline loss: 0.6341790556907654
########
Epoch: 8
Meta Train Loss: 0.5137763023376465
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1007980108261108
Baseline loss: 0.6341790556907654
########
Epoch: 9
Meta Train Loss: 0.5090359449386597
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0760953426361084
Baseline loss: 0.6341790556907654
########
Epoch: 10
Meta Train Loss: 0.6040388345718384
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0993479490280151
Baseline loss: 0.6341790556907654
########
Epoch: 11
Meta Train Loss: 0.5757219791412354
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0926092863082886
Baseline loss: 0.6341790556907654
########
Epoch: 12
Meta Train Loss: 0.5344971418380737
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0687732696533203
Baseline loss: 0.6341790556907654
########
Epoch: 13
Meta Train Loss: 0.5130457282066345
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0799262523651123
Baseline loss: 0.6341790556907654
########
Epoch: 14
Meta Train Loss: 0.5169976949691772
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0639808177947998
Baseline loss: 0.6341790556907654
########
Epoch: 15
Meta Train Loss: 0.5315205454826355
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.09311044216156
Baseline loss: 0.6341790556907654
########
Epoch: 16
Meta Train Loss: 0.513117253780365
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.072319507598877
Baseline loss: 0.6341790556907654
########
Epoch: 17
Meta Train Loss: 0.5004711151123047
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0835962295532227
Baseline loss: 0.6341790556907654
########
Epoch: 18
Meta Train Loss: 0.5701476335525513
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0825061798095703
Baseline loss: 0.6341790556907654
########
Epoch: 19
Meta Train Loss: 0.5157800912857056
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0899592638015747
Baseline loss: 0.6341790556907654
########
Epoch: 20
Meta Train Loss: 0.5097832679748535
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0954217910766602
Baseline loss: 0.6341790556907654
########
Epoch: 21
Meta Train Loss: 0.531160295009613
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.078670620918274
Baseline loss: 0.6341790556907654
########
Epoch: 22
Meta Train Loss: 0.5902535915374756
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0841307640075684
Baseline loss: 0.6341790556907654
########
Epoch: 23
Meta Train Loss: 0.5771195292472839
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0818696022033691
Baseline loss: 0.6341790556907654
########
Epoch: 24
Meta Train Loss: 0.5210679173469543
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0672340393066406
Baseline loss: 0.6341790556907654
########
Epoch: 25
Meta Train Loss: 0.5097048878669739
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.074244499206543
Baseline loss: 0.6341790556907654
########
Epoch: 26
Meta Train Loss: 0.5584022998809814
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0878546237945557
Baseline loss: 0.6341790556907654
########
Epoch: 27
Meta Train Loss: 0.5003694891929626
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0602788925170898
Baseline loss: 0.6341790556907654
########
Epoch: 28
Meta Train Loss: 0.517591118812561
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0972102880477905
Baseline loss: 0.6341790556907654
########
Epoch: 29
Meta Train Loss: 0.5595663785934448
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.09654700756073
Baseline loss: 0.6341790556907654
########
Epoch: 30
Meta Train Loss: 0.5071027874946594
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0959969758987427
Baseline loss: 0.6341790556907654
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/citibike2014-tripdata-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0817017555236816
Baseline loss: 0.9803446531295776
########
Epoch: 2
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0935323238372803
Baseline loss: 0.9803446531295776
########
Epoch: 3
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0893805027008057
Baseline loss: 0.9803446531295776
########
Epoch: 4
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.078761339187622
Baseline loss: 0.9803446531295776
########
Epoch: 5
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0942258834838867
Baseline loss: 0.9803446531295776
########
Epoch: 6
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.082371473312378
Baseline loss: 0.9803446531295776
########
Epoch: 7
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1163780689239502
Baseline loss: 0.9803446531295776
########
Epoch: 8
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0963789224624634
Baseline loss: 0.9803446531295776
########
Epoch: 9
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1328141689300537
Baseline loss: 0.9803446531295776
########
Epoch: 10
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.079421043395996
Baseline loss: 0.9803446531295776
########
Epoch: 11
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0862817764282227
Baseline loss: 0.9803446531295776
########
Epoch: 12
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0844300985336304
Baseline loss: 0.9803446531295776
########
Epoch: 13
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.080804705619812
Baseline loss: 0.9803446531295776
########
Epoch: 14
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.092108964920044
Baseline loss: 0.9803446531295776
########
Epoch: 15
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0758062601089478
Baseline loss: 0.9803446531295776
########
Epoch: 16
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0980498790740967
Baseline loss: 0.9803446531295776
########
Epoch: 17
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1049312353134155
Baseline loss: 0.9803446531295776
########
Epoch: 18
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0989062786102295
Baseline loss: 0.9803446531295776
########
Epoch: 19
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1058965921401978
Baseline loss: 0.9803446531295776
########
Epoch: 20
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.097021222114563
Baseline loss: 0.9803446531295776
########
Epoch: 21
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.08706796169281
Baseline loss: 0.9803446531295776
########
Epoch: 22
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0794391632080078
Baseline loss: 0.9803446531295776
########
Epoch: 23
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.080159306526184
Baseline loss: 0.9803446531295776
########
Epoch: 24
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0920140743255615
Baseline loss: 0.9803446531295776
########
Epoch: 25
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0938078165054321
Baseline loss: 0.9803446531295776
########
Epoch: 26
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0780668258666992
Baseline loss: 0.9803446531295776
########
Epoch: 27
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.090666651725769
Baseline loss: 0.9803446531295776
########
Epoch: 28
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.097842812538147
Baseline loss: 0.9803446531295776
########
Epoch: 29
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.085241436958313
Baseline loss: 0.9803446531295776
########
Epoch: 30
Meta Train Loss: 0.6883649230003357
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0760109424591064
Baseline loss: 0.9803446531295776
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7196627259254456
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.2481682300567627
Baseline loss: 0.9803446531295776
########
Epoch: 2
Meta Train Loss: 0.6829947829246521
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.157675862312317
Baseline loss: 0.9803446531295776
########
Epoch: 3
Meta Train Loss: 1.4764620065689087
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1024233102798462
Baseline loss: 0.9803446531295776
########
Epoch: 4
Meta Train Loss: 0.6859608888626099
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0861504077911377
Baseline loss: 0.9803446531295776
########
Epoch: 5
Meta Train Loss: 0.6825620532035828
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.123551607131958
Baseline loss: 0.9803446531295776
########
Epoch: 6
Meta Train Loss: 0.6892924904823303
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.121962070465088
Baseline loss: 0.9803446531295776
########
Epoch: 7
Meta Train Loss: 0.6934213042259216
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0911813974380493
Baseline loss: 0.9803446531295776
########
Epoch: 8
Meta Train Loss: 0.6904783248901367
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1095669269561768
Baseline loss: 0.9803446531295776
########
Epoch: 9
Meta Train Loss: 0.6963441967964172
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1043422222137451
Baseline loss: 0.9803446531295776
########
Epoch: 10
Meta Train Loss: 0.6849973797798157
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1198869943618774
Baseline loss: 0.9803446531295776
########
Epoch: 11
Meta Train Loss: 0.7676584124565125
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1022921800613403
Baseline loss: 0.9803446531295776
########
Epoch: 12
Meta Train Loss: 0.9150833487510681
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.085634469985962
Baseline loss: 0.9803446531295776
########
Epoch: 13
Meta Train Loss: 0.6829513311386108
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0919994115829468
Baseline loss: 0.9803446531295776
########
Epoch: 14
Meta Train Loss: 0.6813308000564575
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0771487951278687
Baseline loss: 0.9803446531295776
########
Epoch: 15
Meta Train Loss: 0.6869397759437561
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0831706523895264
Baseline loss: 0.9803446531295776
########
Epoch: 16
Meta Train Loss: 0.6840130686759949
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.086768627166748
Baseline loss: 0.9803446531295776
########
Epoch: 17
Meta Train Loss: 0.6899026036262512
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0903797149658203
Baseline loss: 0.9803446531295776
########
Epoch: 18
Meta Train Loss: 0.7447291016578674
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0859571695327759
Baseline loss: 0.9803446531295776
########
Epoch: 19
Meta Train Loss: 0.6884487271308899
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.105892300605774
Baseline loss: 0.9803446531295776
########
Epoch: 20
Meta Train Loss: 0.7142394781112671
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1029233932495117
Baseline loss: 0.9803446531295776
########
Epoch: 21
Meta Train Loss: 0.6822797060012817
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0973243713378906
Baseline loss: 0.9803446531295776
########
Epoch: 22
Meta Train Loss: 0.7664798498153687
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0858484506607056
Baseline loss: 0.9803446531295776
########
Epoch: 23
Meta Train Loss: 0.7407550811767578
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0918322801589966
Baseline loss: 0.9803446531295776
########
Epoch: 24
Meta Train Loss: 0.6921327710151672
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.079324722290039
Baseline loss: 0.9803446531295776
########
Epoch: 25
Meta Train Loss: 0.6789298057556152
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0808464288711548
Baseline loss: 0.9803446531295776
########
Epoch: 26
Meta Train Loss: 0.6852938532829285
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.096713662147522
Baseline loss: 0.9803446531295776
########
Epoch: 27
Meta Train Loss: 0.6865725517272949
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0709116458892822
Baseline loss: 0.9803446531295776
########
Epoch: 28
Meta Train Loss: 0.7358208298683167
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0990846157073975
Baseline loss: 0.9803446531295776
########
Epoch: 29
Meta Train Loss: 0.7217801213264465
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.094852328300476
Baseline loss: 0.9803446531295776
########
Epoch: 30
Meta Train Loss: 0.6791683435440063
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0978642702102661
Baseline loss: 0.9803446531295776
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7154208421707153
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1177167892456055
Baseline loss: 0.9803446531295776
########
Epoch: 2
Meta Train Loss: 0.6792548894882202
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0817760229110718
Baseline loss: 0.9803446531295776
########
Epoch: 3
Meta Train Loss: 0.6959697604179382
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0792710781097412
Baseline loss: 0.9803446531295776
########
Epoch: 4
Meta Train Loss: 0.7121079564094543
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0881980657577515
Baseline loss: 0.9803446531295776
########
Epoch: 5
Meta Train Loss: 0.6962451934814453
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.083029866218567
Baseline loss: 0.9803446531295776
########
Epoch: 6
Meta Train Loss: 0.6814762353897095
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0938817262649536
Baseline loss: 0.9803446531295776
########
Epoch: 7
Meta Train Loss: 0.6840440630912781
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.080487847328186
Baseline loss: 0.9803446531295776
########
Epoch: 8
Meta Train Loss: 0.6858058571815491
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.090806007385254
Baseline loss: 0.9803446531295776
########
Epoch: 9
Meta Train Loss: 0.6833897829055786
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0830497741699219
Baseline loss: 0.9803446531295776
########
Epoch: 10
Meta Train Loss: 0.7415666580200195
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0767548084259033
Baseline loss: 0.9803446531295776
########
Epoch: 11
Meta Train Loss: 0.726625382900238
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0973889827728271
Baseline loss: 0.9803446531295776
########
Epoch: 12
Meta Train Loss: 0.7087224721908569
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.087415099143982
Baseline loss: 0.9803446531295776
########
Epoch: 13
Meta Train Loss: 0.6859667301177979
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0808719396591187
Baseline loss: 0.9803446531295776
########
Epoch: 14
Meta Train Loss: 0.6910095810890198
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.086744785308838
Baseline loss: 0.9803446531295776
########
Epoch: 15
Meta Train Loss: 0.6910749077796936
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.091209888458252
Baseline loss: 0.9803446531295776
########
Epoch: 16
Meta Train Loss: 0.6845051646232605
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0935572385787964
Baseline loss: 0.9803446531295776
########
Epoch: 17
Meta Train Loss: 0.6803569197654724
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0803786516189575
Baseline loss: 0.9803446531295776
########
Epoch: 18
Meta Train Loss: 0.7100889086723328
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0731379985809326
Baseline loss: 0.9803446531295776
########
Epoch: 19
Meta Train Loss: 0.6853834986686707
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0884546041488647
Baseline loss: 0.9803446531295776
########
Epoch: 20
Meta Train Loss: 0.6819353103637695
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0997885465621948
Baseline loss: 0.9803446531295776
########
Epoch: 21
Meta Train Loss: 0.6938254237174988
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.092996597290039
Baseline loss: 0.9803446531295776
########
Epoch: 22
Meta Train Loss: 0.7111725211143494
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0946086645126343
Baseline loss: 0.9803446531295776
########
Epoch: 23
Meta Train Loss: 0.7336966395378113
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.078717827796936
Baseline loss: 0.9803446531295776
########
Epoch: 24
Meta Train Loss: 0.6980706453323364
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0906827449798584
Baseline loss: 0.9803446531295776
########
Epoch: 25
Meta Train Loss: 0.6876736283302307
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0925170183181763
Baseline loss: 0.9803446531295776
########
Epoch: 26
Meta Train Loss: 0.7121220827102661
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1254453659057617
Baseline loss: 0.9803446531295776
########
Epoch: 27
Meta Train Loss: 0.6786227226257324
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.077182412147522
Baseline loss: 0.9803446531295776
########
Epoch: 28
Meta Train Loss: 0.6893028020858765
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.078703761100769
Baseline loss: 0.9803446531295776
########
Epoch: 29
Meta Train Loss: 0.7204022407531738
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0734198093414307
Baseline loss: 0.9803446531295776
########
Epoch: 30
Meta Train Loss: 0.6882292032241821
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1073497533798218
Baseline loss: 0.9803446531295776
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10567607: <compare> in cluster <dcc> Done

Job <compare> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Tue Oct  5 17:38:36 2021
Job was executed on host(s) <n-62-11-15>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Tue Oct  5 17:38:39 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Tue Oct  5 17:38:39 2021
Terminated at Tue Oct  5 18:28:48 2021
Results reported at Tue Oct  5 18:28:48 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J compare #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate


python /zhome/2b/7/117471/Thesis/src/models/compare_metalearning.py


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2994.18 sec.
    Max Memory :                                 3039 MB
    Average Memory :                             2766.92 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9249.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   3009 sec.
    Turnaround time :                            3012 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10567607> for stderr output of this job.

