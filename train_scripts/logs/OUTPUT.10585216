Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9860509634017944
########
Epoch: 2
Meta Train Loss: 0.9809404015541077
########
Epoch: 3
Meta Train Loss: 1.1150907278060913
########
Epoch: 4
Meta Train Loss: 1.1605970859527588
########
Epoch: 5
Meta Train Loss: 2.011263132095337
########
Epoch: 6
Meta Train Loss: 1.273455023765564
########
Epoch: 7
Meta Train Loss: 0.9517574906349182
########
Epoch: 8
Meta Train Loss: 1.089976191520691
########
Epoch: 9
Meta Train Loss: 1.3967366218566895
########
Epoch: 10
Meta Train Loss: 0.7821966409683228
########
Epoch: 11
Meta Train Loss: 1.0537934303283691
########
Epoch: 12
Meta Train Loss: 0.8572795391082764
########
Epoch: 13
Meta Train Loss: 0.9774702191352844
########
Epoch: 14
Meta Train Loss: 1.147437334060669
########
Epoch: 15
Meta Train Loss: 1.056757926940918
########
Epoch: 16
Meta Train Loss: 1.1529121398925781
########
Epoch: 17
Meta Train Loss: 1.4157294034957886
########
Epoch: 18
Meta Train Loss: 1.2215585708618164
########
Epoch: 19
Meta Train Loss: 1.0412695407867432
########
Epoch: 20
Meta Train Loss: 1.1306421756744385
########
Epoch: 21
Meta Train Loss: 0.9455707669258118
########
Epoch: 22
Meta Train Loss: 1.0748177766799927
########
Epoch: 23
Meta Train Loss: 0.826997697353363
########
Epoch: 24
Meta Train Loss: 1.0906542539596558
########
Epoch: 25
Meta Train Loss: 0.9389945268630981
########
Epoch: 26
Meta Train Loss: 1.0803399085998535
########
Epoch: 27
Meta Train Loss: 0.931778609752655
########
Epoch: 28
Meta Train Loss: 1.2340072393417358
########
Epoch: 29
Meta Train Loss: 0.9604296088218689
########
Epoch: 30
Meta Train Loss: 1.0522453784942627
########
Epoch: 31
Meta Train Loss: 1.1457685232162476
########
Epoch: 32
Meta Train Loss: 0.8034495115280151
########
Epoch: 33
Meta Train Loss: 1.0912809371948242
########
Epoch: 34
Meta Train Loss: 0.8595528602600098
########
Epoch: 35
Meta Train Loss: 0.7791278958320618
########
Epoch: 36
Meta Train Loss: 0.9650595188140869
########
Epoch: 37
Meta Train Loss: 0.7507159113883972
########
Epoch: 38
Meta Train Loss: 0.8104990720748901
########
Epoch: 39
Meta Train Loss: 0.9906914830207825
########
Epoch: 40
Meta Train Loss: 0.6990607976913452
########
Epoch: 41
Meta Train Loss: 0.7594701647758484
########
Epoch: 42
Meta Train Loss: 1.0222715139389038
########
Epoch: 43
Meta Train Loss: 0.6614556312561035
########
Epoch: 44
Meta Train Loss: 0.6429533362388611
########
Epoch: 45
Meta Train Loss: 1.338486671447754
########
Epoch: 46
Meta Train Loss: 1.008453369140625
########
Epoch: 47
Meta Train Loss: 0.8754153847694397
########
Epoch: 48
Meta Train Loss: 0.8759059309959412
########
Epoch: 49
Meta Train Loss: 0.7230534553527832
########
Epoch: 50
Meta Train Loss: 0.7775344252586365
########
Epoch: 51
Meta Train Loss: 0.6026330590248108
########
Epoch: 52
Meta Train Loss: 0.6613885164260864
########
Epoch: 53
Meta Train Loss: 0.6448679566383362
########
Epoch: 54
Meta Train Loss: 0.8681114315986633
########
Epoch: 55
Meta Train Loss: 0.814150333404541
########
Epoch: 56
Meta Train Loss: 0.7868669033050537
########
Epoch: 57
Meta Train Loss: 0.9130995869636536
########
Epoch: 58
Meta Train Loss: 0.6947844624519348
########
Epoch: 59
Meta Train Loss: 0.7477220296859741
########
Epoch: 60
Meta Train Loss: 0.6849568486213684
########
Epoch: 61
Meta Train Loss: 0.7293555736541748
########
Epoch: 62
Meta Train Loss: 0.687362551689148
########
Epoch: 63
Meta Train Loss: 1.068411946296692
########
Epoch: 64
Meta Train Loss: 0.7896711826324463
########
Epoch: 65
Meta Train Loss: 0.7977972626686096
########
Epoch: 66
Meta Train Loss: 0.7299365997314453
########
Epoch: 67
Meta Train Loss: 0.6750253438949585
########
Epoch: 68
Meta Train Loss: 0.8480361700057983
########
Epoch: 69
Meta Train Loss: 0.6118308901786804
########
Epoch: 70
Meta Train Loss: 0.7915694117546082
########
Epoch: 71
Meta Train Loss: 0.6660431623458862
########
Epoch: 72
Meta Train Loss: 0.6533942222595215
########
Epoch: 73
Meta Train Loss: 0.49795079231262207
########
Epoch: 74
Meta Train Loss: 0.6894752383232117
########
Epoch: 75
Meta Train Loss: 0.571950376033783
########
Epoch: 76
Meta Train Loss: 0.6713719367980957
########
Epoch: 77
Meta Train Loss: 0.8034379482269287
########
Epoch: 78
Meta Train Loss: 0.699605405330658
########
Epoch: 79
Meta Train Loss: 0.5601338744163513
########
Epoch: 80
Meta Train Loss: 0.4866175651550293
########
Epoch: 81
Meta Train Loss: 0.6455515027046204
########
Epoch: 82
Meta Train Loss: 0.757946789264679
########
Epoch: 83
Meta Train Loss: 0.8314419388771057
########
Epoch: 84
Meta Train Loss: 0.667208731174469
########
Epoch: 85
Meta Train Loss: 1.0365508794784546
########
Epoch: 86
Meta Train Loss: 0.6316403746604919
########
Epoch: 87
Meta Train Loss: 0.5821530222892761
########
Epoch: 88
Meta Train Loss: 0.89441978931427
########
Epoch: 89
Meta Train Loss: 0.5989107489585876
########
Epoch: 90
Meta Train Loss: 0.538347065448761
########
Epoch: 91
Meta Train Loss: 0.7354297041893005
########
Epoch: 92
Meta Train Loss: 0.7470995783805847
########
Epoch: 93
Meta Train Loss: 0.7458051443099976
########
Epoch: 94
Meta Train Loss: 0.4893542528152466
########
Epoch: 95
Meta Train Loss: 0.6991493105888367
########
Epoch: 96
Meta Train Loss: 0.48694777488708496
########
Epoch: 97
Meta Train Loss: 0.8711003065109253
########
Epoch: 98
Meta Train Loss: 0.6515579223632812
########
Epoch: 99
Meta Train Loss: 0.6284806132316589
########
Epoch: 100
Meta Train Loss: 0.7725748419761658
########
Epoch: 101
Meta Train Loss: 0.5604333281517029
########
Epoch: 102
Meta Train Loss: 0.5964386463165283
########
Epoch: 103
Meta Train Loss: 0.8869680166244507
########
Epoch: 104
Meta Train Loss: 0.7803109288215637
########
Epoch: 105
Meta Train Loss: 0.9669274091720581
########
Epoch: 106
Meta Train Loss: 0.8300297260284424
########
Epoch: 107
Meta Train Loss: 0.8297643661499023
########
Epoch: 108
Meta Train Loss: 0.6654061675071716
########
Epoch: 109
Meta Train Loss: 1.0553086996078491
########
Epoch: 110
Meta Train Loss: 0.5995681881904602
########
Epoch: 111
Meta Train Loss: 0.5758380889892578
########
Epoch: 112
Meta Train Loss: 0.5163034200668335
########
Epoch: 113
Meta Train Loss: 0.6838333010673523
########
Epoch: 114
Meta Train Loss: 0.5871351957321167
########
Epoch: 115
Meta Train Loss: 0.5613093972206116
########
Epoch: 116
Meta Train Loss: 0.66448974609375
########
Epoch: 117
Meta Train Loss: 0.797199547290802
########
Epoch: 118
Meta Train Loss: 1643.6702880859375
########
Epoch: 119
Meta Train Loss: 0.7845883369445801
########
Epoch: 120
Meta Train Loss: 0.5464354157447815
########
Epoch: 121
Meta Train Loss: 0.5892962217330933
########
Epoch: 122
Meta Train Loss: 1.0437262058258057
########
Epoch: 123
Meta Train Loss: 0.7523974776268005
########
Epoch: 124
Meta Train Loss: 0.6026807427406311
########
Epoch: 125
Meta Train Loss: 0.6718437671661377
########
Epoch: 126
Meta Train Loss: 0.7357415556907654
########
Epoch: 127
Meta Train Loss: 0.5246840119361877
########
Epoch: 128
Meta Train Loss: 0.6527512073516846
########
Epoch: 129
Meta Train Loss: 0.5016858577728271
########
Epoch: 130
Meta Train Loss: 0.7115837931632996
########
Epoch: 131
Meta Train Loss: 0.8876988887786865
########
Epoch: 132
Meta Train Loss: 0.6265568137168884
########
Epoch: 133
Meta Train Loss: 0.8783067464828491
########
Epoch: 134
Meta Train Loss: 0.9154843688011169
########
Epoch: 135
Meta Train Loss: 0.761601984500885
########
Epoch: 136
Meta Train Loss: 0.6981877684593201
########
Epoch: 137
Meta Train Loss: 0.6472139358520508
########
Epoch: 138
Meta Train Loss: 0.6654939651489258
########
Epoch: 139
Meta Train Loss: 0.6431128978729248
########
Epoch: 140
Meta Train Loss: 0.84168940782547
########
Epoch: 141
Meta Train Loss: 0.6053104400634766
########
Epoch: 142
Meta Train Loss: 0.8325551748275757
########
Epoch: 143
Meta Train Loss: 0.6452160477638245
########
Epoch: 144
Meta Train Loss: 0.8919097185134888
########
Epoch: 145
Meta Train Loss: 0.7815036177635193
########
Epoch: 146
Meta Train Loss: 0.5787762999534607
########
Epoch: 147
Meta Train Loss: 0.6329332590103149
########
Epoch: 148
Meta Train Loss: 0.7078383564949036
########
Epoch: 149
Meta Train Loss: 1.3168575763702393
########
Epoch: 150
Meta Train Loss: 0.5096597075462341
########
Epoch: 151
Meta Train Loss: 0.6098536252975464
########
Epoch: 152
Meta Train Loss: 0.6354702115058899
########
Epoch: 153
Meta Train Loss: 0.5752739310264587
########
Epoch: 154
Meta Train Loss: 0.6139853000640869
########
Epoch: 155
Meta Train Loss: 0.5350012183189392
########
Epoch: 156
Meta Train Loss: 0.8546468019485474
########
Epoch: 157
Meta Train Loss: 0.6214606761932373
########
Epoch: 158
Meta Train Loss: 0.7014050483703613
########
Epoch: 159
Meta Train Loss: 0.552402138710022
########
Epoch: 160
Meta Train Loss: 0.7442836761474609
########
Epoch: 161
Meta Train Loss: 0.5465572476387024
########
Epoch: 162
Meta Train Loss: 0.6821277737617493
########
Epoch: 163
Meta Train Loss: 0.7201387286186218
########
Epoch: 164
Meta Train Loss: 0.6690333485603333
########
Epoch: 165
Meta Train Loss: 0.6193461418151855
########
Epoch: 166
Meta Train Loss: 0.6872047781944275
########
Epoch: 167
Meta Train Loss: 0.6913378238677979
########
Epoch: 168
Meta Train Loss: 0.8476364612579346
########
Epoch: 169
Meta Train Loss: 0.8862076997756958
########
Epoch: 170
Meta Train Loss: 0.7740378975868225
########
Epoch: 171
Meta Train Loss: 0.7311868071556091
########
Epoch: 172
Meta Train Loss: 0.7711792588233948
########
Epoch: 173
Meta Train Loss: 0.6509666442871094
########
Epoch: 174
Meta Train Loss: 0.7486458420753479
########
Epoch: 175
Meta Train Loss: 0.6069693565368652
########
Epoch: 176
Meta Train Loss: 0.5820301175117493
########
Epoch: 177
Meta Train Loss: 0.6142998337745667
########
Epoch: 178
Meta Train Loss: 0.46426764130592346
########
Epoch: 179
Meta Train Loss: 0.7998983860015869
########
Epoch: 180
Meta Train Loss: 0.6015102863311768
########
Epoch: 181
Meta Train Loss: 0.6696646809577942
########
Epoch: 182
Meta Train Loss: 0.6092579960823059
########
Epoch: 183
Meta Train Loss: 0.592023491859436
########
Epoch: 184
Meta Train Loss: 0.6467053294181824
########
Epoch: 185
Meta Train Loss: 0.6682663559913635
########
Epoch: 186
Meta Train Loss: 0.4831336736679077
########
Epoch: 187
Meta Train Loss: 0.7106032967567444
########
Epoch: 188
Meta Train Loss: 4981.50390625
########
Epoch: 189
Meta Train Loss: 0.7853865623474121
########
Epoch: 190
Meta Train Loss: 0.7957106828689575
########
Epoch: 191
Meta Train Loss: 0.7820174098014832
########
Epoch: 192
Meta Train Loss: 0.6000946760177612
########
Epoch: 193
Meta Train Loss: 0.8238767385482788
########
Epoch: 194
Meta Train Loss: 0.5943348407745361
########
Epoch: 195
Meta Train Loss: 0.5217289924621582
########
Epoch: 196
Meta Train Loss: 0.47779959440231323
########
Epoch: 197
Meta Train Loss: 0.5414156913757324
########
Epoch: 198
Meta Train Loss: 0.9553811550140381
########
Epoch: 199
Meta Train Loss: 0.5832570791244507
########
Epoch: 200
Meta Train Loss: 0.7265161275863647
########
Epoch: 201
Meta Train Loss: 0.6285679340362549
########
Epoch: 202
Meta Train Loss: 0.5073354840278625
########
Epoch: 203
Meta Train Loss: 0.5203177332878113
########
Epoch: 204
Meta Train Loss: 0.6280376315116882
########
Epoch: 205
Meta Train Loss: 0.7105901837348938
########
Epoch: 206
Meta Train Loss: 0.6056106090545654
########
Epoch: 207
Meta Train Loss: 0.6411960124969482
########
Epoch: 208
Meta Train Loss: 0.5638287663459778
########
Epoch: 209
Meta Train Loss: 0.9405108094215393
########
Epoch: 210
Meta Train Loss: 0.7866655588150024
########
Epoch: 211
Meta Train Loss: 0.8663361668586731
########
Epoch: 212
Meta Train Loss: 0.8364312648773193
########
Epoch: 213
Meta Train Loss: 0.5312765836715698
########
Epoch: 214
Meta Train Loss: 0.8358021378517151
########
Epoch: 215
Meta Train Loss: 0.5870482325553894
########
Epoch: 216
Meta Train Loss: 0.48113393783569336
########
Epoch: 217
Meta Train Loss: 0.6477428078651428
########
Epoch: 218
Meta Train Loss: 0.5946621894836426
########
Epoch: 219
Meta Train Loss: 0.697889506816864
########
Epoch: 220
Meta Train Loss: 0.7188604474067688
########
Epoch: 221
Meta Train Loss: 0.9342229962348938
########
Epoch: 222
Meta Train Loss: 0.6295705437660217
########
Epoch: 223
Meta Train Loss: 0.5368232131004333
########
Epoch: 224
Meta Train Loss: 0.682234525680542
########
Epoch: 225
Meta Train Loss: 0.6513833403587341
########
Epoch: 226
Meta Train Loss: 0.97491055727005
########
Epoch: 227
Meta Train Loss: 0.6780922412872314
########
Epoch: 228
Meta Train Loss: 0.5904342532157898
########
Epoch: 229
Meta Train Loss: 0.8942509889602661
########
Epoch: 230
Meta Train Loss: 0.5494208335876465
########
Epoch: 231
Meta Train Loss: 0.507116436958313
########
Epoch: 232
Meta Train Loss: 0.6561776995658875
########
Epoch: 233
Meta Train Loss: 0.721433699131012
########
Epoch: 234
Meta Train Loss: 0.5602148175239563
########
Epoch: 235
Meta Train Loss: 0.5568749904632568
########
Epoch: 236
Meta Train Loss: 0.5876821875572205
########
Epoch: 237
Meta Train Loss: 0.7481125593185425
########
Epoch: 238
Meta Train Loss: 0.5532596111297607
########
Epoch: 239
Meta Train Loss: 0.8957752585411072
########
Epoch: 240
Meta Train Loss: 0.5030803680419922
########
Epoch: 241
Meta Train Loss: 0.7408266663551331
########
Epoch: 242
Meta Train Loss: 0.6519521474838257
########
Epoch: 243
Meta Train Loss: 0.4492074251174927
########
Epoch: 244
Meta Train Loss: 0.5897356867790222
########
Epoch: 245
Meta Train Loss: 0.9742344617843628
########
Epoch: 246
Meta Train Loss: 0.5423480272293091
########
Epoch: 247
Meta Train Loss: 0.768157958984375
########
Epoch: 248
Meta Train Loss: 0.6536192893981934
########
Epoch: 249
Meta Train Loss: 0.5830246210098267
########
Epoch: 250
Meta Train Loss: 0.8067678213119507
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10585216: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Sun Oct 10 15:29:51 2021
Job was executed on host(s) <n-62-11-16>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Sun Oct 10 15:29:53 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Sun Oct 10 15:29:53 2021
Terminated at Sun Oct 10 20:17:31 2021
Results reported at Sun Oct 10 20:17:31 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/metalearning
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=8
K_SHOT=5
ADAPTATION_STEPS=5
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=green
LOG_DIR=/zhome/2b/7/117471/Thesis/metalearning
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10


python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR --exclude $EXCLUDE \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --gpu






------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17210.50 sec.
    Max Memory :                                 4162 MB
    Average Memory :                             4148.04 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               8126.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   17258 sec.
    Turnaround time :                            17260 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10585216> for stderr output of this job.

