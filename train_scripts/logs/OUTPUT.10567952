Starting:
/zhome/2b/7/117471/Thesis/data/processed/metalearning/GM2017-july-sep-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4111352264881134
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5000623464584351
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.41340672969818115
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4844666123390198
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.41025635600090027
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4784853458404541
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.4103878140449524
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47531014680862427
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.41005367040634155
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4970892369747162
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.4093984365463257
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.469474196434021
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.40827468037605286
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5189172625541687
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.41198888421058655
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49407124519348145
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.41620904207229614
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5335704684257507
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.4128956198692322
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48072174191474915
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.4147462248802185
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4758172631263733
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.40940865874290466
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4851605296134949
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.4122450649738312
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4784858524799347
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.40980812907218933
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47432461380958557
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.4061717092990875
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47134241461753845
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.4085412919521332
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5049903988838196
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.39881473779678345
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5072422623634338
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.40629249811172485
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4812282621860504
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.41268083453178406
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4873937666416168
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.40885642170906067
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49281740188598633
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.411161869764328
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4845091998577118
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.4181750416755676
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4816265404224396
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.40929126739501953
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4743184745311737
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.40656331181526184
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4846685826778412
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.4100876748561859
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47903966903686523
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.4136137366294861
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4789533317089081
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.4082789123058319
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48261523246765137
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.41115856170654297
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4949943721294403
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.41415441036224365
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4925828278064728
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.4117123484611511
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.46394461393356323
Baseline loss: 0.1409626454114914
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.39968377351760864
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49582940340042114
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.3983292877674103
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5508971214294434
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.4124436676502228
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5225412249565125
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.4061157703399658
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47654348611831665
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.40773889422416687
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47745952010154724
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.4162787199020386
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4795515537261963
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.4132029414176941
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48611879348754883
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.4100002944469452
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5223568081855774
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.41952696442604065
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48434796929359436
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.40384775400161743
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4974564015865326
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.3984558880329132
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4793754518032074
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.39585432410240173
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4662284851074219
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.3966785669326782
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5028430223464966
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.39706042408943176
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47595134377479553
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.41478732228279114
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5040417313575745
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.3078976571559906
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4789747893810272
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.29994893074035645
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4729348421096802
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.3557693660259247
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47230586409568787
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.4046688377857208
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4934650659561157
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.40899449586868286
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5116437077522278
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.4273666739463806
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5011367797851562
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.40920546650886536
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4902609884738922
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.3947320282459259
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4930430054664612
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.4297609329223633
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.482526570558548
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.40821075439453125
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.472365140914917
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.42658767104148865
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5026812553405762
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.4265601336956024
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47582653164863586
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.40193119645118713
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5148394703865051
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.41596922278404236
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4918937385082245
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.3871868848800659
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48287519812583923
Baseline loss: 0.1409626454114914
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.3785255253314972
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49957892298698425
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.4070587158203125
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5223240256309509
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.38344836235046387
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48835521936416626
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.4031781256198883
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.477137953042984
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.3743785321712494
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4790436625480652
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.4301597476005554
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48297470808029175
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.43022313714027405
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49879202246665955
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.37682661414146423
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5226587057113647
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.4312755763530731
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4842454195022583
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.37488478422164917
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4960917830467224
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.3842150568962097
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48265811800956726
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.40768495202064514
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4656749963760376
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.38865917921066284
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5140843391418457
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.40300440788269043
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4758250415325165
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.4090563654899597
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.497368723154068
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.42449232935905457
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4769296944141388
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.35087913274765015
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4752136170864105
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.36911001801490784
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47185570001602173
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.409802109003067
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49954909086227417
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.4810105860233307
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5231876969337463
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.44258302450180054
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4966300427913666
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.39577165246009827
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4973560571670532
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.3630579710006714
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49603432416915894
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.46541738510131836
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4814005494117737
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.4071080982685089
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4733617603778839
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.40158265829086304
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5041012763977051
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.4627998173236847
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48254042863845825
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.3983977437019348
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5133796334266663
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.4412051737308502
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5201003551483154
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.3947509527206421
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47990575432777405
Baseline loss: 0.1409626454114914
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/yellow-taxi2020-nov-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.8597808480262756
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0602054595947266
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.8601611852645874
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0926148891448975
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.8608464598655701
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0628904104232788
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.8603500127792358
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0625269412994385
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.860205352306366
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1157408952713013
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.8607927560806274
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0428472757339478
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.8610062599182129
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0662412643432617
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.8617350459098816
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0550017356872559
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.8603389859199524
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0471121072769165
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.8611969351768494
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0393457412719727
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.8613664507865906
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.063838005065918
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.861083984375
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0340888500213623
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.8607388734817505
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0408155918121338
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.8604154586791992
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0786314010620117
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.8598842620849609
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0333483219146729
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.8603997826576233
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0454705953598022
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.8615532517433167
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.057149052619934
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.8607069849967957
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0864198207855225
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.8595564961433411
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0608311891555786
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.8601029515266418
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0575109720230103
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.8608411550521851
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0496501922607422
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.8602514863014221
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0695631504058838
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.8607062101364136
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0365374088287354
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.8602514266967773
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0505938529968262
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.8607439994812012
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.05605947971344
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.8613483309745789
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0448412895202637
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.8604841232299805
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0716156959533691
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.8601652383804321
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0489917993545532
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.860632061958313
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0460351705551147
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.8609489798545837
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.047742247581482
Baseline loss: 1.3998377323150635
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.8405269980430603
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0496842861175537
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.833570659160614
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1420890092849731
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.8864942193031311
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1293095350265503
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.8626360893249512
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0469056367874146
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.8366305232048035
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1184720993041992
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.8354912996292114
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0550049543380737
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.844871997833252
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0659602880477905
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.8713341355323792
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0534727573394775
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.8426117300987244
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0662565231323242
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.8438557386398315
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.04701566696167
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.8379965424537659
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0688050985336304
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.921264111995697
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0854638814926147
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.8715173006057739
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0554231405258179
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.8360328078269958
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0435770750045776
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.840435266494751
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0480198860168457
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.853907585144043
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0972297191619873
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.8331446051597595
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1127374172210693
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.8538804650306702
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0652210712432861
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.86021888256073
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0450823307037354
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.8448993563652039
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.058334469795227
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.8649125695228577
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0487873554229736
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.8363276124000549
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.051020622253418
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.8519649505615234
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.069000005722046
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.8860675692558289
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0295169353485107
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.8345568776130676
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0442306995391846
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 1.4291644096374512
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.094031810760498
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.8852814435958862
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0284620523452759
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.8733152151107788
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0870261192321777
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.8688123226165771
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0466021299362183
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.843177855014801
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0775030851364136
Baseline loss: 1.3998377323150635
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.8472748398780823
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0829435586929321
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.8394063711166382
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0559310913085938
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.8519629836082458
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0430779457092285
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.8581179976463318
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0405176877975464
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.8518109917640686
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0927625894546509
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.8386464715003967
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0374125242233276
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.8797000050544739
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0289314985275269
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.8601321578025818
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1227794885635376
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.841670036315918
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0806125402450562
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.8505768775939941
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0766140222549438
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.8434579968452454
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0768013000488281
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.8474107980728149
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0468487739562988
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.8398366570472717
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.061414122581482
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.8356801867485046
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.038912296295166
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.8411211967468262
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0575298070907593
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.8445383310317993
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0730899572372437
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.8405619263648987
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0875991582870483
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.8597825765609741
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0605103969573975
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.8431006669998169
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1180044412612915
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.8413268327713013
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0427236557006836
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.8372976183891296
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0395865440368652
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.832414448261261
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0477204322814941
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.8339901566505432
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0318351984024048
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.8393322229385376
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.046735167503357
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.8450727462768555
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.069571614265442
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.838754415512085
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0530803203582764
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.8509215116500854
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0680124759674072
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.8392785787582397
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0446078777313232
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.843731164932251
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.03676176071167
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.848125159740448
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.034545660018921
Baseline loss: 1.3998377323150635
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/LYFT2014-july-sep-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1729440689086914
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3907314538955688
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.1710282564163208
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3603090047836304
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.1729074716567993
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3582837581634521
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.1720092296600342
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3515127897262573
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.1714513301849365
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3833580017089844
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1729776859283447
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3447073698043823
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1726983785629272
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3740503787994385
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1731364727020264
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.357926368713379
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.1734447479248047
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.390346884727478
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.1708732843399048
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3467531204223633
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1729621887207031
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3577607870101929
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.1727266311645508
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.354710340499878
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.1720623970031738
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.35458505153656
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1720770597457886
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3558279275894165
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.1735576391220093
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3443986177444458
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1717311143875122
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.4029676914215088
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.1726415157318115
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.395033836364746
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1726263761520386
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3683007955551147
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1729063987731934
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3897863626480103
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.170992136001587
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3635687828063965
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.172074317932129
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3648954629898071
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1721261739730835
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3467817306518555
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.171083688735962
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3526368141174316
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.1729093790054321
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3613113164901733
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1727267503738403
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3648701906204224
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.1734014749526978
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3470736742019653
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 1.1713378429412842
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3594564199447632
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1717777252197266
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3612788915634155
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1719006299972534
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.365120530128479
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1722197532653809
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3495848178863525
Baseline loss: 1.6722253561019897
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1854828596115112
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.4592639207839966
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.1775976419448853
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3861843347549438
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.1816415786743164
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3756961822509766
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.1822208166122437
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3508816957473755
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.1748000383377075
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3734461069107056
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1766266822814941
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3727638721466064
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.2240983247756958
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3554638624191284
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1941533088684082
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3800841569900513
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.1876164674758911
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3473544120788574
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.1710511445999146
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3717830181121826
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1791691780090332
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3540902137756348
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.173271894454956
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3498579263687134
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.178528070449829
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3724749088287354
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 2.2327704429626465
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3458811044692993
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.175120234489441
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3690857887268066
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1752307415008545
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3579379320144653
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.2929397821426392
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3536628484725952
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.175869107246399
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3588173389434814
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1716591119766235
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3744186162948608
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1756142377853394
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3800125122070312
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.1740480661392212
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3630616664886475
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1773169040679932
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3596503734588623
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1921560764312744
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.361514687538147
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.1944234371185303
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.353232741355896
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.2038902044296265
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3521850109100342
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.1841949224472046
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.351438045501709
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 1.1833820343017578
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.342306137084961
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1807374954223633
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.398267149925232
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1822373867034912
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.365116000175476
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1859456300735474
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3587812185287476
Baseline loss: 1.6722253561019897
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1718790531158447
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3809905052185059
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.1818151473999023
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3994513750076294
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.1710178852081299
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3605856895446777
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.1763980388641357
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3510075807571411
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.2206790447235107
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3673124313354492
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1836919784545898
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3750331401824951
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1979081630706787
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3545258045196533
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1767507791519165
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3737519979476929
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.1799057722091675
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3582676649093628
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.1839818954467773
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3627777099609375
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1755447387695312
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3523058891296387
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.1737552881240845
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3496592044830322
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.1742949485778809
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3736796379089355
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1683987379074097
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3445556163787842
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.170952320098877
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3722596168518066
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1810026168823242
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3546932935714722
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.1852741241455078
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3553773164749146
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1891326904296875
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.359628438949585
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1772799491882324
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3629956245422363
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1729222536087036
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3812748193740845
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.186115026473999
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3682937622070312
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1981425285339355
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3737280368804932
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1754894256591797
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.363295078277588
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.187374234199524
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3547821044921875
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1726330518722534
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3494271039962769
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.187662124633789
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.350731611251831
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 1.1769458055496216
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3390064239501953
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1939260959625244
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3948729038238525
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1798648834228516
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3802077770233154
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1990832090377808
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3567067384719849
Baseline loss: 1.6722253561019897
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/UBER2015-jan-june-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7362603545188904
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1207146644592285
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7374098300933838
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1110891103744507
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7383195757865906
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1176964044570923
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 0.7393314242362976
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0965136289596558
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7359403371810913
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1138070821762085
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.737756073474884
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1075865030288696
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7373763918876648
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1230416297912598
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7373709678649902
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1143059730529785
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7371828556060791
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1433848142623901
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7365962862968445
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0973924398422241
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7374972701072693
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0984172821044922
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7374828457832336
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1016324758529663
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.737596869468689
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1076226234436035
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7378588318824768
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1112866401672363
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7373161911964417
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0987296104431152
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7376423478126526
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1057989597320557
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7381514310836792
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1175872087478638
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7377622723579407
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1119897365570068
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7368713617324829
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1222018003463745
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.7371601462364197
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1080526113510132
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.7370299100875854
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1013325452804565
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7375840544700623
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1032849550247192
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7374678254127502
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0997402667999268
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.737028181552887
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1131511926651
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7372826337814331
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1173523664474487
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7376350164413452
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1002087593078613
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7378398776054382
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1111433506011963
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.7374734878540039
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.124065637588501
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7377775311470032
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.100844383239746
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7370133996009827
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0957032442092896
Baseline loss: 0.9849832057952881
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7461568117141724
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.209950566291809
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7390244603157043
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1234345436096191
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7405471801757812
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.124436616897583
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 0.742235541343689
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1026806831359863
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7444968223571777
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1186864376068115
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.7411539554595947
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1136490106582642
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7500627040863037
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1004961729049683
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7401911616325378
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1177456378936768
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7366541028022766
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.125543236732483
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7436362504959106
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1418859958648682
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7585267424583435
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1241422891616821
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7408338785171509
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0965691804885864
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7723283767700195
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1014055013656616
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7651972770690918
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0978021621704102
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7655741572380066
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1130353212356567
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.736348569393158
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1068116426467896
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7389878630638123
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1179397106170654
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7517528533935547
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.111219882965088
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7348846793174744
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1075087785720825
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.749367356300354
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1124157905578613
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.759043276309967
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1060134172439575
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7482390999794006
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1011345386505127
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7400017380714417
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1063369512557983
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7400990724563599
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.100063443183899
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7389535903930664
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0947096347808838
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7343443036079407
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1084423065185547
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7389029860496521
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0876872539520264
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.7402781248092651
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1230788230895996
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7401600480079651
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.124055027961731
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7349749803543091
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.095679521560669
Baseline loss: 0.9849832057952881
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7454299926757812
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1159706115722656
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7387381792068481
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1256901025772095
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7412451505661011
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.111959457397461
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 0.7542241215705872
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1035248041152954
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7404970526695251
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1112834215164185
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.760276198387146
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1017149686813354
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7307984232902527
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.100744366645813
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7350268363952637
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1220345497131348
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7365264296531677
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1085721254348755
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7470938563346863
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1166905164718628
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.731947124004364
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1249737739562988
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7433574199676514
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0956288576126099
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7695364356040955
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0984885692596436
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7570083737373352
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0966941118240356
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.744851291179657
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.103823184967041
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7318103313446045
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1067273616790771
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7527797818183899
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1124720573425293
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7585273385047913
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0943621397018433
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7375434637069702
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1041488647460938
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.7385509610176086
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1067111492156982
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.738824188709259
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1055915355682373
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7493452429771423
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1013522148132324
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7378907203674316
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.105602502822876
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7498998045921326
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0964725017547607
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7453578114509583
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0950366258621216
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7464619874954224
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1070770025253296
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7449159026145935
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0883208513259888
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.7445780634880066
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1150175333023071
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7699370384216309
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.103812575340271
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7654702663421631
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.098034143447876
Baseline loss: 0.9849832057952881
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/TLC2018-FHV-aug-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.47522783279418945
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9797519445419312
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.4744403660297394
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9453082084655762
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.4754981994628906
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9479371905326843
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.4745486378669739
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9550113081932068
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.4753733277320862
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0044416189193726
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.4752810299396515
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9564976692199707
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.4749051630496979
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.009031057357788
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.47492173314094543
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9954693913459778
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.47517096996307373
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0281380414962769
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.4737127125263214
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9574024081230164
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.4746599793434143
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9619861245155334
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.4750949740409851
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9501329660415649
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.4749893248081207
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9817463755607605
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.47484534978866577
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9696744084358215
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.47524067759513855
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9418225288391113
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.4748542606830597
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9754971861839294
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.4753599762916565
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0453946590423584
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.47482261061668396
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9776596426963806
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.47482338547706604
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0296448469161987
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.4747365117073059
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9514533281326294
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.47444072365760803
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9471352100372314
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.47559261322021484
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9432124495506287
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.4750363528728485
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9464268684387207
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.47479841113090515
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9647202491760254
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.4749188721179962
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.971467912197113
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.47433972358703613
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9687157869338989
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.47533464431762695
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9798100590705872
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.47450798749923706
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9617366790771484
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.47483134269714355
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9602662324905396
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.4746415913105011
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9444335699081421
Baseline loss: 0.44635626673698425
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4848502278327942
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.1647918224334717
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.7393433451652527
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.5571317672729492
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.43164873123168945
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9454705715179443
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.5900681614875793
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9384558796882629
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.6794084906578064
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.005807876586914
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.7792737483978271
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9720283150672913
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.5110474228858948
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9454488754272461
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.4685478210449219
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0019229650497437
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.5484590530395508
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9643585085868835
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.6112711429595947
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9944292306900024
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.5072808265686035
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9523353576660156
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.4311099648475647
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9615997076034546
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.41296231746673584
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9749026894569397
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.4253404140472412
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9389191269874573
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.52668297290802
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0103683471679688
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.5556037425994873
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9623948335647583
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.6416425108909607
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9783579111099243
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.4544534385204315
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9637860059738159
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.4362853467464447
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9779205918312073
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.5029292106628418
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9616653323173523
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.4498208165168762
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9772511720657349
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.48560968041419983
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9909491539001465
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.42540863156318665
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9605243802070618
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.43027541041374207
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9500796794891357
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.5779054164886475
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9660745859146118
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.6110538244247437
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9487780928611755
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.7967328429222107
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.974125325679779
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.43752697110176086
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.980638325214386
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.4796772599220276
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0434669256210327
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.43984413146972656
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9500395059585571
Baseline loss: 0.44635626673698425
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4277894198894501
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.014567255973816
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.517184853553772
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0112756490707397
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.4287896156311035
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9928929805755615
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.47445371747016907
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9508916139602661
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.480230450630188
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0553414821624756
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.5652645826339722
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9531420469284058
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.467786580324173
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9388092756271362
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.4213113486766815
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.950235903263092
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.500541627407074
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.948189914226532
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.5350081920623779
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.976557731628418
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.4171208143234253
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9538206458091736
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.47963714599609375
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9514531493186951
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.4606333076953888
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9717197418212891
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.4747557044029236
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9789429306983948
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.4321177005767822
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9876335263252258
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.5521990656852722
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9951820969581604
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.4565953016281128
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9404088854789734
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.5774492621421814
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9780098795890808
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.42007723450660706
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9593981504440308
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.4455665051937103
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9517247080802917
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.5172477960586548
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9476781487464905
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.5183590650558472
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.957929253578186
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.5494611859321594
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9922211170196533
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.41417986154556274
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9501757621765137
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.4367254078388214
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9783845543861389
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.5161216855049133
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9794607162475586
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.5988028049468994
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.990658700466156
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.41217857599258423
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.956198513507843
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.42329081892967224
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9707983136177063
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.4487036168575287
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9608280658721924
Baseline loss: 0.44635626673698425
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/T-Drive-taxi-pickups-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1169676780700684
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1033960580825806
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.1156952381134033
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.102260708808899
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.118924856185913
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.094048023223877
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.115304708480835
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.091504693031311
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.124725341796875
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1102553606033325
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.113210916519165
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0884947776794434
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.1162333488464355
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.101867914199829
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.1164262294769287
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1023476123809814
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.11655855178833
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0900278091430664
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.1149742603302002
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0907670259475708
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.1150516271591187
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0998059511184692
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.11661696434021
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0937178134918213
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.116626501083374
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1055370569229126
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.122076392173767
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1026922464370728
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.1176319122314453
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0940206050872803
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.116989016532898
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1299424171447754
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.1129701137542725
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1071056127548218
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.1191351413726807
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0955921411514282
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.1161233186721802
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.099284291267395
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.1188013553619385
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1029016971588135
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.1195058822631836
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0959264039993286
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.119346261024475
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1036497354507446
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.115131139755249
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0971161127090454
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.112917423248291
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1077033281326294
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.1133074760437012
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1167100667953491
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.1184321641921997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0971938371658325
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.116835117340088
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1200549602508545
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.119102120399475
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0998395681381226
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.1181548833847046
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1106452941894531
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.1164919137954712
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0968297719955444
Baseline loss: 2.267239809036255
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1039013862609863
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.137162446975708
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.1116958856582642
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.163547396659851
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.091640830039978
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0813579559326172
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.1603927612304688
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1143726110458374
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.1387660503387451
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1265957355499268
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.1072266101837158
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0969895124435425
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.0990312099456787
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1123168468475342
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.090575098991394
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.12473726272583
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.0936404466629028
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0914517641067505
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.1167936325073242
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.108108639717102
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.126880168914795
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0971264839172363
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.0899815559387207
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1018460988998413
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.1497994661331177
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1126842498779297
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.1476104259490967
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0875614881515503
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.0978996753692627
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1281412839889526
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.1152228116989136
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1008244752883911
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.1055867671966553
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.094902515411377
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.0755066871643066
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1855090856552124
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.1169848442077637
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1042757034301758
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.1202183961868286
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1121412515640259
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.0987998247146606
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0912047624588013
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.1057443618774414
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.086858868598938
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.0996366739273071
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1158944368362427
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.1104471683502197
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0856801271438599
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.106502890586853
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0973159074783325
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.0741342306137085
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1073780059814453
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.1044843196868896
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0882339477539062
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.1163244247436523
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1835973262786865
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.081981897354126
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.117117166519165
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.0858607292175293
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1022160053253174
Baseline loss: 2.267239809036255
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0952941179275513
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0954452753067017
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.090990424156189
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1378706693649292
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.0888936519622803
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0921683311462402
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.0860612392425537
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1032873392105103
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.0854028463363647
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1394851207733154
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.0893522500991821
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.124976396560669
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.0950599908828735
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1014089584350586
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.095427393913269
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.112944483757019
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.1003714799880981
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0906823873519897
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.0970470905303955
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1066534519195557
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.0978972911834717
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0949866771697998
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.0864571332931519
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0952705144882202
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.1095757484436035
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1118648052215576
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.1238902807235718
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.087589144706726
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.0826950073242188
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.123077630996704
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.0936620235443115
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.108446717262268
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.084381103515625
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0901800394058228
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.0856231451034546
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1478456258773804
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.0853338241577148
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0939013957977295
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.079679250717163
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1146697998046875
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.1087850332260132
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.09250009059906
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.0849461555480957
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.091080904006958
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.087742567062378
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1063859462738037
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.0948545932769775
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0856781005859375
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.1114954948425293
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.097583293914795
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.0863871574401855
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1067603826522827
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.083304524421692
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.089792013168335
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.0832384824752808
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.128916621208191
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.092181921005249
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1265994310379028
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.0965114831924438
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0979288816452026
Baseline loss: 2.267239809036255
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/GM2017-july-sep-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0769404172897339
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1459522247314453
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.078513503074646
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1136236190795898
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0782573223114014
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1057531833648682
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0772318840026855
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0938323736190796
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.077470064163208
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.120296597480774
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.077405333518982
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0951488018035889
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0784552097320557
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1278715133666992
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0780184268951416
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1103978157043457
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0784298181533813
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1438705921173096
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.0776382684707642
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0994161367416382
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0774260759353638
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.103216290473938
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.0782018899917603
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1055701971054077
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.078580617904663
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.095596194267273
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.0783543586730957
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1010375022888184
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.0782206058502197
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.094043254852295
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0778485536575317
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.13009512424469
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.0790526866912842
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1240603923797607
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.078187346458435
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1078059673309326
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.0773931741714478
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1206154823303223
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0772227048873901
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1167938709259033
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.077846646308899
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1099032163619995
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0781056880950928
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0953917503356934
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.0775130987167358
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.095733642578125
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.077692985534668
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1071327924728394
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0782092809677124
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1035878658294678
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.0783518552780151
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.098132848739624
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0783543586730957
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1004389524459839
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.0779610872268677
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1053025722503662
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.078529715538025
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.116945505142212
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0773829221725464
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0986487865447998
Baseline loss: 2.165649890899658
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.08204185962677
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.133129596710205
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0579543113708496
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.2300331592559814
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0471397638320923
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1366699934005737
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.053951621055603
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0994521379470825
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.071555256843567
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.128429889678955
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0637272596359253
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1095046997070312
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0478585958480835
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1025347709655762
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0459868907928467
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1281782388687134
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0613327026367188
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.134225845336914
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.0504627227783203
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1137694120407104
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0579248666763306
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1077109575271606
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.054662823677063
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0925954580307007
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0532082319259644
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1059244871139526
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.0657260417938232
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0959042310714722
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.0721367597579956
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1438872814178467
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.1071161031723022
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1150126457214355
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.0980594158172607
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1009191274642944
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.0563899278640747
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1119894981384277
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.0729902982711792
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.109973430633545
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0562293529510498
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1346707344055176
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.0721960067749023
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1136865615844727
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.050732970237732
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0997700691223145
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.0726025104522705
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1082583665847778
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.0490726232528687
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1066677570343018
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0699684619903564
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1102616786956787
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.0701848268508911
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1042109727859497
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0596719980239868
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0949054956436157
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.0506075620651245
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1379427909851074
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.0528706312179565
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1174557209014893
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0689793825149536
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0974130630493164
Baseline loss: 2.165649890899658
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0737645626068115
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.133844256401062
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0570015907287598
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1322423219680786
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0527452230453491
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1037501096725464
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0539034605026245
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0959434509277344
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.051530122756958
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1065499782562256
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0621793270111084
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.113157868385315
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0555477142333984
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1158207654953003
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0497387647628784
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1093800067901611
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0629408359527588
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0966624021530151
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.053369402885437
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1158134937286377
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0593382120132446
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.111494541168213
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.0541110038757324
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0972315073013306
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0540554523468018
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0962450504302979
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.070451021194458
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.108331322669983
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.0589185953140259
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0901869535446167
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0718283653259277
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1082638502120972
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.0721911191940308
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1153603792190552
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.046730399131775
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.095453143119812
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.0535544157028198
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1028356552124023
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.057644248008728
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.115382194519043
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.0524754524230957
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1066253185272217
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0515722036361694
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1047956943511963
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.0615043640136719
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1054044961929321
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.0576815605163574
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1028929948806763
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0590453147888184
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1060978174209595
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.0581402778625488
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1144152879714966
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0632901191711426
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0958086252212524
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.0488476753234863
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1016621589660645
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.059299111366272
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1063848733901978
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0646412372589111
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0969703197479248
Baseline loss: 2.165649890899658
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/UBER2015-jan-june-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7525817155838013
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0724433660507202
Baseline loss: 1.0902918577194214
########
Epoch: 2
Meta Train Loss: 0.7528150081634521
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0656673908233643
Baseline loss: 1.0902918577194214
########
Epoch: 3
Meta Train Loss: 0.7528916001319885
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0682414770126343
Baseline loss: 1.0902918577194214
########
Epoch: 4
Meta Train Loss: 0.7532069683074951
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0492613315582275
Baseline loss: 1.0902918577194214
########
Epoch: 5
Meta Train Loss: 0.752543032169342
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0645802021026611
Baseline loss: 1.0902918577194214
########
Epoch: 6
Meta Train Loss: 0.7533888220787048
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0560325384140015
Baseline loss: 1.0902918577194214
########
Epoch: 7
Meta Train Loss: 0.7530115842819214
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0730705261230469
Baseline loss: 1.0902918577194214
########
Epoch: 8
Meta Train Loss: 0.7528422474861145
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0629889965057373
Baseline loss: 1.0902918577194214
########
Epoch: 9
Meta Train Loss: 0.7526516318321228
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0912193059921265
Baseline loss: 1.0902918577194214
########
Epoch: 10
Meta Train Loss: 0.753327488899231
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0490248203277588
Baseline loss: 1.0902918577194214
########
Epoch: 11
Meta Train Loss: 0.7532422542572021
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.048765778541565
Baseline loss: 1.0902918577194214
########
Epoch: 12
Meta Train Loss: 0.7528923153877258
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0504695177078247
Baseline loss: 1.0902918577194214
########
Epoch: 13
Meta Train Loss: 0.7532091736793518
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.056469440460205
Baseline loss: 1.0902918577194214
########
Epoch: 14
Meta Train Loss: 0.7531217932701111
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0626006126403809
Baseline loss: 1.0902918577194214
########
Epoch: 15
Meta Train Loss: 0.7535942196846008
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0460495948791504
Baseline loss: 1.0902918577194214
########
Epoch: 16
Meta Train Loss: 0.75290447473526
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0579020977020264
Baseline loss: 1.0902918577194214
########
Epoch: 17
Meta Train Loss: 0.7529269456863403
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.067181944847107
Baseline loss: 1.0902918577194214
########
Epoch: 18
Meta Train Loss: 0.7529457807540894
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0654367208480835
Baseline loss: 1.0902918577194214
########
Epoch: 19
Meta Train Loss: 0.753125786781311
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0675833225250244
Baseline loss: 1.0902918577194214
########
Epoch: 20
Meta Train Loss: 0.752496600151062
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0598533153533936
Baseline loss: 1.0902918577194214
########
Epoch: 21
Meta Train Loss: 0.7527106404304504
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.053584337234497
Baseline loss: 1.0902918577194214
########
Epoch: 22
Meta Train Loss: 0.7527462840080261
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.051732063293457
Baseline loss: 1.0902918577194214
########
Epoch: 23
Meta Train Loss: 0.7525731921195984
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0458219051361084
Baseline loss: 1.0902918577194214
########
Epoch: 24
Meta Train Loss: 0.7536265850067139
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0641252994537354
Baseline loss: 1.0902918577194214
########
Epoch: 25
Meta Train Loss: 0.7533807158470154
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.068597674369812
Baseline loss: 1.0902918577194214
########
Epoch: 26
Meta Train Loss: 0.7528852224349976
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0495109558105469
Baseline loss: 1.0902918577194214
########
Epoch: 27
Meta Train Loss: 0.7531704306602478
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0614169836044312
Baseline loss: 1.0902918577194214
########
Epoch: 28
Meta Train Loss: 0.7526350021362305
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0736936330795288
Baseline loss: 1.0902918577194214
########
Epoch: 29
Meta Train Loss: 0.7527813911437988
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0511994361877441
Baseline loss: 1.0902918577194214
########
Epoch: 30
Meta Train Loss: 0.7529260516166687
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0465657711029053
Baseline loss: 1.0902918577194214
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7696506381034851
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.096291184425354
Baseline loss: 1.0902918577194214
########
Epoch: 2
Meta Train Loss: 0.757493793964386
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0927186012268066
Baseline loss: 1.0902918577194214
########
Epoch: 3
Meta Train Loss: 0.7549563050270081
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0743752717971802
Baseline loss: 1.0902918577194214
########
Epoch: 4
Meta Train Loss: 0.7558872699737549
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0509871244430542
Baseline loss: 1.0902918577194214
########
Epoch: 5
Meta Train Loss: 0.7609314322471619
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0713562965393066
Baseline loss: 1.0902918577194214
########
Epoch: 6
Meta Train Loss: 0.7504902482032776
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0639102458953857
Baseline loss: 1.0902918577194214
########
Epoch: 7
Meta Train Loss: 0.7637140154838562
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0518674850463867
Baseline loss: 1.0902918577194214
########
Epoch: 8
Meta Train Loss: 0.7824831604957581
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0682311058044434
Baseline loss: 1.0902918577194214
########
Epoch: 9
Meta Train Loss: 0.751859724521637
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0728590488433838
Baseline loss: 1.0902918577194214
########
Epoch: 10
Meta Train Loss: 0.7558675408363342
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0921326875686646
Baseline loss: 1.0902918577194214
########
Epoch: 11
Meta Train Loss: 0.779867947101593
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.073987364768982
Baseline loss: 1.0902918577194214
########
Epoch: 12
Meta Train Loss: 0.7526571154594421
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0477608442306519
Baseline loss: 1.0902918577194214
########
Epoch: 13
Meta Train Loss: 0.7528415322303772
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0535022020339966
Baseline loss: 1.0902918577194214
########
Epoch: 14
Meta Train Loss: 0.7725123167037964
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0464832782745361
Baseline loss: 1.0902918577194214
########
Epoch: 15
Meta Train Loss: 0.7521375417709351
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.059931993484497
Baseline loss: 1.0902918577194214
########
Epoch: 16
Meta Train Loss: 0.7687540054321289
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.059026837348938
Baseline loss: 1.0902918577194214
########
Epoch: 17
Meta Train Loss: 0.7576268911361694
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.066166877746582
Baseline loss: 1.0902918577194214
########
Epoch: 18
Meta Train Loss: 0.765302300453186
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.067196249961853
Baseline loss: 1.0902918577194214
########
Epoch: 19
Meta Train Loss: 0.7519626617431641
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0554828643798828
Baseline loss: 1.0902918577194214
########
Epoch: 20
Meta Train Loss: 0.7540517449378967
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0568379163742065
Baseline loss: 1.0902918577194214
########
Epoch: 21
Meta Train Loss: 0.7761867642402649
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0522675514221191
Baseline loss: 1.0902918577194214
########
Epoch: 22
Meta Train Loss: 0.7521651387214661
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0485950708389282
Baseline loss: 1.0902918577194214
########
Epoch: 23
Meta Train Loss: 0.7740617990493774
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0585527420043945
Baseline loss: 1.0902918577194214
########
Epoch: 24
Meta Train Loss: 0.7471248507499695
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0538831949234009
Baseline loss: 1.0902918577194214
########
Epoch: 25
Meta Train Loss: 0.7446768879890442
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0469094514846802
Baseline loss: 1.0902918577194214
########
Epoch: 26
Meta Train Loss: 0.7529711723327637
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0624525547027588
Baseline loss: 1.0902918577194214
########
Epoch: 27
Meta Train Loss: 0.7515988349914551
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0385173559188843
Baseline loss: 1.0902918577194214
########
Epoch: 28
Meta Train Loss: 0.7488462328910828
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0783522129058838
Baseline loss: 1.0902918577194214
########
Epoch: 29
Meta Train Loss: 0.7568962574005127
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.076295256614685
Baseline loss: 1.0902918577194214
########
Epoch: 30
Meta Train Loss: 0.7480001449584961
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0458186864852905
Baseline loss: 1.0902918577194214
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7739080190658569
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0671825408935547
Baseline loss: 1.0902918577194214
########
Epoch: 2
Meta Train Loss: 0.7478922009468079
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.047316074371338
Baseline loss: 1.0902918577194214
########
Epoch: 3
Meta Train Loss: 0.7618122696876526
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0429553985595703
Baseline loss: 1.0902918577194214
########
Epoch: 4
Meta Train Loss: 0.7577056884765625
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0591548681259155
Baseline loss: 1.0902918577194214
########
Epoch: 5
Meta Train Loss: 0.7559533715248108
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0705722570419312
Baseline loss: 1.0902918577194214
########
Epoch: 6
Meta Train Loss: 0.7718786001205444
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0433839559555054
Baseline loss: 1.0902918577194214
########
Epoch: 7
Meta Train Loss: 0.7505385279655457
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0504943132400513
Baseline loss: 1.0902918577194214
########
Epoch: 8
Meta Train Loss: 0.7509007453918457
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0662922859191895
Baseline loss: 1.0902918577194214
########
Epoch: 9
Meta Train Loss: 0.7510811686515808
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0547889471054077
Baseline loss: 1.0902918577194214
########
Epoch: 10
Meta Train Loss: 0.7539027333259583
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0695983171463013
Baseline loss: 1.0902918577194214
########
Epoch: 11
Meta Train Loss: 0.7512494921684265
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.065561056137085
Baseline loss: 1.0902918577194214
########
Epoch: 12
Meta Train Loss: 0.7586356997489929
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0466440916061401
Baseline loss: 1.0902918577194214
########
Epoch: 13
Meta Train Loss: 0.7514858841896057
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0516356229782104
Baseline loss: 1.0902918577194214
########
Epoch: 14
Meta Train Loss: 0.7752187848091125
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0936319828033447
Baseline loss: 1.0902918577194214
########
Epoch: 15
Meta Train Loss: 0.7558332085609436
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0471049547195435
Baseline loss: 1.0902918577194214
########
Epoch: 16
Meta Train Loss: 0.7548107504844666
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0657891035079956
Baseline loss: 1.0902918577194214
########
Epoch: 17
Meta Train Loss: 0.7705881595611572
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.050702452659607
Baseline loss: 1.0902918577194214
########
Epoch: 18
Meta Train Loss: 0.7527984380722046
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0591177940368652
Baseline loss: 1.0902918577194214
########
Epoch: 19
Meta Train Loss: 0.7468678951263428
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0638928413391113
Baseline loss: 1.0902918577194214
########
Epoch: 20
Meta Train Loss: 0.7474288940429688
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0562238693237305
Baseline loss: 1.0902918577194214
########
Epoch: 21
Meta Train Loss: 0.7638559937477112
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0467380285263062
Baseline loss: 1.0902918577194214
########
Epoch: 22
Meta Train Loss: 0.7565534114837646
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0561023950576782
Baseline loss: 1.0902918577194214
########
Epoch: 23
Meta Train Loss: 0.7525381445884705
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0540446043014526
Baseline loss: 1.0902918577194214
########
Epoch: 24
Meta Train Loss: 0.7664374113082886
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.056174635887146
Baseline loss: 1.0902918577194214
########
Epoch: 25
Meta Train Loss: 0.749870240688324
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0478733777999878
Baseline loss: 1.0902918577194214
########
Epoch: 26
Meta Train Loss: 0.7546001076698303
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0470772981643677
Baseline loss: 1.0902918577194214
########
Epoch: 27
Meta Train Loss: 0.7546266317367554
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0649263858795166
Baseline loss: 1.0902918577194214
########
Epoch: 28
Meta Train Loss: 0.7508147954940796
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.058610200881958
Baseline loss: 1.0902918577194214
########
Epoch: 29
Meta Train Loss: 0.7953087687492371
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0722709894180298
Baseline loss: 1.0902918577194214
########
Epoch: 30
Meta Train Loss: 0.7805373072624207
Finetuned loss: 0.7097439765930176
Trained Edgeconv loss: 0.6776156425476074
Untrained Edgeconv loss: 1.0625594854354858
Baseline loss: 1.0902918577194214
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/green-taxi2020-dec-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7297097444534302
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.005937099456787
Baseline loss: 1.3143926858901978
########
Epoch: 2
Meta Train Loss: 0.7296804189682007
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9878692030906677
Baseline loss: 1.3143926858901978
########
Epoch: 3
Meta Train Loss: 0.7282136082649231
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9822454452514648
Baseline loss: 1.3143926858901978
########
Epoch: 4
Meta Train Loss: 0.7288491725921631
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9707282781600952
Baseline loss: 1.3143926858901978
########
Epoch: 5
Meta Train Loss: 0.7306994795799255
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9993497133255005
Baseline loss: 1.3143926858901978
########
Epoch: 6
Meta Train Loss: 0.7287635207176208
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0086344480514526
Baseline loss: 1.3143926858901978
########
Epoch: 7
Meta Train Loss: 0.7281749248504639
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9872210621833801
Baseline loss: 1.3143926858901978
########
Epoch: 8
Meta Train Loss: 0.7306065559387207
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0007619857788086
Baseline loss: 1.3143926858901978
########
Epoch: 9
Meta Train Loss: 0.7272979617118835
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9819663763046265
Baseline loss: 1.3143926858901978
########
Epoch: 10
Meta Train Loss: 0.7294397354125977
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9694119095802307
Baseline loss: 1.3143926858901978
########
Epoch: 11
Meta Train Loss: 0.7288247346878052
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9644598960876465
Baseline loss: 1.3143926858901978
########
Epoch: 12
Meta Train Loss: 0.7291312217712402
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9727301001548767
Baseline loss: 1.3143926858901978
########
Epoch: 13
Meta Train Loss: 0.7277007102966309
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9735335111618042
Baseline loss: 1.3143926858901978
########
Epoch: 14
Meta Train Loss: 0.7274228930473328
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9738370180130005
Baseline loss: 1.3143926858901978
########
Epoch: 15
Meta Train Loss: 0.7280983328819275
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9638127088546753
Baseline loss: 1.3143926858901978
########
Epoch: 16
Meta Train Loss: 0.7297404408454895
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9736412763595581
Baseline loss: 1.3143926858901978
########
Epoch: 17
Meta Train Loss: 0.7299728989601135
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9752446413040161
Baseline loss: 1.3143926858901978
########
Epoch: 18
Meta Train Loss: 0.7277937531471252
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9845246076583862
Baseline loss: 1.3143926858901978
########
Epoch: 19
Meta Train Loss: 0.730131208896637
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.992136538028717
Baseline loss: 1.3143926858901978
########
Epoch: 20
Meta Train Loss: 0.7309530377388
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9711553454399109
Baseline loss: 1.3143926858901978
########
Epoch: 21
Meta Train Loss: 0.7283166646957397
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9823482632637024
Baseline loss: 1.3143926858901978
########
Epoch: 22
Meta Train Loss: 0.7284313440322876
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9686161279678345
Baseline loss: 1.3143926858901978
########
Epoch: 23
Meta Train Loss: 0.7294095158576965
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9826732873916626
Baseline loss: 1.3143926858901978
########
Epoch: 24
Meta Train Loss: 0.727887749671936
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9729077816009521
Baseline loss: 1.3143926858901978
########
Epoch: 25
Meta Train Loss: 0.7277707457542419
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9658913016319275
Baseline loss: 1.3143926858901978
########
Epoch: 26
Meta Train Loss: 0.7283774018287659
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9726146459579468
Baseline loss: 1.3143926858901978
########
Epoch: 27
Meta Train Loss: 0.7303586006164551
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.003185510635376
Baseline loss: 1.3143926858901978
########
Epoch: 28
Meta Train Loss: 0.7295591831207275
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9967337846755981
Baseline loss: 1.3143926858901978
########
Epoch: 29
Meta Train Loss: 0.7284637689590454
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9780451059341431
Baseline loss: 1.3143926858901978
########
Epoch: 30
Meta Train Loss: 0.7301657199859619
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9717534184455872
Baseline loss: 1.3143926858901978
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7231075167655945
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9712895154953003
Baseline loss: 1.3143926858901978
########
Epoch: 2
Meta Train Loss: 0.73734050989151
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9939862489700317
Baseline loss: 1.3143926858901978
########
Epoch: 3
Meta Train Loss: 0.7210181951522827
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9929434061050415
Baseline loss: 1.3143926858901978
########
Epoch: 4
Meta Train Loss: 0.7428078651428223
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9937102794647217
Baseline loss: 1.3143926858901978
########
Epoch: 5
Meta Train Loss: 0.7241351008415222
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0843093395233154
Baseline loss: 1.3143926858901978
########
Epoch: 6
Meta Train Loss: 0.7210725545883179
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0039746761322021
Baseline loss: 1.3143926858901978
########
Epoch: 7
Meta Train Loss: 0.7141050100326538
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.987326979637146
Baseline loss: 1.3143926858901978
########
Epoch: 8
Meta Train Loss: 0.7413718700408936
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9875270128250122
Baseline loss: 1.3143926858901978
########
Epoch: 9
Meta Train Loss: 0.7238521575927734
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9851487278938293
Baseline loss: 1.3143926858901978
########
Epoch: 10
Meta Train Loss: 0.7273136973381042
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.036072850227356
Baseline loss: 1.3143926858901978
########
Epoch: 11
Meta Train Loss: 0.6971884965896606
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0552754402160645
Baseline loss: 1.3143926858901978
########
Epoch: 12
Meta Train Loss: 0.7483492493629456
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.998967170715332
Baseline loss: 1.3143926858901978
########
Epoch: 13
Meta Train Loss: 0.7149215936660767
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.981194794178009
Baseline loss: 1.3143926858901978
########
Epoch: 14
Meta Train Loss: 0.7345084547996521
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9694455862045288
Baseline loss: 1.3143926858901978
########
Epoch: 15
Meta Train Loss: 0.7329992055892944
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.990300178527832
Baseline loss: 1.3143926858901978
########
Epoch: 16
Meta Train Loss: 0.7397786974906921
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9843613505363464
Baseline loss: 1.3143926858901978
########
Epoch: 17
Meta Train Loss: 0.7246984839439392
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.005879521369934
Baseline loss: 1.3143926858901978
########
Epoch: 18
Meta Train Loss: 0.70942622423172
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9681921005249023
Baseline loss: 1.3143926858901978
########
Epoch: 19
Meta Train Loss: 1024.966064453125
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9767358899116516
Baseline loss: 1.3143926858901978
########
Epoch: 20
Meta Train Loss: 0.7267974615097046
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9752868413925171
Baseline loss: 1.3143926858901978
########
Epoch: 21
Meta Train Loss: 0.699230968952179
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0195064544677734
Baseline loss: 1.3143926858901978
########
Epoch: 22
Meta Train Loss: 0.7155930399894714
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9747918844223022
Baseline loss: 1.3143926858901978
########
Epoch: 23
Meta Train Loss: 0.7332854866981506
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.984727144241333
Baseline loss: 1.3143926858901978
########
Epoch: 24
Meta Train Loss: 0.7214030027389526
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9721989035606384
Baseline loss: 1.3143926858901978
########
Epoch: 25
Meta Train Loss: 0.7307255268096924
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0298575162887573
Baseline loss: 1.3143926858901978
########
Epoch: 26
Meta Train Loss: 0.7480136752128601
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9799497723579407
Baseline loss: 1.3143926858901978
########
Epoch: 27
Meta Train Loss: 0.7336626052856445
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9639137387275696
Baseline loss: 1.3143926858901978
########
Epoch: 28
Meta Train Loss: 0.7233996987342834
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0020520687103271
Baseline loss: 1.3143926858901978
########
Epoch: 29
Meta Train Loss: 0.7194873690605164
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.004185676574707
Baseline loss: 1.3143926858901978
########
Epoch: 30
Meta Train Loss: 0.7350665926933289
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.972149670124054
Baseline loss: 1.3143926858901978
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7049919962882996
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9822719693183899
Baseline loss: 1.3143926858901978
########
Epoch: 2
Meta Train Loss: 0.6940658688545227
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9816899299621582
Baseline loss: 1.3143926858901978
########
Epoch: 3
Meta Train Loss: 0.6962568759918213
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.979154109954834
Baseline loss: 1.3143926858901978
########
Epoch: 4
Meta Train Loss: 0.7249394059181213
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9705134034156799
Baseline loss: 1.3143926858901978
########
Epoch: 5
Meta Train Loss: 0.7139163017272949
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0000872611999512
Baseline loss: 1.3143926858901978
########
Epoch: 6
Meta Train Loss: 0.7250894904136658
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9808319211006165
Baseline loss: 1.3143926858901978
########
Epoch: 7
Meta Train Loss: 0.7125993967056274
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9910541772842407
Baseline loss: 1.3143926858901978
########
Epoch: 8
Meta Train Loss: 0.7259742617607117
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9995314478874207
Baseline loss: 1.3143926858901978
########
Epoch: 9
Meta Train Loss: 0.7006418108940125
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9850823879241943
Baseline loss: 1.3143926858901978
########
Epoch: 10
Meta Train Loss: 0.7184115648269653
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.012845516204834
Baseline loss: 1.3143926858901978
########
Epoch: 11
Meta Train Loss: 0.6923007369041443
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.012363314628601
Baseline loss: 1.3143926858901978
########
Epoch: 12
Meta Train Loss: 0.6997556090354919
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9779902696609497
Baseline loss: 1.3143926858901978
########
Epoch: 13
Meta Train Loss: 0.6996586918830872
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9806997179985046
Baseline loss: 1.3143926858901978
########
Epoch: 14
Meta Train Loss: 0.7110474109649658
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.968895435333252
Baseline loss: 1.3143926858901978
########
Epoch: 15
Meta Train Loss: 0.6944491863250732
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9806593060493469
Baseline loss: 1.3143926858901978
########
Epoch: 16
Meta Train Loss: 0.7453513741493225
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.981971263885498
Baseline loss: 1.3143926858901978
########
Epoch: 17
Meta Train Loss: 0.7159302234649658
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9983041286468506
Baseline loss: 1.3143926858901978
########
Epoch: 18
Meta Train Loss: 0.6918310523033142
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9653461575508118
Baseline loss: 1.3143926858901978
########
Epoch: 19
Meta Train Loss: 0.7270486354827881
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9940798878669739
Baseline loss: 1.3143926858901978
########
Epoch: 20
Meta Train Loss: 0.6923170685768127
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9739619493484497
Baseline loss: 1.3143926858901978
########
Epoch: 21
Meta Train Loss: 0.7086254954338074
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.983167827129364
Baseline loss: 1.3143926858901978
########
Epoch: 22
Meta Train Loss: 0.6959795355796814
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9887657761573792
Baseline loss: 1.3143926858901978
########
Epoch: 23
Meta Train Loss: 0.6971117258071899
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9806835651397705
Baseline loss: 1.3143926858901978
########
Epoch: 24
Meta Train Loss: 0.706556499004364
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9653988480567932
Baseline loss: 1.3143926858901978
########
Epoch: 25
Meta Train Loss: 0.7231625318527222
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 1.0111991167068481
Baseline loss: 1.3143926858901978
########
Epoch: 26
Meta Train Loss: 0.6938766837120056
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9852367043495178
Baseline loss: 1.3143926858901978
########
Epoch: 27
Meta Train Loss: 0.751207709312439
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.964033305644989
Baseline loss: 1.3143926858901978
########
Epoch: 28
Meta Train Loss: 0.7048565149307251
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9957132339477539
Baseline loss: 1.3143926858901978
########
Epoch: 29
Meta Train Loss: 0.6959211826324463
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.9960433840751648
Baseline loss: 1.3143926858901978
########
Epoch: 30
Meta Train Loss: 0.7029650807380676
Finetuned loss: 0.6831055283546448
Trained Edgeconv loss: 0.6663655638694763
Untrained Edgeconv loss: 0.966634213924408
Baseline loss: 1.3143926858901978
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/TLC2018-FHV-aug-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4389379322528839
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9919444918632507
Baseline loss: 0.40216851234436035
########
Epoch: 2
Meta Train Loss: 0.43577033281326294
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.949601948261261
Baseline loss: 0.40216851234436035
########
Epoch: 3
Meta Train Loss: 0.44217413663864136
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9581601619720459
Baseline loss: 0.40216851234436035
########
Epoch: 4
Meta Train Loss: 0.4383162558078766
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9635477066040039
Baseline loss: 0.40216851234436035
########
Epoch: 5
Meta Train Loss: 0.4379411041736603
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0207163095474243
Baseline loss: 0.40216851234436035
########
Epoch: 6
Meta Train Loss: 0.4373890161514282
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9694266319274902
Baseline loss: 0.40216851234436035
########
Epoch: 7
Meta Train Loss: 0.43874669075012207
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.024780035018921
Baseline loss: 0.40216851234436035
########
Epoch: 8
Meta Train Loss: 0.4388441741466522
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0081861019134521
Baseline loss: 0.40216851234436035
########
Epoch: 9
Meta Train Loss: 0.43681657314300537
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.044760823249817
Baseline loss: 0.40216851234436035
########
Epoch: 10
Meta Train Loss: 0.43337318301200867
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9700815677642822
Baseline loss: 0.40216851234436035
########
Epoch: 11
Meta Train Loss: 0.43859872221946716
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9816184639930725
Baseline loss: 0.40216851234436035
########
Epoch: 12
Meta Train Loss: 0.43563875555992126
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9648261070251465
Baseline loss: 0.40216851234436035
########
Epoch: 13
Meta Train Loss: 0.43823185563087463
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9984962344169617
Baseline loss: 0.40216851234436035
########
Epoch: 14
Meta Train Loss: 0.43857628107070923
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9821261763572693
Baseline loss: 0.40216851234436035
########
Epoch: 15
Meta Train Loss: 0.43758049607276917
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9571518301963806
Baseline loss: 0.40216851234436035
########
Epoch: 16
Meta Train Loss: 0.4399244487285614
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9798882007598877
Baseline loss: 0.40216851234436035
########
Epoch: 17
Meta Train Loss: 0.4415506422519684
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.059408187866211
Baseline loss: 0.40216851234436035
########
Epoch: 18
Meta Train Loss: 0.4404124617576599
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9906311631202698
Baseline loss: 0.40216851234436035
########
Epoch: 19
Meta Train Loss: 0.4391360282897949
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0445024967193604
Baseline loss: 0.40216851234436035
########
Epoch: 20
Meta Train Loss: 0.43910840153694153
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9585511088371277
Baseline loss: 0.40216851234436035
########
Epoch: 21
Meta Train Loss: 0.4391728639602661
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9573529362678528
Baseline loss: 0.40216851234436035
########
Epoch: 22
Meta Train Loss: 0.444407194852829
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9462360739707947
Baseline loss: 0.40216851234436035
########
Epoch: 23
Meta Train Loss: 0.4344650208950043
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.958612322807312
Baseline loss: 0.40216851234436035
########
Epoch: 24
Meta Train Loss: 0.4391917586326599
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9742555618286133
Baseline loss: 0.40216851234436035
########
Epoch: 25
Meta Train Loss: 0.43732011318206787
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9836066961288452
Baseline loss: 0.40216851234436035
########
Epoch: 26
Meta Train Loss: 0.43561360239982605
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.980869472026825
Baseline loss: 0.40216851234436035
########
Epoch: 27
Meta Train Loss: 0.44188201427459717
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9901700615882874
Baseline loss: 0.40216851234436035
########
Epoch: 28
Meta Train Loss: 0.4334370195865631
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9722920060157776
Baseline loss: 0.40216851234436035
########
Epoch: 29
Meta Train Loss: 0.4391419589519501
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9701352119445801
Baseline loss: 0.40216851234436035
########
Epoch: 30
Meta Train Loss: 0.43873870372772217
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9622992277145386
Baseline loss: 0.40216851234436035
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.46824634075164795
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.2253296375274658
Baseline loss: 0.40216851234436035
########
Epoch: 2
Meta Train Loss: 0.681331992149353
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.6071211099624634
Baseline loss: 0.40216851234436035
########
Epoch: 3
Meta Train Loss: 0.41675055027008057
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9559985399246216
Baseline loss: 0.40216851234436035
########
Epoch: 4
Meta Train Loss: 0.5600546598434448
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9456236362457275
Baseline loss: 0.40216851234436035
########
Epoch: 5
Meta Train Loss: 0.6251159906387329
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0258684158325195
Baseline loss: 0.40216851234436035
########
Epoch: 6
Meta Train Loss: 0.7529441118240356
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9794349670410156
Baseline loss: 0.40216851234436035
########
Epoch: 7
Meta Train Loss: 0.49702128767967224
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9600656032562256
Baseline loss: 0.40216851234436035
########
Epoch: 8
Meta Train Loss: 0.4754588305950165
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0204263925552368
Baseline loss: 0.40216851234436035
########
Epoch: 9
Meta Train Loss: 0.5157449841499329
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9767267107963562
Baseline loss: 0.40216851234436035
########
Epoch: 10
Meta Train Loss: 0.59378981590271
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0083553791046143
Baseline loss: 0.40216851234436035
########
Epoch: 11
Meta Train Loss: 0.4620853364467621
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9656330943107605
Baseline loss: 0.40216851234436035
########
Epoch: 12
Meta Train Loss: 0.41456007957458496
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9744504690170288
Baseline loss: 0.40216851234436035
########
Epoch: 13
Meta Train Loss: 0.4108424782752991
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9855373501777649
Baseline loss: 0.40216851234436035
########
Epoch: 14
Meta Train Loss: 0.40835562348365784
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.952358603477478
Baseline loss: 0.40216851234436035
########
Epoch: 15
Meta Train Loss: 0.48904716968536377
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0268950462341309
Baseline loss: 0.40216851234436035
########
Epoch: 16
Meta Train Loss: 0.5233412384986877
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9760172963142395
Baseline loss: 0.40216851234436035
########
Epoch: 17
Meta Train Loss: 0.6405485272407532
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9885510206222534
Baseline loss: 0.40216851234436035
########
Epoch: 18
Meta Train Loss: 0.42957812547683716
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9698124527931213
Baseline loss: 0.40216851234436035
########
Epoch: 19
Meta Train Loss: 0.44823360443115234
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9937275052070618
Baseline loss: 0.40216851234436035
########
Epoch: 20
Meta Train Loss: 0.5090947151184082
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9654567241668701
Baseline loss: 0.40216851234436035
########
Epoch: 21
Meta Train Loss: 0.43538740277290344
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9945673942565918
Baseline loss: 0.40216851234436035
########
Epoch: 22
Meta Train Loss: 0.4811214506626129
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9962472319602966
Baseline loss: 0.40216851234436035
########
Epoch: 23
Meta Train Loss: 0.4053686261177063
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9766898155212402
Baseline loss: 0.40216851234436035
########
Epoch: 24
Meta Train Loss: 0.4182088077068329
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9588771462440491
Baseline loss: 0.40216851234436035
########
Epoch: 25
Meta Train Loss: 0.5538084506988525
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9733033776283264
Baseline loss: 0.40216851234436035
########
Epoch: 26
Meta Train Loss: 0.5638774037361145
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9632701873779297
Baseline loss: 0.40216851234436035
########
Epoch: 27
Meta Train Loss: 0.7087633013725281
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9886832237243652
Baseline loss: 0.40216851234436035
########
Epoch: 28
Meta Train Loss: 0.42363956570625305
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9981517791748047
Baseline loss: 0.40216851234436035
########
Epoch: 29
Meta Train Loss: 0.46340009570121765
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.059186339378357
Baseline loss: 0.40216851234436035
########
Epoch: 30
Meta Train Loss: 0.41183415055274963
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9580758213996887
Baseline loss: 0.40216851234436035
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.42528653144836426
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.031943440437317
Baseline loss: 0.40216851234436035
########
Epoch: 2
Meta Train Loss: 0.5070596933364868
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.082927942276001
Baseline loss: 0.40216851234436035
########
Epoch: 3
Meta Train Loss: 0.4127630293369293
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9971293807029724
Baseline loss: 0.40216851234436035
########
Epoch: 4
Meta Train Loss: 0.44547131657600403
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.945824384689331
Baseline loss: 0.40216851234436035
########
Epoch: 5
Meta Train Loss: 0.43552255630493164
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9808304309844971
Baseline loss: 0.40216851234436035
########
Epoch: 6
Meta Train Loss: 0.5381441116333008
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9568339586257935
Baseline loss: 0.40216851234436035
########
Epoch: 7
Meta Train Loss: 0.44662338495254517
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.967780590057373
Baseline loss: 0.40216851234436035
########
Epoch: 8
Meta Train Loss: 0.41755902767181396
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9920960068702698
Baseline loss: 0.40216851234436035
########
Epoch: 9
Meta Train Loss: 0.47561973333358765
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9802614450454712
Baseline loss: 0.40216851234436035
########
Epoch: 10
Meta Train Loss: 0.5031160116195679
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9852100014686584
Baseline loss: 0.40216851234436035
########
Epoch: 11
Meta Train Loss: 0.41230258345603943
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9666531682014465
Baseline loss: 0.40216851234436035
########
Epoch: 12
Meta Train Loss: 0.44191741943359375
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9783952832221985
Baseline loss: 0.40216851234436035
########
Epoch: 13
Meta Train Loss: 0.4435740113258362
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.01026451587677
Baseline loss: 0.40216851234436035
########
Epoch: 14
Meta Train Loss: 0.442788690328598
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9566885828971863
Baseline loss: 0.40216851234436035
########
Epoch: 15
Meta Train Loss: 0.41523173451423645
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0057990550994873
Baseline loss: 0.40216851234436035
########
Epoch: 16
Meta Train Loss: 0.4891863465309143
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9663099646568298
Baseline loss: 0.40216851234436035
########
Epoch: 17
Meta Train Loss: 0.4439845383167267
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9798445105552673
Baseline loss: 0.40216851234436035
########
Epoch: 18
Meta Train Loss: 0.5353823900222778
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9671350717544556
Baseline loss: 0.40216851234436035
########
Epoch: 19
Meta Train Loss: 0.41103312373161316
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.007248878479004
Baseline loss: 0.40216851234436035
########
Epoch: 20
Meta Train Loss: 0.4324975311756134
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9654722809791565
Baseline loss: 0.40216851234436035
########
Epoch: 21
Meta Train Loss: 0.4807724058628082
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9905924797058105
Baseline loss: 0.40216851234436035
########
Epoch: 22
Meta Train Loss: 0.5094479322433472
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0166206359863281
Baseline loss: 0.40216851234436035
########
Epoch: 23
Meta Train Loss: 0.5077754855155945
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9768933057785034
Baseline loss: 0.40216851234436035
########
Epoch: 24
Meta Train Loss: 0.4048629403114319
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9582965970039368
Baseline loss: 0.40216851234436035
########
Epoch: 25
Meta Train Loss: 0.42927417159080505
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9881658554077148
Baseline loss: 0.40216851234436035
########
Epoch: 26
Meta Train Loss: 0.4870169460773468
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9580843448638916
Baseline loss: 0.40216851234436035
########
Epoch: 27
Meta Train Loss: 0.5541755557060242
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9811162948608398
Baseline loss: 0.40216851234436035
########
Epoch: 28
Meta Train Loss: 0.4064003825187683
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0004178285598755
Baseline loss: 0.40216851234436035
########
Epoch: 29
Meta Train Loss: 0.4170728623867035
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 1.0118006467819214
Baseline loss: 0.40216851234436035
########
Epoch: 30
Meta Train Loss: 0.4212428033351898
Finetuned loss: 0.4180654287338257
Trained Edgeconv loss: 0.32147303223609924
Untrained Edgeconv loss: 0.9669771790504456
Baseline loss: 0.40216851234436035
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/citibike-tripdata-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.41799020767211914
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9568667411804199
Baseline loss: 0.48034629225730896
########
Epoch: 2
Meta Train Loss: 0.4182491898536682
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9556183218955994
Baseline loss: 0.48034629225730896
########
Epoch: 3
Meta Train Loss: 0.4181593656539917
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9366856217384338
Baseline loss: 0.48034629225730896
########
Epoch: 4
Meta Train Loss: 0.41789692640304565
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9367918372154236
Baseline loss: 0.48034629225730896
########
Epoch: 5
Meta Train Loss: 0.41856321692466736
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9518084526062012
Baseline loss: 0.48034629225730896
########
Epoch: 6
Meta Train Loss: 0.4169892370700836
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9335957765579224
Baseline loss: 0.48034629225730896
########
Epoch: 7
Meta Train Loss: 0.41820138692855835
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9533630013465881
Baseline loss: 0.48034629225730896
########
Epoch: 8
Meta Train Loss: 0.4176596999168396
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.938624918460846
Baseline loss: 0.48034629225730896
########
Epoch: 9
Meta Train Loss: 0.41653043031692505
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9972807168960571
Baseline loss: 0.48034629225730896
########
Epoch: 10
Meta Train Loss: 0.4199993312358856
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9285993576049805
Baseline loss: 0.48034629225730896
########
Epoch: 11
Meta Train Loss: 0.4187597930431366
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9431540369987488
Baseline loss: 0.48034629225730896
########
Epoch: 12
Meta Train Loss: 0.41819000244140625
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9301832914352417
Baseline loss: 0.48034629225730896
########
Epoch: 13
Meta Train Loss: 0.41990673542022705
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9264307618141174
Baseline loss: 0.48034629225730896
########
Epoch: 14
Meta Train Loss: 0.417761892080307
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9591663479804993
Baseline loss: 0.48034629225730896
########
Epoch: 15
Meta Train Loss: 0.41736558079719543
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9285136461257935
Baseline loss: 0.48034629225730896
########
Epoch: 16
Meta Train Loss: 0.4184441566467285
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9423559904098511
Baseline loss: 0.48034629225730896
########
Epoch: 17
Meta Train Loss: 0.41654983162879944
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9468562602996826
Baseline loss: 0.48034629225730896
########
Epoch: 18
Meta Train Loss: 0.41585442423820496
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.962363064289093
Baseline loss: 0.48034629225730896
########
Epoch: 19
Meta Train Loss: 0.4185578525066376
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9453616142272949
Baseline loss: 0.48034629225730896
########
Epoch: 20
Meta Train Loss: 0.41762813925743103
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9556819200515747
Baseline loss: 0.48034629225730896
########
Epoch: 21
Meta Train Loss: 0.41830959916114807
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9400413036346436
Baseline loss: 0.48034629225730896
########
Epoch: 22
Meta Train Loss: 0.4191107153892517
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.941497266292572
Baseline loss: 0.48034629225730896
########
Epoch: 23
Meta Train Loss: 0.4199989140033722
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9367700815200806
Baseline loss: 0.48034629225730896
########
Epoch: 24
Meta Train Loss: 0.4167781174182892
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9494098424911499
Baseline loss: 0.48034629225730896
########
Epoch: 25
Meta Train Loss: 0.41921308636665344
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9431992173194885
Baseline loss: 0.48034629225730896
########
Epoch: 26
Meta Train Loss: 0.41802603006362915
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.933535635471344
Baseline loss: 0.48034629225730896
########
Epoch: 27
Meta Train Loss: 0.41727161407470703
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9380645155906677
Baseline loss: 0.48034629225730896
########
Epoch: 28
Meta Train Loss: 0.41781604290008545
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9465330839157104
Baseline loss: 0.48034629225730896
########
Epoch: 29
Meta Train Loss: 0.41848182678222656
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9351367354393005
Baseline loss: 0.48034629225730896
########
Epoch: 30
Meta Train Loss: 0.419889360666275
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9306861162185669
Baseline loss: 0.48034629225730896
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4056888818740845
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 1.0651683807373047
Baseline loss: 0.48034629225730896
########
Epoch: 2
Meta Train Loss: 0.5067275166511536
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 1.159650206565857
Baseline loss: 0.48034629225730896
########
Epoch: 3
Meta Train Loss: 0.40596193075180054
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9467527270317078
Baseline loss: 0.48034629225730896
########
Epoch: 4
Meta Train Loss: 0.4096817076206207
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9575451612472534
Baseline loss: 0.48034629225730896
########
Epoch: 5
Meta Train Loss: 0.4668676257133484
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9515604972839355
Baseline loss: 0.48034629225730896
########
Epoch: 6
Meta Train Loss: 0.5019375681877136
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9380719661712646
Baseline loss: 0.48034629225730896
########
Epoch: 7
Meta Train Loss: 0.8196302652359009
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9400020837783813
Baseline loss: 0.48034629225730896
########
Epoch: 8
Meta Train Loss: 0.368315726518631
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9469488859176636
Baseline loss: 0.48034629225730896
########
Epoch: 9
Meta Train Loss: 0.4709402024745941
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9532486796379089
Baseline loss: 0.48034629225730896
########
Epoch: 10
Meta Train Loss: 0.4074097275733948
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.948732852935791
Baseline loss: 0.48034629225730896
########
Epoch: 11
Meta Train Loss: 0.36908841133117676
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9481258988380432
Baseline loss: 0.48034629225730896
########
Epoch: 12
Meta Train Loss: 0.42230474948883057
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9450533986091614
Baseline loss: 0.48034629225730896
########
Epoch: 13
Meta Train Loss: 0.5034269094467163
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9345398545265198
Baseline loss: 0.48034629225730896
########
Epoch: 14
Meta Train Loss: 0.4092952311038971
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9271796345710754
Baseline loss: 0.48034629225730896
########
Epoch: 15
Meta Train Loss: 0.4382105767726898
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9696234464645386
Baseline loss: 0.48034629225730896
########
Epoch: 16
Meta Train Loss: 0.37219372391700745
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9602874517440796
Baseline loss: 0.48034629225730896
########
Epoch: 17
Meta Train Loss: 0.38457685708999634
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9385958909988403
Baseline loss: 0.48034629225730896
########
Epoch: 18
Meta Train Loss: 0.49390909075737
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9494988918304443
Baseline loss: 0.48034629225730896
########
Epoch: 19
Meta Train Loss: 0.41094595193862915
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9447565674781799
Baseline loss: 0.48034629225730896
########
Epoch: 20
Meta Train Loss: 0.38527747988700867
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9348787665367126
Baseline loss: 0.48034629225730896
########
Epoch: 21
Meta Train Loss: 0.46266528964042664
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.93604576587677
Baseline loss: 0.48034629225730896
########
Epoch: 22
Meta Train Loss: 0.3706009089946747
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9415943026542664
Baseline loss: 0.48034629225730896
########
Epoch: 23
Meta Train Loss: 0.44636744260787964
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9456841945648193
Baseline loss: 0.48034629225730896
########
Epoch: 24
Meta Train Loss: 0.6278187036514282
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9329641461372375
Baseline loss: 0.48034629225730896
########
Epoch: 25
Meta Train Loss: 40158.1875
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9384559392929077
Baseline loss: 0.48034629225730896
########
Epoch: 26
Meta Train Loss: 0.4855794608592987
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9527117609977722
Baseline loss: 0.48034629225730896
########
Epoch: 27
Meta Train Loss: 0.4053615927696228
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9219434857368469
Baseline loss: 0.48034629225730896
########
Epoch: 28
Meta Train Loss: 0.43690288066864014
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9582842588424683
Baseline loss: 0.48034629225730896
########
Epoch: 29
Meta Train Loss: 0.45588088035583496
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9328727722167969
Baseline loss: 0.48034629225730896
########
Epoch: 30
Meta Train Loss: 0.37559372186660767
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9471901655197144
Baseline loss: 0.48034629225730896
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.41283926367759705
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9658246040344238
Baseline loss: 0.48034629225730896
########
Epoch: 2
Meta Train Loss: 0.42049363255500793
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9801733493804932
Baseline loss: 0.48034629225730896
########
Epoch: 3
Meta Train Loss: 0.3681561350822449
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.946107804775238
Baseline loss: 0.48034629225730896
########
Epoch: 4
Meta Train Loss: 0.4311543107032776
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9385640025138855
Baseline loss: 0.48034629225730896
########
Epoch: 5
Meta Train Loss: 0.4024597704410553
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.948125422000885
Baseline loss: 0.48034629225730896
########
Epoch: 6
Meta Train Loss: 0.4406106173992157
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9372703433036804
Baseline loss: 0.48034629225730896
########
Epoch: 7
Meta Train Loss: 0.3818283677101135
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9346607327461243
Baseline loss: 0.48034629225730896
########
Epoch: 8
Meta Train Loss: 0.41121819615364075
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9466760158538818
Baseline loss: 0.48034629225730896
########
Epoch: 9
Meta Train Loss: 0.40916451811790466
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9426690340042114
Baseline loss: 0.48034629225730896
########
Epoch: 10
Meta Train Loss: 0.38345932960510254
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9500368237495422
Baseline loss: 0.48034629225730896
########
Epoch: 11
Meta Train Loss: 0.6118533611297607
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9498395919799805
Baseline loss: 0.48034629225730896
########
Epoch: 12
Meta Train Loss: 0.41461682319641113
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.944889485836029
Baseline loss: 0.48034629225730896
########
Epoch: 13
Meta Train Loss: 0.4568066895008087
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9372761845588684
Baseline loss: 0.48034629225730896
########
Epoch: 14
Meta Train Loss: 0.3770877420902252
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9362014532089233
Baseline loss: 0.48034629225730896
########
Epoch: 15
Meta Train Loss: 0.45485007762908936
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9557880163192749
Baseline loss: 0.48034629225730896
########
Epoch: 16
Meta Train Loss: 0.4115317463874817
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9463604092597961
Baseline loss: 0.48034629225730896
########
Epoch: 17
Meta Train Loss: 0.3740147054195404
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9490029811859131
Baseline loss: 0.48034629225730896
########
Epoch: 18
Meta Train Loss: 0.367511510848999
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9397082924842834
Baseline loss: 0.48034629225730896
########
Epoch: 19
Meta Train Loss: 0.3857276141643524
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9365420341491699
Baseline loss: 0.48034629225730896
########
Epoch: 20
Meta Train Loss: 0.3819044828414917
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9401862621307373
Baseline loss: 0.48034629225730896
########
Epoch: 21
Meta Train Loss: 0.3932131826877594
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9315932989120483
Baseline loss: 0.48034629225730896
########
Epoch: 22
Meta Train Loss: 0.38338571786880493
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9404656291007996
Baseline loss: 0.48034629225730896
########
Epoch: 23
Meta Train Loss: 0.37552034854888916
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9464315176010132
Baseline loss: 0.48034629225730896
########
Epoch: 24
Meta Train Loss: 0.577224612236023
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9323351383209229
Baseline loss: 0.48034629225730896
########
Epoch: 25
Meta Train Loss: 0.37551894783973694
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.937187671661377
Baseline loss: 0.48034629225730896
########
Epoch: 26
Meta Train Loss: 0.4581267535686493
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9510528445243835
Baseline loss: 0.48034629225730896
########
Epoch: 27
Meta Train Loss: 0.4509105682373047
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9225773215293884
Baseline loss: 0.48034629225730896
########
Epoch: 28
Meta Train Loss: 0.4058043360710144
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9556418657302856
Baseline loss: 0.48034629225730896
########
Epoch: 29
Meta Train Loss: 0.38262253999710083
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9482400417327881
Baseline loss: 0.48034629225730896
########
Epoch: 30
Meta Train Loss: 0.35622742772102356
Finetuned loss: 0.37494534254074097
Trained Edgeconv loss: 0.3260219991207123
Untrained Edgeconv loss: 0.9436781406402588
Baseline loss: 0.48034629225730896
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/yellow-taxi2020-nov-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.787039041519165
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0482558012008667
Baseline loss: 1.2131158113479614
########
Epoch: 2
Meta Train Loss: 0.7871721386909485
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0846774578094482
Baseline loss: 1.2131158113479614
########
Epoch: 3
Meta Train Loss: 0.7870140671730042
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0612375736236572
Baseline loss: 1.2131158113479614
########
Epoch: 4
Meta Train Loss: 0.7862417101860046
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0547213554382324
Baseline loss: 1.2131158113479614
########
Epoch: 5
Meta Train Loss: 0.7886744737625122
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0952117443084717
Baseline loss: 1.2131158113479614
########
Epoch: 6
Meta Train Loss: 0.7882203459739685
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0327376127243042
Baseline loss: 1.2131158113479614
########
Epoch: 7
Meta Train Loss: 0.7868154048919678
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0542417764663696
Baseline loss: 1.2131158113479614
########
Epoch: 8
Meta Train Loss: 0.786618709564209
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0491260290145874
Baseline loss: 1.2131158113479614
########
Epoch: 9
Meta Train Loss: 0.7864617705345154
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0393401384353638
Baseline loss: 1.2131158113479614
########
Epoch: 10
Meta Train Loss: 0.7878289222717285
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0243322849273682
Baseline loss: 1.2131158113479614
########
Epoch: 11
Meta Train Loss: 0.7845784425735474
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0396263599395752
Baseline loss: 1.2131158113479614
########
Epoch: 12
Meta Train Loss: 0.7852082848548889
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0209959745407104
Baseline loss: 1.2131158113479614
########
Epoch: 13
Meta Train Loss: 0.7858420014381409
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0306646823883057
Baseline loss: 1.2131158113479614
########
Epoch: 14
Meta Train Loss: 0.78703373670578
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0602937936782837
Baseline loss: 1.2131158113479614
########
Epoch: 15
Meta Train Loss: 0.7867956161499023
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0255241394042969
Baseline loss: 1.2131158113479614
########
Epoch: 16
Meta Train Loss: 0.7874111533164978
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0314117670059204
Baseline loss: 1.2131158113479614
########
Epoch: 17
Meta Train Loss: 0.786755383014679
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.047597885131836
Baseline loss: 1.2131158113479614
########
Epoch: 18
Meta Train Loss: 0.7846416234970093
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0682241916656494
Baseline loss: 1.2131158113479614
########
Epoch: 19
Meta Train Loss: 0.7858001589775085
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0504374504089355
Baseline loss: 1.2131158113479614
########
Epoch: 20
Meta Train Loss: 0.7863118648529053
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.042694330215454
Baseline loss: 1.2131158113479614
########
Epoch: 21
Meta Train Loss: 0.7863560318946838
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0387988090515137
Baseline loss: 1.2131158113479614
########
Epoch: 22
Meta Train Loss: 0.7877665162086487
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0564507246017456
Baseline loss: 1.2131158113479614
########
Epoch: 23
Meta Train Loss: 0.7868626117706299
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0260370969772339
Baseline loss: 1.2131158113479614
########
Epoch: 24
Meta Train Loss: 0.7870307564735413
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0362606048583984
Baseline loss: 1.2131158113479614
########
Epoch: 25
Meta Train Loss: 0.7889545559883118
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0488420724868774
Baseline loss: 1.2131158113479614
########
Epoch: 26
Meta Train Loss: 0.7870132923126221
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0315579175949097
Baseline loss: 1.2131158113479614
########
Epoch: 27
Meta Train Loss: 0.7870608568191528
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.056573510169983
Baseline loss: 1.2131158113479614
########
Epoch: 28
Meta Train Loss: 0.7871947288513184
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0345674753189087
Baseline loss: 1.2131158113479614
########
Epoch: 29
Meta Train Loss: 0.7876462340354919
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0402666330337524
Baseline loss: 1.2131158113479614
########
Epoch: 30
Meta Train Loss: 0.7876399755477905
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0384098291397095
Baseline loss: 1.2131158113479614
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.748436689376831
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0536340475082397
Baseline loss: 1.2131158113479614
########
Epoch: 2
Meta Train Loss: 0.7512819766998291
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.1168131828308105
Baseline loss: 1.2131158113479614
########
Epoch: 3
Meta Train Loss: 0.7697951793670654
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.123421549797058
Baseline loss: 1.2131158113479614
########
Epoch: 4
Meta Train Loss: 0.7612736821174622
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0396043062210083
Baseline loss: 1.2131158113479614
########
Epoch: 5
Meta Train Loss: 0.7646095156669617
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.1192179918289185
Baseline loss: 1.2131158113479614
########
Epoch: 6
Meta Train Loss: 0.7827882766723633
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0389515161514282
Baseline loss: 1.2131158113479614
########
Epoch: 7
Meta Train Loss: 0.761809229850769
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0530518293380737
Baseline loss: 1.2131158113479614
########
Epoch: 8
Meta Train Loss: 0.7665866613388062
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0499008893966675
Baseline loss: 1.2131158113479614
########
Epoch: 9
Meta Train Loss: 0.7585552334785461
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0550861358642578
Baseline loss: 1.2131158113479614
########
Epoch: 10
Meta Train Loss: 0.7804680466651917
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0384867191314697
Baseline loss: 1.2131158113479614
########
Epoch: 11
Meta Train Loss: 0.7575965523719788
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0629246234893799
Baseline loss: 1.2131158113479614
########
Epoch: 12
Meta Train Loss: 0.7834551930427551
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0656416416168213
Baseline loss: 1.2131158113479614
########
Epoch: 13
Meta Train Loss: 0.7871041893959045
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0518004894256592
Baseline loss: 1.2131158113479614
########
Epoch: 14
Meta Train Loss: 0.7552431225776672
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0341765880584717
Baseline loss: 1.2131158113479614
########
Epoch: 15
Meta Train Loss: 0.7566881775856018
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0304899215698242
Baseline loss: 1.2131158113479614
########
Epoch: 16
Meta Train Loss: 0.7798567414283752
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0694983005523682
Baseline loss: 1.2131158113479614
########
Epoch: 17
Meta Train Loss: 0.7499681711196899
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.098987340927124
Baseline loss: 1.2131158113479614
########
Epoch: 18
Meta Train Loss: 0.7616214156150818
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.047240972518921
Baseline loss: 1.2131158113479614
########
Epoch: 19
Meta Train Loss: 0.7723989486694336
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0388529300689697
Baseline loss: 1.2131158113479614
########
Epoch: 20
Meta Train Loss: 0.7895949482917786
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.044278860092163
Baseline loss: 1.2131158113479614
########
Epoch: 21
Meta Train Loss: 0.8070650100708008
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0431344509124756
Baseline loss: 1.2131158113479614
########
Epoch: 22
Meta Train Loss: 0.7591491937637329
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0457061529159546
Baseline loss: 1.2131158113479614
########
Epoch: 23
Meta Train Loss: 0.7774930596351624
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.062273621559143
Baseline loss: 1.2131158113479614
########
Epoch: 24
Meta Train Loss: 0.7884641289710999
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0283334255218506
Baseline loss: 1.2131158113479614
########
Epoch: 25
Meta Train Loss: 0.7563446164131165
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0292508602142334
Baseline loss: 1.2131158113479614
########
Epoch: 26
Meta Train Loss: 1.4108790159225464
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0820361375808716
Baseline loss: 1.2131158113479614
########
Epoch: 27
Meta Train Loss: 0.7730615735054016
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0179990530014038
Baseline loss: 1.2131158113479614
########
Epoch: 28
Meta Train Loss: 0.7686691284179688
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0943379402160645
Baseline loss: 1.2131158113479614
########
Epoch: 29
Meta Train Loss: 0.798690915107727
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0500543117523193
Baseline loss: 1.2131158113479614
########
Epoch: 30
Meta Train Loss: 0.7568792700767517
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.070642113685608
Baseline loss: 1.2131158113479614
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7541085481643677
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0607103109359741
Baseline loss: 1.2131158113479614
########
Epoch: 2
Meta Train Loss: 0.7569708228111267
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0827609300613403
Baseline loss: 1.2131158113479614
########
Epoch: 3
Meta Train Loss: 0.7790918946266174
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0354077816009521
Baseline loss: 1.2131158113479614
########
Epoch: 4
Meta Train Loss: 0.7766318917274475
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0280771255493164
Baseline loss: 1.2131158113479614
########
Epoch: 5
Meta Train Loss: 0.7659760117530823
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.1120989322662354
Baseline loss: 1.2131158113479614
########
Epoch: 6
Meta Train Loss: 0.7520074844360352
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.034345030784607
Baseline loss: 1.2131158113479614
########
Epoch: 7
Meta Train Loss: 0.7784332633018494
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0543338060379028
Baseline loss: 1.2131158113479614
########
Epoch: 8
Meta Train Loss: 0.7703437805175781
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0761789083480835
Baseline loss: 1.2131158113479614
########
Epoch: 9
Meta Train Loss: 0.7601194977760315
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0581554174423218
Baseline loss: 1.2131158113479614
########
Epoch: 10
Meta Train Loss: 0.7549217343330383
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0356628894805908
Baseline loss: 1.2131158113479614
########
Epoch: 11
Meta Train Loss: 0.752970278263092
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0671292543411255
Baseline loss: 1.2131158113479614
########
Epoch: 12
Meta Train Loss: 0.7577766180038452
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.078588604927063
Baseline loss: 1.2131158113479614
########
Epoch: 13
Meta Train Loss: 0.7545933723449707
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0391943454742432
Baseline loss: 1.2131158113479614
########
Epoch: 14
Meta Train Loss: 0.7520837783813477
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0359307527542114
Baseline loss: 1.2131158113479614
########
Epoch: 15
Meta Train Loss: 0.7500730752944946
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0386757850646973
Baseline loss: 1.2131158113479614
########
Epoch: 16
Meta Train Loss: 0.7675021886825562
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.069846510887146
Baseline loss: 1.2131158113479614
########
Epoch: 17
Meta Train Loss: 0.7612692713737488
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0931581258773804
Baseline loss: 1.2131158113479614
########
Epoch: 18
Meta Train Loss: 0.7732393145561218
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0345078706741333
Baseline loss: 1.2131158113479614
########
Epoch: 19
Meta Train Loss: 0.7552383542060852
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0362824201583862
Baseline loss: 1.2131158113479614
########
Epoch: 20
Meta Train Loss: 0.7546373009681702
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.045189380645752
Baseline loss: 1.2131158113479614
########
Epoch: 21
Meta Train Loss: 0.7502784729003906
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.041157841682434
Baseline loss: 1.2131158113479614
########
Epoch: 22
Meta Train Loss: 0.7522308230400085
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0495067834854126
Baseline loss: 1.2131158113479614
########
Epoch: 23
Meta Train Loss: 0.7487398386001587
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0571105480194092
Baseline loss: 1.2131158113479614
########
Epoch: 24
Meta Train Loss: 0.7556692361831665
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.029218316078186
Baseline loss: 1.2131158113479614
########
Epoch: 25
Meta Train Loss: 0.7581515312194824
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0286058187484741
Baseline loss: 1.2131158113479614
########
Epoch: 26
Meta Train Loss: 0.7710617184638977
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0876591205596924
Baseline loss: 1.2131158113479614
########
Epoch: 27
Meta Train Loss: 0.7659653425216675
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0183486938476562
Baseline loss: 1.2131158113479614
########
Epoch: 28
Meta Train Loss: 0.7635639905929565
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0643455982208252
Baseline loss: 1.2131158113479614
########
Epoch: 29
Meta Train Loss: 0.7645325660705566
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.043697476387024
Baseline loss: 1.2131158113479614
########
Epoch: 30
Meta Train Loss: 0.7622151374816895
Finetuned loss: 0.7476953864097595
Trained Edgeconv loss: 0.7360658645629883
Untrained Edgeconv loss: 1.0693280696868896
Baseline loss: 1.2131158113479614
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/green-taxi2020-dec-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9587882161140442
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0522254705429077
Baseline loss: 1.7573487758636475
########
Epoch: 2
Meta Train Loss: 0.9586426019668579
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0532402992248535
Baseline loss: 1.7573487758636475
########
Epoch: 3
Meta Train Loss: 0.9601488709449768
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.051949381828308
Baseline loss: 1.7573487758636475
########
Epoch: 4
Meta Train Loss: 0.9592700600624084
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.024850845336914
Baseline loss: 1.7573487758636475
########
Epoch: 5
Meta Train Loss: 0.9589917659759521
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0623838901519775
Baseline loss: 1.7573487758636475
########
Epoch: 6
Meta Train Loss: 0.9589987397193909
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0601755380630493
Baseline loss: 1.7573487758636475
########
Epoch: 7
Meta Train Loss: 0.9590495824813843
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0362472534179688
Baseline loss: 1.7573487758636475
########
Epoch: 8
Meta Train Loss: 0.9576279520988464
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0526739358901978
Baseline loss: 1.7573487758636475
########
Epoch: 9
Meta Train Loss: 0.9587134718894958
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0310685634613037
Baseline loss: 1.7573487758636475
########
Epoch: 10
Meta Train Loss: 0.9587656259536743
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0276050567626953
Baseline loss: 1.7573487758636475
########
Epoch: 11
Meta Train Loss: 0.9584389328956604
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.030361294746399
Baseline loss: 1.7573487758636475
########
Epoch: 12
Meta Train Loss: 0.9600711464881897
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0342931747436523
Baseline loss: 1.7573487758636475
########
Epoch: 13
Meta Train Loss: 0.959377646446228
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0324732065200806
Baseline loss: 1.7573487758636475
########
Epoch: 14
Meta Train Loss: 0.9586982727050781
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0342016220092773
Baseline loss: 1.7573487758636475
########
Epoch: 15
Meta Train Loss: 0.9591861963272095
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.023220181465149
Baseline loss: 1.7573487758636475
########
Epoch: 16
Meta Train Loss: 0.9590979814529419
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0360914468765259
Baseline loss: 1.7573487758636475
########
Epoch: 17
Meta Train Loss: 0.9593213796615601
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0321539640426636
Baseline loss: 1.7573487758636475
########
Epoch: 18
Meta Train Loss: 0.9592507481575012
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0495017766952515
Baseline loss: 1.7573487758636475
########
Epoch: 19
Meta Train Loss: 0.958879828453064
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0431573390960693
Baseline loss: 1.7573487758636475
########
Epoch: 20
Meta Train Loss: 0.959008514881134
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.032017469406128
Baseline loss: 1.7573487758636475
########
Epoch: 21
Meta Train Loss: 0.959173321723938
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0358952283859253
Baseline loss: 1.7573487758636475
########
Epoch: 22
Meta Train Loss: 0.9592297077178955
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0221694707870483
Baseline loss: 1.7573487758636475
########
Epoch: 23
Meta Train Loss: 0.9590801000595093
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0429798364639282
Baseline loss: 1.7573487758636475
########
Epoch: 24
Meta Train Loss: 0.9599167704582214
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0304912328720093
Baseline loss: 1.7573487758636475
########
Epoch: 25
Meta Train Loss: 0.9585549831390381
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0273487567901611
Baseline loss: 1.7573487758636475
########
Epoch: 26
Meta Train Loss: 0.9593492150306702
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0258170366287231
Baseline loss: 1.7573487758636475
########
Epoch: 27
Meta Train Loss: 0.9591495990753174
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0514070987701416
Baseline loss: 1.7573487758636475
########
Epoch: 28
Meta Train Loss: 0.9589393734931946
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0557482242584229
Baseline loss: 1.7573487758636475
########
Epoch: 29
Meta Train Loss: 0.9589563012123108
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0336575508117676
Baseline loss: 1.7573487758636475
########
Epoch: 30
Meta Train Loss: 0.9593883752822876
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0336215496063232
Baseline loss: 1.7573487758636475
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.941359281539917
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0230661630630493
Baseline loss: 1.7573487758636475
########
Epoch: 2
Meta Train Loss: 0.9616182446479797
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0395852327346802
Baseline loss: 1.7573487758636475
########
Epoch: 3
Meta Train Loss: 0.9415157437324524
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.056479573249817
Baseline loss: 1.7573487758636475
########
Epoch: 4
Meta Train Loss: 0.9626375436782837
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0253733396530151
Baseline loss: 1.7573487758636475
########
Epoch: 5
Meta Train Loss: 0.95824134349823
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.1186021566390991
Baseline loss: 1.7573487758636475
########
Epoch: 6
Meta Train Loss: 0.9578230381011963
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.044764518737793
Baseline loss: 1.7573487758636475
########
Epoch: 7
Meta Train Loss: 0.944732129573822
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0410884618759155
Baseline loss: 1.7573487758636475
########
Epoch: 8
Meta Train Loss: 0.9418935775756836
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0383814573287964
Baseline loss: 1.7573487758636475
########
Epoch: 9
Meta Train Loss: 0.953274667263031
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0360397100448608
Baseline loss: 1.7573487758636475
########
Epoch: 10
Meta Train Loss: 0.9587989449501038
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0777997970581055
Baseline loss: 1.7573487758636475
########
Epoch: 11
Meta Train Loss: 0.955538809299469
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.112676739692688
Baseline loss: 1.7573487758636475
########
Epoch: 12
Meta Train Loss: 0.9414146542549133
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.062024712562561
Baseline loss: 1.7573487758636475
########
Epoch: 13
Meta Train Loss: 0.9485533833503723
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.027194619178772
Baseline loss: 1.7573487758636475
########
Epoch: 14
Meta Train Loss: 0.9590213298797607
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.031293272972107
Baseline loss: 1.7573487758636475
########
Epoch: 15
Meta Train Loss: 0.9628230333328247
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0445162057876587
Baseline loss: 1.7573487758636475
########
Epoch: 16
Meta Train Loss: 0.9696835875511169
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.041018009185791
Baseline loss: 1.7573487758636475
########
Epoch: 17
Meta Train Loss: 0.9516761898994446
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0553576946258545
Baseline loss: 1.7573487758636475
########
Epoch: 18
Meta Train Loss: 0.9418808817863464
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0273817777633667
Baseline loss: 1.7573487758636475
########
Epoch: 19
Meta Train Loss: 3153.699951171875
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0327588319778442
Baseline loss: 1.7573487758636475
########
Epoch: 20
Meta Train Loss: 0.935184121131897
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.037411093711853
Baseline loss: 1.7573487758636475
########
Epoch: 21
Meta Train Loss: 0.9461072683334351
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0895226001739502
Baseline loss: 1.7573487758636475
########
Epoch: 22
Meta Train Loss: 0.9456358551979065
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0307952165603638
Baseline loss: 1.7573487758636475
########
Epoch: 23
Meta Train Loss: 0.9516420960426331
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0469359159469604
Baseline loss: 1.7573487758636475
########
Epoch: 24
Meta Train Loss: 0.9378612637519836
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.038453459739685
Baseline loss: 1.7573487758636475
########
Epoch: 25
Meta Train Loss: 0.9600278735160828
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0829793214797974
Baseline loss: 1.7573487758636475
########
Epoch: 26
Meta Train Loss: 0.9644874334335327
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.038907766342163
Baseline loss: 1.7573487758636475
########
Epoch: 27
Meta Train Loss: 0.9620862603187561
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.017877221107483
Baseline loss: 1.7573487758636475
########
Epoch: 28
Meta Train Loss: 0.9326163530349731
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0631355047225952
Baseline loss: 1.7573487758636475
########
Epoch: 29
Meta Train Loss: 0.9515494704246521
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0557044744491577
Baseline loss: 1.7573487758636475
########
Epoch: 30
Meta Train Loss: 0.9617938995361328
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0311164855957031
Baseline loss: 1.7573487758636475
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9320915937423706
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0375912189483643
Baseline loss: 1.7573487758636475
########
Epoch: 2
Meta Train Loss: 0.9360492825508118
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0585583448410034
Baseline loss: 1.7573487758636475
########
Epoch: 3
Meta Train Loss: 0.9322546124458313
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0334504842758179
Baseline loss: 1.7573487758636475
########
Epoch: 4
Meta Train Loss: 0.9541292190551758
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0430141687393188
Baseline loss: 1.7573487758636475
########
Epoch: 5
Meta Train Loss: 0.9432441592216492
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.060843825340271
Baseline loss: 1.7573487758636475
########
Epoch: 6
Meta Train Loss: 0.9554554224014282
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0317025184631348
Baseline loss: 1.7573487758636475
########
Epoch: 7
Meta Train Loss: 0.9450071454048157
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0214183330535889
Baseline loss: 1.7573487758636475
########
Epoch: 8
Meta Train Loss: 0.9475426077842712
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0481481552124023
Baseline loss: 1.7573487758636475
########
Epoch: 9
Meta Train Loss: 0.9413044452667236
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0299605131149292
Baseline loss: 1.7573487758636475
########
Epoch: 10
Meta Train Loss: 0.9471005201339722
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0493720769882202
Baseline loss: 1.7573487758636475
########
Epoch: 11
Meta Train Loss: 0.9369930028915405
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0442354679107666
Baseline loss: 1.7573487758636475
########
Epoch: 12
Meta Train Loss: 0.93828946352005
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0181797742843628
Baseline loss: 1.7573487758636475
########
Epoch: 13
Meta Train Loss: 0.9358700513839722
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0413646697998047
Baseline loss: 1.7573487758636475
########
Epoch: 14
Meta Train Loss: 0.9399775862693787
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0441256761550903
Baseline loss: 1.7573487758636475
########
Epoch: 15
Meta Train Loss: 0.9331393241882324
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.024569034576416
Baseline loss: 1.7573487758636475
########
Epoch: 16
Meta Train Loss: 0.9705274105072021
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.034679651260376
Baseline loss: 1.7573487758636475
########
Epoch: 17
Meta Train Loss: 0.9526090621948242
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0403810739517212
Baseline loss: 1.7573487758636475
########
Epoch: 18
Meta Train Loss: 0.931796669960022
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.038036823272705
Baseline loss: 1.7573487758636475
########
Epoch: 19
Meta Train Loss: 0.9448102712631226
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0826371908187866
Baseline loss: 1.7573487758636475
########
Epoch: 20
Meta Train Loss: 0.9337737560272217
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0334761142730713
Baseline loss: 1.7573487758636475
########
Epoch: 21
Meta Train Loss: 0.9360065460205078
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.024238109588623
Baseline loss: 1.7573487758636475
########
Epoch: 22
Meta Train Loss: 0.9348006844520569
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0368374586105347
Baseline loss: 1.7573487758636475
########
Epoch: 23
Meta Train Loss: 0.936805009841919
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0287586450576782
Baseline loss: 1.7573487758636475
########
Epoch: 24
Meta Train Loss: 0.9410876035690308
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0332801342010498
Baseline loss: 1.7573487758636475
########
Epoch: 25
Meta Train Loss: 0.9493811130523682
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0340417623519897
Baseline loss: 1.7573487758636475
########
Epoch: 26
Meta Train Loss: 0.9382492303848267
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0489622354507446
Baseline loss: 1.7573487758636475
########
Epoch: 27
Meta Train Loss: 0.9536781907081604
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0727217197418213
Baseline loss: 1.7573487758636475
########
Epoch: 28
Meta Train Loss: 0.9330682754516602
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.021385908126831
Baseline loss: 1.7573487758636475
########
Epoch: 29
Meta Train Loss: 0.9369862675666809
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0384174585342407
Baseline loss: 1.7573487758636475
########
Epoch: 30
Meta Train Loss: 0.9340500235557556
Finetuned loss: 0.9267516732215881
Trained Edgeconv loss: 0.9473752975463867
Untrained Edgeconv loss: 1.0248017311096191
Baseline loss: 1.7573487758636475
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/citibike2014-tripdata-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.5053313374519348
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0885167121887207
Baseline loss: 0.6341790556907654
########
Epoch: 2
Meta Train Loss: 0.504438042640686
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0813003778457642
Baseline loss: 0.6341790556907654
########
Epoch: 3
Meta Train Loss: 0.5048835277557373
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0822056531906128
Baseline loss: 0.6341790556907654
########
Epoch: 4
Meta Train Loss: 0.5053619146347046
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0703002214431763
Baseline loss: 0.6341790556907654
########
Epoch: 5
Meta Train Loss: 0.5047764778137207
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0871384143829346
Baseline loss: 0.6341790556907654
########
Epoch: 6
Meta Train Loss: 0.5035020709037781
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0780880451202393
Baseline loss: 0.6341790556907654
########
Epoch: 7
Meta Train Loss: 0.5045017004013062
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1089152097702026
Baseline loss: 0.6341790556907654
########
Epoch: 8
Meta Train Loss: 0.5051404237747192
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0911957025527954
Baseline loss: 0.6341790556907654
########
Epoch: 9
Meta Train Loss: 0.5046126842498779
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.131360650062561
Baseline loss: 0.6341790556907654
########
Epoch: 10
Meta Train Loss: 0.5055696964263916
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.069112777709961
Baseline loss: 0.6341790556907654
########
Epoch: 11
Meta Train Loss: 0.5038375854492188
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.076446294784546
Baseline loss: 0.6341790556907654
########
Epoch: 12
Meta Train Loss: 0.5038933753967285
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0797550678253174
Baseline loss: 0.6341790556907654
########
Epoch: 13
Meta Train Loss: 0.5023773908615112
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0741297006607056
Baseline loss: 0.6341790556907654
########
Epoch: 14
Meta Train Loss: 0.5040132403373718
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0824666023254395
Baseline loss: 0.6341790556907654
########
Epoch: 15
Meta Train Loss: 0.5048418641090393
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0656023025512695
Baseline loss: 0.6341790556907654
########
Epoch: 16
Meta Train Loss: 0.5048914551734924
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0888051986694336
Baseline loss: 0.6341790556907654
########
Epoch: 17
Meta Train Loss: 0.5047923922538757
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0991166830062866
Baseline loss: 0.6341790556907654
########
Epoch: 18
Meta Train Loss: 0.5060449242591858
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0889794826507568
Baseline loss: 0.6341790556907654
########
Epoch: 19
Meta Train Loss: 0.5054415464401245
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0977133512496948
Baseline loss: 0.6341790556907654
########
Epoch: 20
Meta Train Loss: 0.5035505890846252
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0900704860687256
Baseline loss: 0.6341790556907654
########
Epoch: 21
Meta Train Loss: 0.5058197379112244
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.079321026802063
Baseline loss: 0.6341790556907654
########
Epoch: 22
Meta Train Loss: 0.5042476654052734
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0691475868225098
Baseline loss: 0.6341790556907654
########
Epoch: 23
Meta Train Loss: 0.50333571434021
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0658727884292603
Baseline loss: 0.6341790556907654
########
Epoch: 24
Meta Train Loss: 0.5054142475128174
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0835849046707153
Baseline loss: 0.6341790556907654
########
Epoch: 25
Meta Train Loss: 0.5046250820159912
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0896050930023193
Baseline loss: 0.6341790556907654
########
Epoch: 26
Meta Train Loss: 0.5047412514686584
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.072136402130127
Baseline loss: 0.6341790556907654
########
Epoch: 27
Meta Train Loss: 0.5038759708404541
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0856013298034668
Baseline loss: 0.6341790556907654
########
Epoch: 28
Meta Train Loss: 0.504287838935852
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0896902084350586
Baseline loss: 0.6341790556907654
########
Epoch: 29
Meta Train Loss: 0.5050131678581238
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.079703450202942
Baseline loss: 0.6341790556907654
########
Epoch: 30
Meta Train Loss: 0.5052461624145508
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0684654712677002
Baseline loss: 0.6341790556907654
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.5606686472892761
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.3090499639511108
Baseline loss: 0.6341790556907654
########
Epoch: 2
Meta Train Loss: 1.9014867544174194
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0983396768569946
Baseline loss: 0.6341790556907654
########
Epoch: 3
Meta Train Loss: 0.5041649341583252
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.133128046989441
Baseline loss: 0.6341790556907654
########
Epoch: 4
Meta Train Loss: 0.5104728937149048
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0639746189117432
Baseline loss: 0.6341790556907654
########
Epoch: 5
Meta Train Loss: 0.5188273191452026
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1014858484268188
Baseline loss: 0.6341790556907654
########
Epoch: 6
Meta Train Loss: 0.6709821820259094
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.075410008430481
Baseline loss: 0.6341790556907654
########
Epoch: 7
Meta Train Loss: 0.5045263171195984
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.072875738143921
Baseline loss: 0.6341790556907654
########
Epoch: 8
Meta Train Loss: 0.5322890281677246
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0912106037139893
Baseline loss: 0.6341790556907654
########
Epoch: 9
Meta Train Loss: 0.5108781456947327
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0634313821792603
Baseline loss: 0.6341790556907654
########
Epoch: 10
Meta Train Loss: 0.5087222456932068
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1093631982803345
Baseline loss: 0.6341790556907654
########
Epoch: 11
Meta Train Loss: 0.5033060312271118
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.120589017868042
Baseline loss: 0.6341790556907654
########
Epoch: 12
Meta Train Loss: 0.5951123237609863
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.075905680656433
Baseline loss: 0.6341790556907654
########
Epoch: 13
Meta Train Loss: 0.5005157589912415
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0801979303359985
Baseline loss: 0.6341790556907654
########
Epoch: 14
Meta Train Loss: 0.508803129196167
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0673658847808838
Baseline loss: 0.6341790556907654
########
Epoch: 15
Meta Train Loss: 0.5631659030914307
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0774695873260498
Baseline loss: 0.6341790556907654
########
Epoch: 16
Meta Train Loss: 0.9752589464187622
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0938875675201416
Baseline loss: 0.6341790556907654
########
Epoch: 17
Meta Train Loss: 0.5169898271560669
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0760498046875
Baseline loss: 0.6341790556907654
########
Epoch: 18
Meta Train Loss: 0.55599445104599
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.076257348060608
Baseline loss: 0.6341790556907654
########
Epoch: 19
Meta Train Loss: 0.541438102722168
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.090183138847351
Baseline loss: 0.6341790556907654
########
Epoch: 20
Meta Train Loss: 0.5478149056434631
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0845732688903809
Baseline loss: 0.6341790556907654
########
Epoch: 21
Meta Train Loss: 0.8442314267158508
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0854566097259521
Baseline loss: 0.6341790556907654
########
Epoch: 22
Meta Train Loss: 0.4968430995941162
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0806128978729248
Baseline loss: 0.6341790556907654
########
Epoch: 23
Meta Train Loss: 0.5218250155448914
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0820202827453613
Baseline loss: 0.6341790556907654
########
Epoch: 24
Meta Train Loss: 0.5293091535568237
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.070804476737976
Baseline loss: 0.6341790556907654
########
Epoch: 25
Meta Train Loss: 0.5631328821182251
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.074289083480835
Baseline loss: 0.6341790556907654
########
Epoch: 26
Meta Train Loss: 0.5661098957061768
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0846928358078003
Baseline loss: 0.6341790556907654
########
Epoch: 27
Meta Train Loss: 0.5390750169754028
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0648390054702759
Baseline loss: 0.6341790556907654
########
Epoch: 28
Meta Train Loss: 0.5042012333869934
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0928348302841187
Baseline loss: 0.6341790556907654
########
Epoch: 29
Meta Train Loss: 0.515475869178772
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1169058084487915
Baseline loss: 0.6341790556907654
########
Epoch: 30
Meta Train Loss: 0.5008054375648499
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0758883953094482
Baseline loss: 0.6341790556907654
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.5333442091941833
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1144120693206787
Baseline loss: 0.6341790556907654
########
Epoch: 2
Meta Train Loss: 0.5240541696548462
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.10303795337677
Baseline loss: 0.6341790556907654
########
Epoch: 3
Meta Train Loss: 0.5255943536758423
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0874578952789307
Baseline loss: 0.6341790556907654
########
Epoch: 4
Meta Train Loss: 0.5086549520492554
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0678774118423462
Baseline loss: 0.6341790556907654
########
Epoch: 5
Meta Train Loss: 0.509684145450592
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0810996294021606
Baseline loss: 0.6341790556907654
########
Epoch: 6
Meta Train Loss: 0.5746273398399353
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0768076181411743
Baseline loss: 0.6341790556907654
########
Epoch: 7
Meta Train Loss: 0.5124192237854004
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0732455253601074
Baseline loss: 0.6341790556907654
########
Epoch: 8
Meta Train Loss: 0.5310739874839783
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.1074678897857666
Baseline loss: 0.6341790556907654
########
Epoch: 9
Meta Train Loss: 0.5009123682975769
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.063370704650879
Baseline loss: 0.6341790556907654
########
Epoch: 10
Meta Train Loss: 0.5145582556724548
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0932561159133911
Baseline loss: 0.6341790556907654
########
Epoch: 11
Meta Train Loss: 0.5325425267219543
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0974513292312622
Baseline loss: 0.6341790556907654
########
Epoch: 12
Meta Train Loss: 0.578582763671875
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0760960578918457
Baseline loss: 0.6341790556907654
########
Epoch: 13
Meta Train Loss: 0.5085245966911316
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0874848365783691
Baseline loss: 0.6341790556907654
########
Epoch: 14
Meta Train Loss: 0.5004633665084839
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0676398277282715
Baseline loss: 0.6341790556907654
########
Epoch: 15
Meta Train Loss: 0.5599234104156494
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0942684412002563
Baseline loss: 0.6341790556907654
########
Epoch: 16
Meta Train Loss: 0.5815663933753967
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0789718627929688
Baseline loss: 0.6341790556907654
########
Epoch: 17
Meta Train Loss: 0.5597994923591614
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0854742527008057
Baseline loss: 0.6341790556907654
########
Epoch: 18
Meta Train Loss: 0.5246489644050598
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0766223669052124
Baseline loss: 0.6341790556907654
########
Epoch: 19
Meta Train Loss: 0.5197362303733826
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0788466930389404
Baseline loss: 0.6341790556907654
########
Epoch: 20
Meta Train Loss: 0.5650455355644226
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0848731994628906
Baseline loss: 0.6341790556907654
########
Epoch: 21
Meta Train Loss: 0.5841140747070312
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.081223487854004
Baseline loss: 0.6341790556907654
########
Epoch: 22
Meta Train Loss: 0.51270991563797
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.07649827003479
Baseline loss: 0.6341790556907654
########
Epoch: 23
Meta Train Loss: 0.5483690500259399
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.081665277481079
Baseline loss: 0.6341790556907654
########
Epoch: 24
Meta Train Loss: 0.5140380263328552
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0697935819625854
Baseline loss: 0.6341790556907654
########
Epoch: 25
Meta Train Loss: 0.5610511302947998
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0744054317474365
Baseline loss: 0.6341790556907654
########
Epoch: 26
Meta Train Loss: 0.5095743536949158
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0859317779541016
Baseline loss: 0.6341790556907654
########
Epoch: 27
Meta Train Loss: 0.569435179233551
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0635745525360107
Baseline loss: 0.6341790556907654
########
Epoch: 28
Meta Train Loss: 0.5151357054710388
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0934181213378906
Baseline loss: 0.6341790556907654
########
Epoch: 29
Meta Train Loss: 0.6015791296958923
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.0837254524230957
Baseline loss: 0.6341790556907654
########
Epoch: 30
Meta Train Loss: 0.5032952427864075
Finetuned loss: 0.48462975025177
Trained Edgeconv loss: 0.46100759506225586
Untrained Edgeconv loss: 1.081221342086792
Baseline loss: 0.6341790556907654
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/citibike2014-tripdata-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.6884973049163818
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0996778011322021
Baseline loss: 0.9803446531295776
########
Epoch: 2
Meta Train Loss: 0.6882805228233337
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.093748688697815
Baseline loss: 0.9803446531295776
########
Epoch: 3
Meta Train Loss: 0.6884346008300781
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.088356375694275
Baseline loss: 0.9803446531295776
########
Epoch: 4
Meta Train Loss: 0.6880506277084351
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0782787799835205
Baseline loss: 0.9803446531295776
########
Epoch: 5
Meta Train Loss: 0.6880674958229065
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0960042476654053
Baseline loss: 0.9803446531295776
########
Epoch: 6
Meta Train Loss: 0.6882064342498779
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0836204290390015
Baseline loss: 0.9803446531295776
########
Epoch: 7
Meta Train Loss: 0.6879630088806152
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1159363985061646
Baseline loss: 0.9803446531295776
########
Epoch: 8
Meta Train Loss: 0.688222348690033
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.097469687461853
Baseline loss: 0.9803446531295776
########
Epoch: 9
Meta Train Loss: 0.6884300708770752
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.133194088935852
Baseline loss: 0.9803446531295776
########
Epoch: 10
Meta Train Loss: 0.6884350180625916
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0789520740509033
Baseline loss: 0.9803446531295776
########
Epoch: 11
Meta Train Loss: 0.6879338026046753
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0858349800109863
Baseline loss: 0.9803446531295776
########
Epoch: 12
Meta Train Loss: 0.6880688667297363
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.083959698677063
Baseline loss: 0.9803446531295776
########
Epoch: 13
Meta Train Loss: 0.6880324482917786
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0817499160766602
Baseline loss: 0.9803446531295776
########
Epoch: 14
Meta Train Loss: 0.688154935836792
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.092952847480774
Baseline loss: 0.9803446531295776
########
Epoch: 15
Meta Train Loss: 0.6884299516677856
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.075189471244812
Baseline loss: 0.9803446531295776
########
Epoch: 16
Meta Train Loss: 0.6881098747253418
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0960413217544556
Baseline loss: 0.9803446531295776
########
Epoch: 17
Meta Train Loss: 0.6886093616485596
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1056225299835205
Baseline loss: 0.9803446531295776
########
Epoch: 18
Meta Train Loss: 0.6884790062904358
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0984244346618652
Baseline loss: 0.9803446531295776
########
Epoch: 19
Meta Train Loss: 0.68837970495224
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1052076816558838
Baseline loss: 0.9803446531295776
########
Epoch: 20
Meta Train Loss: 0.6879896521568298
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0969641208648682
Baseline loss: 0.9803446531295776
########
Epoch: 21
Meta Train Loss: 0.6885532736778259
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0870460271835327
Baseline loss: 0.9803446531295776
########
Epoch: 22
Meta Train Loss: 0.6878334283828735
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0793997049331665
Baseline loss: 0.9803446531295776
########
Epoch: 23
Meta Train Loss: 0.6879857182502747
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0790914297103882
Baseline loss: 0.9803446531295776
########
Epoch: 24
Meta Train Loss: 0.6882175207138062
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0913304090499878
Baseline loss: 0.9803446531295776
########
Epoch: 25
Meta Train Loss: 0.6885305643081665
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.093538522720337
Baseline loss: 0.9803446531295776
########
Epoch: 26
Meta Train Loss: 0.6879952549934387
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0776787996292114
Baseline loss: 0.9803446531295776
########
Epoch: 27
Meta Train Loss: 0.6878675222396851
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0917741060256958
Baseline loss: 0.9803446531295776
########
Epoch: 28
Meta Train Loss: 0.6880907416343689
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.097439169883728
Baseline loss: 0.9803446531295776
########
Epoch: 29
Meta Train Loss: 0.6881290674209595
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0858535766601562
Baseline loss: 0.9803446531295776
########
Epoch: 30
Meta Train Loss: 0.6883852481842041
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0757967233657837
Baseline loss: 0.9803446531295776
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7196094393730164
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.2477692365646362
Baseline loss: 0.9803446531295776
########
Epoch: 2
Meta Train Loss: 1.454777717590332
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1002991199493408
Baseline loss: 0.9803446531295776
########
Epoch: 3
Meta Train Loss: 0.6824696063995361
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1316126585006714
Baseline loss: 0.9803446531295776
########
Epoch: 4
Meta Train Loss: 0.6926237344741821
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0734142065048218
Baseline loss: 0.9803446531295776
########
Epoch: 5
Meta Train Loss: 0.6966140866279602
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1080081462860107
Baseline loss: 0.9803446531295776
########
Epoch: 6
Meta Train Loss: 0.7663811445236206
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0820423364639282
Baseline loss: 0.9803446531295776
########
Epoch: 7
Meta Train Loss: 0.6828529834747314
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0835150480270386
Baseline loss: 0.9803446531295776
########
Epoch: 8
Meta Train Loss: 0.6869682669639587
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1030097007751465
Baseline loss: 0.9803446531295776
########
Epoch: 9
Meta Train Loss: 0.6904560327529907
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0736010074615479
Baseline loss: 0.9803446531295776
########
Epoch: 10
Meta Train Loss: 0.6878758072853088
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1137217283248901
Baseline loss: 0.9803446531295776
########
Epoch: 11
Meta Train Loss: 0.6818175911903381
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1272526979446411
Baseline loss: 0.9803446531295776
########
Epoch: 12
Meta Train Loss: 0.7404729127883911
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0800154209136963
Baseline loss: 0.9803446531295776
########
Epoch: 13
Meta Train Loss: 0.6784125566482544
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0857858657836914
Baseline loss: 0.9803446531295776
########
Epoch: 14
Meta Train Loss: 0.6859695911407471
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.075581669807434
Baseline loss: 0.9803446531295776
########
Epoch: 15
Meta Train Loss: 0.7224676012992859
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0847272872924805
Baseline loss: 0.9803446531295776
########
Epoch: 16
Meta Train Loss: 0.93626868724823
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1038141250610352
Baseline loss: 0.9803446531295776
########
Epoch: 17
Meta Train Loss: 0.6875258088111877
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0868397951126099
Baseline loss: 0.9803446531295776
########
Epoch: 18
Meta Train Loss: 0.7045977711677551
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0846080780029297
Baseline loss: 0.9803446531295776
########
Epoch: 19
Meta Train Loss: 0.7161073684692383
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0960503816604614
Baseline loss: 0.9803446531295776
########
Epoch: 20
Meta Train Loss: 0.7102677226066589
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0939700603485107
Baseline loss: 0.9803446531295776
########
Epoch: 21
Meta Train Loss: 0.8334599733352661
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0961418151855469
Baseline loss: 0.9803446531295776
########
Epoch: 22
Meta Train Loss: 0.6790494918823242
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0889848470687866
Baseline loss: 0.9803446531295776
########
Epoch: 23
Meta Train Loss: 0.6956177353858948
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0920392274856567
Baseline loss: 0.9803446531295776
########
Epoch: 24
Meta Train Loss: 0.7110467553138733
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0790165662765503
Baseline loss: 0.9803446531295776
########
Epoch: 25
Meta Train Loss: 0.708055853843689
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0798954963684082
Baseline loss: 0.9803446531295776
########
Epoch: 26
Meta Train Loss: 0.736510157585144
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0947496891021729
Baseline loss: 0.9803446531295776
########
Epoch: 27
Meta Train Loss: 0.7031064629554749
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0721014738082886
Baseline loss: 0.9803446531295776
########
Epoch: 28
Meta Train Loss: 0.6824876070022583
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1032788753509521
Baseline loss: 0.9803446531295776
########
Epoch: 29
Meta Train Loss: 0.6869359016418457
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1208679676055908
Baseline loss: 0.9803446531295776
########
Epoch: 30
Meta Train Loss: 0.680124044418335
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.082600474357605
Baseline loss: 0.9803446531295776
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7152169942855835
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.117850661277771
Baseline loss: 0.9803446531295776
########
Epoch: 2
Meta Train Loss: 0.6957622766494751
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0766152143478394
Baseline loss: 0.9803446531295776
########
Epoch: 3
Meta Train Loss: 0.6960781812667847
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0807279348373413
Baseline loss: 0.9803446531295776
########
Epoch: 4
Meta Train Loss: 0.683925986289978
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0956348180770874
Baseline loss: 0.9803446531295776
########
Epoch: 5
Meta Train Loss: 0.683513879776001
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0859510898590088
Baseline loss: 0.9803446531295776
########
Epoch: 6
Meta Train Loss: 0.726998507976532
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0934234857559204
Baseline loss: 0.9803446531295776
########
Epoch: 7
Meta Train Loss: 0.685455322265625
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0839779376983643
Baseline loss: 0.9803446531295776
########
Epoch: 8
Meta Train Loss: 0.6903403997421265
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0974016189575195
Baseline loss: 0.9803446531295776
########
Epoch: 9
Meta Train Loss: 0.6803814768791199
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0837607383728027
Baseline loss: 0.9803446531295776
########
Epoch: 10
Meta Train Loss: 0.6850916743278503
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.074814796447754
Baseline loss: 0.9803446531295776
########
Epoch: 11
Meta Train Loss: 0.6933082342147827
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1018091440200806
Baseline loss: 0.9803446531295776
########
Epoch: 12
Meta Train Loss: 0.7344151735305786
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0860731601715088
Baseline loss: 0.9803446531295776
########
Epoch: 13
Meta Train Loss: 0.6874471306800842
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0822830200195312
Baseline loss: 0.9803446531295776
########
Epoch: 14
Meta Train Loss: 0.6782175302505493
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0871447324752808
Baseline loss: 0.9803446531295776
########
Epoch: 15
Meta Train Loss: 0.7204623222351074
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0935566425323486
Baseline loss: 0.9803446531295776
########
Epoch: 16
Meta Train Loss: 0.7117822766304016
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.092559814453125
Baseline loss: 0.9803446531295776
########
Epoch: 17
Meta Train Loss: 0.7264888882637024
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0858783721923828
Baseline loss: 0.9803446531295776
########
Epoch: 18
Meta Train Loss: 0.696012020111084
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0901696681976318
Baseline loss: 0.9803446531295776
########
Epoch: 19
Meta Train Loss: 0.7010912895202637
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0857834815979004
Baseline loss: 0.9803446531295776
########
Epoch: 20
Meta Train Loss: 0.7063000202178955
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0990819931030273
Baseline loss: 0.9803446531295776
########
Epoch: 21
Meta Train Loss: 0.7498180866241455
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.099965214729309
Baseline loss: 0.9803446531295776
########
Epoch: 22
Meta Train Loss: 0.6874769330024719
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0951931476593018
Baseline loss: 0.9803446531295776
########
Epoch: 23
Meta Train Loss: 0.7120152711868286
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0803601741790771
Baseline loss: 0.9803446531295776
########
Epoch: 24
Meta Train Loss: 0.6788276433944702
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0934386253356934
Baseline loss: 0.9803446531295776
########
Epoch: 25
Meta Train Loss: 0.7135816216468811
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0924055576324463
Baseline loss: 0.9803446531295776
########
Epoch: 26
Meta Train Loss: 0.6848942041397095
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.1178900003433228
Baseline loss: 0.9803446531295776
########
Epoch: 27
Meta Train Loss: 0.7091902494430542
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0766079425811768
Baseline loss: 0.9803446531295776
########
Epoch: 28
Meta Train Loss: 0.682547390460968
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0791016817092896
Baseline loss: 0.9803446531295776
########
Epoch: 29
Meta Train Loss: 0.7216520309448242
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.073280930519104
Baseline loss: 0.9803446531295776
########
Epoch: 30
Meta Train Loss: 0.6859343647956848
Finetuned loss: 0.6747968792915344
Trained Edgeconv loss: 0.6073328852653503
Untrained Edgeconv loss: 1.0962215662002563
Baseline loss: 0.9803446531295776
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10567952: <compare> in cluster <dcc> Done

Job <compare> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Tue Oct  5 19:17:47 2021
Job was executed on host(s) <n-62-20-11>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Tue Oct  5 19:17:49 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Tue Oct  5 19:17:49 2021
Terminated at Tue Oct  5 20:06:09 2021
Results reported at Tue Oct  5 20:06:09 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J compare #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate


python /zhome/2b/7/117471/Thesis/src/models/compare_metalearning.py


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   2877.47 sec.
    Max Memory :                                 3038 MB
    Average Memory :                             2670.42 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9250.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   2905 sec.
    Turnaround time :                            2902 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10567952> for stderr output of this job.

