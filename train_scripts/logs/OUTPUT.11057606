Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 1.2841922044754028
########
Epoch: 2
Meta Train Loss: 0.9932602643966675
########
Epoch: 3
Meta Train Loss: 1.1670676469802856
########
Epoch: 4
Meta Train Loss: 1.1053231954574585
########
Epoch: 5
Meta Train Loss: 1.4592070579528809
########
Epoch: 6
Meta Train Loss: 0.9632731080055237
########
Epoch: 7
Meta Train Loss: 2.607638359069824
########
Epoch: 8
Meta Train Loss: 0.9530348777770996
########
Epoch: 9
Meta Train Loss: 1.4674179553985596
########
Epoch: 10
Meta Train Loss: 0.8937594294548035
########
Epoch: 11
Meta Train Loss: 1.0349098443984985
########
Epoch: 12
Meta Train Loss: 1.097902774810791
########
Epoch: 13
Meta Train Loss: 0.941837728023529
########
Epoch: 14
Meta Train Loss: 0.9319862127304077
########
Epoch: 15
Meta Train Loss: 0.996675968170166
########
Epoch: 16
Meta Train Loss: 0.9478670358657837
########
Epoch: 17
Meta Train Loss: 1.1074867248535156
########
Epoch: 18
Meta Train Loss: 0.7633110284805298
########
Epoch: 19
Meta Train Loss: 0.9373384714126587
########
Epoch: 20
Meta Train Loss: 0.9043636322021484
########
Epoch: 21
Meta Train Loss: 0.7839168310165405
########
Epoch: 22
Meta Train Loss: 1.5787640810012817
########
Epoch: 23
Meta Train Loss: 0.9397211670875549
########
Epoch: 24
Meta Train Loss: 0.8622603416442871
########
Epoch: 25
Meta Train Loss: 1.2742286920547485
########
Epoch: 26
Meta Train Loss: 0.9409307837486267
########
Epoch: 27
Meta Train Loss: 0.9597925543785095
########
Epoch: 28
Meta Train Loss: 0.9810911417007446
########
Epoch: 29
Meta Train Loss: 1.2104277610778809
########
Epoch: 30
Meta Train Loss: 0.8603371977806091
########
Epoch: 31
Meta Train Loss: 1.002928376197815
########
Epoch: 32
Meta Train Loss: 1.2161281108856201
########
Epoch: 33
Meta Train Loss: 1.075788140296936
########
Epoch: 34
Meta Train Loss: 0.9018422365188599
########
Epoch: 35
Meta Train Loss: 0.7395466566085815
########
Epoch: 36
Meta Train Loss: 0.8337075710296631
########
Epoch: 37
Meta Train Loss: 0.7724946737289429
########
Epoch: 38
Meta Train Loss: 0.8273197412490845
########
Epoch: 39
Meta Train Loss: 0.9346606731414795
########
Epoch: 40
Meta Train Loss: 0.841216504573822
########
Epoch: 41
Meta Train Loss: 0.6914656162261963
########
Epoch: 42
Meta Train Loss: 0.7178123593330383
########
Epoch: 43
Meta Train Loss: 0.7577813863754272
########
Epoch: 44
Meta Train Loss: 0.7482653856277466
########
Epoch: 45
Meta Train Loss: 0.750648021697998
########
Epoch: 46
Meta Train Loss: 0.7139219641685486
########
Epoch: 47
Meta Train Loss: 0.7740781307220459
########
Epoch: 48
Meta Train Loss: 132436.328125
########
Epoch: 49
Meta Train Loss: 0.6114591956138611
########
Epoch: 50
Meta Train Loss: 0.6168017387390137
########
Epoch: 51
Meta Train Loss: 0.787898600101471
########
Epoch: 52
Meta Train Loss: 0.6718114614486694
########
Epoch: 53
Meta Train Loss: 0.7313827872276306
########
Epoch: 54
Meta Train Loss: 0.9158823490142822
########
Epoch: 55
Meta Train Loss: 0.5838772058486938
########
Epoch: 56
Meta Train Loss: 0.782215416431427
########
Epoch: 57
Meta Train Loss: 0.6557857990264893
########
Epoch: 58
Meta Train Loss: 0.7951197624206543
########
Epoch: 59
Meta Train Loss: 0.6986256837844849
########
Epoch: 60
Meta Train Loss: 0.9821385145187378
########
Epoch: 61
Meta Train Loss: 0.5702453255653381
########
Epoch: 62
Meta Train Loss: 0.7883865833282471
########
Epoch: 63
Meta Train Loss: 0.8654038310050964
########
Epoch: 64
Meta Train Loss: 0.6687478423118591
########
Epoch: 65
Meta Train Loss: 0.7813111543655396
########
Epoch: 66
Meta Train Loss: 0.6367490291595459
########
Epoch: 67
Meta Train Loss: 0.8980628252029419
########
Epoch: 68
Meta Train Loss: 0.6965385675430298
########
Epoch: 69
Meta Train Loss: 1.1213321685791016
########
Epoch: 70
Meta Train Loss: 1.022612452507019
########
Epoch: 71
Meta Train Loss: 0.6800469756126404
########
Epoch: 72
Meta Train Loss: 0.8172315955162048
########
Epoch: 73
Meta Train Loss: 0.7357547879219055
########
Epoch: 74
Meta Train Loss: 0.7261303663253784
########
Epoch: 75
Meta Train Loss: 0.6915194392204285
########
Epoch: 76
Meta Train Loss: 0.6264162659645081
########
Epoch: 77
Meta Train Loss: 0.7019188404083252
########
Epoch: 78
Meta Train Loss: 0.6881896257400513
########
Epoch: 79
Meta Train Loss: 0.7203069925308228
########
Epoch: 80
Meta Train Loss: 0.7679547667503357
########
Epoch: 81
Meta Train Loss: 0.5428870320320129
########
Epoch: 82
Meta Train Loss: 0.7447171211242676
########
Epoch: 83
Meta Train Loss: 0.5540543794631958
########
Epoch: 84
Meta Train Loss: 0.5793880820274353
########
Epoch: 85
Meta Train Loss: 0.6650983095169067
########
Epoch: 86
Meta Train Loss: 0.6801884174346924
########
Epoch: 87
Meta Train Loss: 0.6123645901679993
########
Epoch: 88
Meta Train Loss: 0.5822696089744568
########
Epoch: 89
Meta Train Loss: 0.5715289115905762
########
Epoch: 90
Meta Train Loss: 0.6211779117584229
########
Epoch: 91
Meta Train Loss: 0.6803936958312988
########
Epoch: 92
Meta Train Loss: 0.5126341581344604
########
Epoch: 93
Meta Train Loss: 0.7383860349655151
########
Epoch: 94
Meta Train Loss: 0.7924346923828125
########
Epoch: 95
Meta Train Loss: 0.5493322014808655
########
Epoch: 96
Meta Train Loss: 0.7804349660873413
########
Epoch: 97
Meta Train Loss: 0.8166612386703491
########
Epoch: 98
Meta Train Loss: 1.1244010925292969
########
Epoch: 99
Meta Train Loss: 0.6180176734924316
########
Epoch: 100
Meta Train Loss: 0.883925199508667
########
Epoch: 101
Meta Train Loss: 0.7451685070991516
########
Epoch: 102
Meta Train Loss: 0.6173982620239258
########
Epoch: 103
Meta Train Loss: 0.7559484839439392
########
Epoch: 104
Meta Train Loss: 0.894749641418457
########
Epoch: 105
Meta Train Loss: 0.6020160913467407
########
Epoch: 106
Meta Train Loss: 0.8109318017959595
########
Epoch: 107
Meta Train Loss: 0.5554483532905579
########
Epoch: 108
Meta Train Loss: 0.5433204174041748
########
Epoch: 109
Meta Train Loss: 0.6724838614463806
########
Epoch: 110
Meta Train Loss: 0.7883038520812988
########
Epoch: 111
Meta Train Loss: 0.5185035467147827
########
Epoch: 112
Meta Train Loss: 0.782710611820221
########
Epoch: 113
Meta Train Loss: 0.6381986141204834
########
Epoch: 114
Meta Train Loss: 0.590017557144165
########
Epoch: 115
Meta Train Loss: 0.7488628029823303
########
Epoch: 116
Meta Train Loss: 0.5824877023696899
########
Epoch: 117
Meta Train Loss: 0.6370817422866821
########
Epoch: 118
Meta Train Loss: 1.0264939069747925
########
Epoch: 119
Meta Train Loss: 0.45601820945739746
########
Epoch: 120
Meta Train Loss: 0.8723050355911255
########
Epoch: 121
Meta Train Loss: 0.6423429846763611
########
Epoch: 122
Meta Train Loss: 0.5394834280014038
########
Epoch: 123
Meta Train Loss: 0.5995415449142456
########
Epoch: 124
Meta Train Loss: 0.5334076881408691
########
Epoch: 125
Meta Train Loss: 0.9141331315040588
########
Epoch: 126
Meta Train Loss: 0.5498086214065552
########
Epoch: 127
Meta Train Loss: 0.6136202812194824
########
Epoch: 128
Meta Train Loss: 0.9943732619285583
########
Epoch: 129
Meta Train Loss: 0.9942963719367981
########
Epoch: 130
Meta Train Loss: 0.5767307877540588
########
Epoch: 131
Meta Train Loss: 0.5289870500564575
########
Epoch: 132
Meta Train Loss: 0.5191205739974976
########
Epoch: 133
Meta Train Loss: 0.4585656225681305
########
Epoch: 134
Meta Train Loss: 5.455263614654541
########
Epoch: 135
Meta Train Loss: 0.5166956782341003
########
Epoch: 136
Meta Train Loss: 0.7005866169929504
########
Epoch: 137
Meta Train Loss: 0.5215483903884888
########
Epoch: 138
Meta Train Loss: 0.7768208980560303
########
Epoch: 139
Meta Train Loss: 0.573103666305542
########
Epoch: 140
Meta Train Loss: 0.7123934626579285
########
Epoch: 141
Meta Train Loss: 0.5467268228530884
########
Epoch: 142
Meta Train Loss: 0.8364914059638977
########
Epoch: 143
Meta Train Loss: 0.5887281894683838
########
Epoch: 144
Meta Train Loss: 0.6531426310539246
########
Epoch: 145
Meta Train Loss: 0.6574683785438538
########
Epoch: 146
Meta Train Loss: 0.5882410407066345
########
Epoch: 147
Meta Train Loss: 0.5537195205688477
########
Epoch: 148
Meta Train Loss: 1.0073788166046143
########
Epoch: 149
Meta Train Loss: 0.5259363651275635
########
Epoch: 150
Meta Train Loss: 0.7275327444076538
########
Epoch: 151
Meta Train Loss: 0.4863653779029846
########
Epoch: 152
Meta Train Loss: 0.610641360282898
########
Epoch: 153
Meta Train Loss: 0.6749299764633179
########
Epoch: 154
Meta Train Loss: 0.9154187440872192
########
Epoch: 155
Meta Train Loss: 0.6078365445137024
########
Epoch: 156
Meta Train Loss: 0.6191871166229248
########
Epoch: 157
Meta Train Loss: 0.6789733171463013
########
Epoch: 158
Meta Train Loss: 0.5702455043792725
########
Epoch: 159
Meta Train Loss: 0.5279308557510376
########
Epoch: 160
Meta Train Loss: 0.7146155834197998
########
Epoch: 161
Meta Train Loss: 0.5980945229530334
########
Epoch: 162
Meta Train Loss: 0.9525712132453918
########
Epoch: 163
Meta Train Loss: 0.574640154838562
########
Epoch: 164
Meta Train Loss: 0.6021686792373657
########
Epoch: 165
Meta Train Loss: 0.503743588924408
########
Epoch: 166
Meta Train Loss: 0.9936488270759583
########
Epoch: 167
Meta Train Loss: 0.6769572496414185
########
Epoch: 168
Meta Train Loss: 0.6458881497383118
########
Epoch: 169
Meta Train Loss: 47225.4140625
########
Epoch: 170
Meta Train Loss: 0.5374499559402466
########
Epoch: 171
Meta Train Loss: 1.249289870262146
########
Epoch: 172
Meta Train Loss: 1.0233854055404663
########
Epoch: 173
Meta Train Loss: 0.6278880834579468
########
Epoch: 174
Meta Train Loss: 0.5039600133895874
########
Epoch: 175
Meta Train Loss: 0.5500404834747314
########
Epoch: 176
Meta Train Loss: 0.8193156123161316
########
Epoch: 177
Meta Train Loss: 0.6312468647956848
########
Epoch: 178
Meta Train Loss: 0.4873928427696228
########
Epoch: 179
Meta Train Loss: 0.6849144697189331
########
Epoch: 180
Meta Train Loss: 0.8577890396118164
########
Epoch: 181
Meta Train Loss: 0.5133328437805176
########
Epoch: 182
Meta Train Loss: 0.6730011701583862
########
Epoch: 183
Meta Train Loss: 0.7250047922134399
########
Epoch: 184
Meta Train Loss: 0.5531749725341797
########
Epoch: 185
Meta Train Loss: 0.6798606514930725
########
Epoch: 186
Meta Train Loss: 0.5052357912063599
########
Epoch: 187
Meta Train Loss: 0.6131758689880371
########
Epoch: 188
Meta Train Loss: 0.5471804141998291
########
Epoch: 189
Meta Train Loss: 0.9703397750854492
########
Epoch: 190
Meta Train Loss: 0.755856990814209
########
Epoch: 191
Meta Train Loss: 0.5772814154624939
########
Epoch: 192
Meta Train Loss: 0.5740801095962524
########
Epoch: 193
Meta Train Loss: 0.6427962183952332
########
Epoch: 194
Meta Train Loss: 0.43297553062438965
########
Epoch: 195
Meta Train Loss: 0.6813992261886597
########
Epoch: 196
Meta Train Loss: 0.5693246722221375
########
Epoch: 197
Meta Train Loss: 0.6782862544059753
########
Epoch: 198
Meta Train Loss: 0.507133424282074
########
Epoch: 199
Meta Train Loss: 2381354.75
########
Epoch: 200
Meta Train Loss: 0.47654929757118225
########
Epoch: 201
Meta Train Loss: 0.6345803141593933
########
Epoch: 202
Meta Train Loss: 1.2616260051727295
########
Epoch: 203
Meta Train Loss: 0.5858301520347595
########
Epoch: 204
Meta Train Loss: 0.5826266407966614
########
Epoch: 205
Meta Train Loss: 0.7396749258041382
########
Epoch: 206
Meta Train Loss: 0.4758482575416565
########
Epoch: 207
Meta Train Loss: 0.577055037021637
########
Epoch: 208
Meta Train Loss: 0.6021533608436584
########
Epoch: 209
Meta Train Loss: 0.8445827960968018
########
Epoch: 210
Meta Train Loss: 0.7944491505622864
########
Epoch: 211
Meta Train Loss: 0.5475928783416748
########
Epoch: 212
Meta Train Loss: 0.6539999842643738
########
Epoch: 213
Meta Train Loss: 0.5206232070922852
########
Epoch: 214
Meta Train Loss: 0.5404210686683655
########
Epoch: 215
Meta Train Loss: 0.7043179869651794
########
Epoch: 216
Meta Train Loss: 0.7257009744644165
########
Epoch: 217
Meta Train Loss: 0.7499118447303772
########
Epoch: 218
Meta Train Loss: 0.7109262943267822
########
Epoch: 219
Meta Train Loss: 0.5675623416900635
########
Epoch: 220
Meta Train Loss: 0.6328125
########
Epoch: 221
Meta Train Loss: 0.6333906054496765
########
Epoch: 222
Meta Train Loss: 0.6190286874771118
########
Epoch: 223
Meta Train Loss: 0.6308541297912598
########
Epoch: 224
Meta Train Loss: 0.595993161201477
########
Epoch: 225
Meta Train Loss: 0.5793269276618958
########
Epoch: 226
Meta Train Loss: 0.6678756475448608
########
Epoch: 227
Meta Train Loss: 0.9349988698959351
########
Epoch: 228
Meta Train Loss: 0.9445194602012634
########
Epoch: 229
Meta Train Loss: 0.8078789710998535
########
Epoch: 230
Meta Train Loss: 0.469872385263443
########
Epoch: 231
Meta Train Loss: 0.5738471746444702
########
Epoch: 232
Meta Train Loss: 1.0247200727462769
########
Epoch: 233
Meta Train Loss: 0.6372148394584656
########
Epoch: 234
Meta Train Loss: 0.6333796381950378
########
Epoch: 235
Meta Train Loss: 0.6306606531143188
########
Epoch: 236
Meta Train Loss: 0.5649884939193726
########
Epoch: 237
Meta Train Loss: 0.7395921349525452
########
Epoch: 238
Meta Train Loss: 0.563480794429779
########
Epoch: 239
Meta Train Loss: 0.5982261300086975
########
Epoch: 240
Meta Train Loss: 0.555749773979187
########
Epoch: 241
Meta Train Loss: 0.8002226948738098
########
Epoch: 242
Meta Train Loss: 0.5315529704093933
########
Epoch: 243
Meta Train Loss: 0.704431414604187
########
Epoch: 244
Meta Train Loss: 0.7636440396308899
########
Epoch: 245
Meta Train Loss: 0.6282024383544922
########
Epoch: 246
Meta Train Loss: 0.7752801179885864
########
Epoch: 247
Meta Train Loss: 0.6931699514389038
########
Epoch: 248
Meta Train Loss: 0.7402791976928711
########
Epoch: 249
Meta Train Loss: 0.4702773094177246
########
Epoch: 250
Meta Train Loss: 0.6965318918228149
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11057606: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Wed Nov 17 16:00:50 2021
Job was executed on host(s) <n-62-11-13>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Wed Nov 17 17:56:16 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Wed Nov 17 17:56:16 2021
Terminated at Wed Nov 17 19:19:17 2021
Results reported at Wed Nov 17 19:19:17 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/aglation-non_augmented
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=10
K_SHOT=5
ADAPTATION_STEPS=10
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=citibike-tripdata,citibike2014,GM
LOG_DIR=/zhome/2b/7/117471/Thesis/ablation-study/non-augmented
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10

# citibike-tripdata,citibike2014,GM,green,LYFT,TLC,UBER,yellow

python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --exclude $EXCLUDE --gpu


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4970.00 sec.
    Max Memory :                                 2826 MB
    Average Memory :                             2772.67 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9462.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   4981 sec.
    Turnaround time :                            11907 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.11057606> for stderr output of this job.

