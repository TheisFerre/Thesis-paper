Starting:
Shuffling data...
Epoch: 1
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9813278615474701
Transfer model loss: 0.8612078130245209
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 2
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9479208886623383
Transfer model loss: 0.8540545105934143
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 3
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9381660521030426
Transfer model loss: 0.8553338646888733
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 4
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.922193631529808
Transfer model loss: 0.8297136574983597
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 5
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.000159427523613
Transfer model loss: 0.8611905723810196
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 6
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9577434062957764
Transfer model loss: 0.8257730603218079
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 7
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0061722546815872
Transfer model loss: 0.8240852802991867
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 8
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9886119216680527
Transfer model loss: 0.8205776214599609
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 9
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0037321746349335
Transfer model loss: 0.8868391960859299
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 10
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9195229262113571
Transfer model loss: 0.8395626544952393
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 11
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9822463542222977
Transfer model loss: 0.8759093433618546
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 12
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9410618096590042
Transfer model loss: 0.918467178940773
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 13
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9793175011873245
Transfer model loss: 0.8661747127771378
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 14
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9731951653957367
Transfer model loss: 0.8669954240322113
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 15
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9595547020435333
Transfer model loss: 0.7777791321277618
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 16
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9897672086954117
Transfer model loss: 0.8524713814258575
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 17
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.038962110877037
Transfer model loss: 0.8380011171102524
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 18
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9939694702625275
Transfer model loss: 0.7786897420883179
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 19
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0118348896503448
Transfer model loss: 0.8936190754175186
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 20
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9597587734460831
Transfer model loss: 0.8365787416696548
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 21
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9637315422296524
Transfer model loss: 0.8992908596992493
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 22
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9414011090993881
Transfer model loss: 0.8344853073358536
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 23
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9333624094724655
Transfer model loss: 0.8877241462469101
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 24
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9615208208560944
Transfer model loss: 0.9389815330505371
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 25
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9645102918148041
Transfer model loss: 0.8908914178609848
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 26
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.982221782207489
Transfer model loss: 0.9374122321605682
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 27
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9831405282020569
Transfer model loss: 0.8319229334592819
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 28
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9645652920007706
Transfer model loss: 0.8987155854701996
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 29
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9860257804393768
Transfer model loss: 0.8726517856121063
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 30
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9448456466197968
Transfer model loss: 0.836761474609375
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Shuffling data...
Epoch: 1
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.233408272266388
Transfer model loss: 0.8540545105934143
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 2
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 2.8101513385772705
Transfer model loss: 0.8297136574983597
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 3
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9776480197906494
Transfer model loss: 0.8257730603218079
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 4
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9549446552991867
Transfer model loss: 0.8205776214599609
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 5
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.2603749334812164
Transfer model loss: 0.8395626544952393
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 6
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.5905970931053162
Transfer model loss: 0.918467178940773
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 7
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9683680683374405
Transfer model loss: 0.8669954240322113
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 8
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9940508157014847
Transfer model loss: 0.8524713814258575
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 9
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9518608450889587
Transfer model loss: 0.7786897420883179
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 10
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.015029862523079
Transfer model loss: 0.8365787416696548
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 11
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9771789610385895
Transfer model loss: 0.8344853073358536
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 12
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9386196434497833
Transfer model loss: 0.9389815330505371
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 13
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9964592158794403
Transfer model loss: 0.9374122321605682
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 14
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9736804366111755
Transfer model loss: 0.8987155854701996
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 15
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9904567003250122
Transfer model loss: 0.836761474609375
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 16
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.028652235865593
Transfer model loss: 0.8571449816226959
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 17
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.26458078622818
Transfer model loss: 0.8399651497602463
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 18
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9421913921833038
Transfer model loss: 0.8060958087444305
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 19
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9854067713022232
Transfer model loss: 0.8485998660326004
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 20
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9316921532154083
Transfer model loss: 0.8315877467393875
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 21
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9563401192426682
Transfer model loss: 0.8335071057081223
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 22
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9719603359699249
Transfer model loss: 0.8441516607999802
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 23
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9379061460494995
Transfer model loss: 0.8428579270839691
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 24
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9670489281415939
Transfer model loss: 0.8685951977968216
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 25
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0521374195814133
Transfer model loss: 0.8364313095808029
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 26
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9864091873168945
Transfer model loss: 0.8316048979759216
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 27
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9868093580007553
Transfer model loss: 0.8187128454446793
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 28
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9507862627506256
Transfer model loss: 0.8480421602725983
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 29
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.1151437312364578
Transfer model loss: 0.8393882215023041
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 30
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.949638307094574
Transfer model loss: 0.8822612911462784
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Shuffling data...
Epoch: 1
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9552932679653168
Transfer model loss: 0.8540545105934143
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 2
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0297314673662186
Transfer model loss: 0.8297136574983597
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 3
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9822622388601303
Transfer model loss: 0.8257730603218079
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 4
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9733332097530365
Transfer model loss: 0.8205776214599609
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 5
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9352305233478546
Transfer model loss: 0.8395626544952393
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 6
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.99977907538414
Transfer model loss: 0.918467178940773
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 7
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0394148379564285
Transfer model loss: 0.8669954240322113
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 8
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9452688544988632
Transfer model loss: 0.8524713814258575
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 9
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9847268015146255
Transfer model loss: 0.7786897420883179
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 10
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9931773841381073
Transfer model loss: 0.8365787416696548
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 11
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9411157965660095
Transfer model loss: 0.8344853073358536
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 12
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9378562420606613
Transfer model loss: 0.9389815330505371
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 13
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.980117529630661
Transfer model loss: 0.9374122321605682
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 14
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9931097626686096
Transfer model loss: 0.8987155854701996
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 15
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9756651222705841
Transfer model loss: 0.836761474609375
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 16
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9519233405590057
Transfer model loss: 0.8571449816226959
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 17
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9834240525960922
Transfer model loss: 0.8399651497602463
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 18
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9443680793046951
Transfer model loss: 0.8060958087444305
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 19
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.00894133746624
Transfer model loss: 0.8485998660326004
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 20
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9186129420995712
Transfer model loss: 0.8315877467393875
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 21
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.948435440659523
Transfer model loss: 0.8335071057081223
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 22
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0236274898052216
Transfer model loss: 0.8441516607999802
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 23
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9886921644210815
Transfer model loss: 0.8428579270839691
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 24
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9453277289867401
Transfer model loss: 0.8685951977968216
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 25
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9923443645238876
Transfer model loss: 0.8364313095808029
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 26
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9840422719717026
Transfer model loss: 0.8316048979759216
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 27
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.2346171736717224
Transfer model loss: 0.8187128454446793
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 28
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 1.0792904198169708
Transfer model loss: 0.8480421602725983
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 29
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9263758808374405
Transfer model loss: 0.8393882215023041
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########
Epoch: 30
Trained Edgeconv loss: 0.35517989844083786
Untrained Edgeconv loss: 0.9624926298856735
Transfer model loss: 0.8822612911462784
Finetuned transfer model loss: 0.6472149789333344
Baseline loss: 0.4515115022659302
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10678046: <compare> in cluster <dcc> Exited

Job <compare> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Thu Oct 21 17:31:37 2021
Job was executed on host(s) <n-62-11-15>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Thu Oct 21 17:31:39 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Thu Oct 21 17:31:39 2021
Terminated at Thu Oct 21 17:44:19 2021
Results reported at Thu Oct 21 17:44:19 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J compare #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate


python /zhome/2b/7/117471/Thesis/src/models/compare_metalearning.py


------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   730.08 sec.
    Max Memory :                                 2591 MB
    Average Memory :                             2317.12 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9697.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   759 sec.
    Turnaround time :                            762 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10678046> for stderr output of this job.

