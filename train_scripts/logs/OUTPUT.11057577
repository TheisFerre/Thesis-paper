Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9737906455993652
########
Epoch: 2
Meta Train Loss: 0.9469922184944153
########
Epoch: 3
Meta Train Loss: 0.9137132167816162
########
Epoch: 4
Meta Train Loss: 1.015870213508606
########
Epoch: 5
Meta Train Loss: 1.1293009519577026
########
Epoch: 6
Meta Train Loss: 1.1275999546051025
########
Epoch: 7
Meta Train Loss: 0.9805049300193787
########
Epoch: 8
Meta Train Loss: 0.9771174788475037
########
Epoch: 9
Meta Train Loss: 1.0810785293579102
########
Epoch: 10
Meta Train Loss: 0.9792932868003845
########
Epoch: 11
Meta Train Loss: 1.0128073692321777
########
Epoch: 12
Meta Train Loss: 0.9900351762771606
########
Epoch: 13
Meta Train Loss: 0.8808396458625793
########
Epoch: 14
Meta Train Loss: 0.8768935203552246
########
Epoch: 15
Meta Train Loss: 0.9978854060173035
########
Epoch: 16
Meta Train Loss: 0.8555722236633301
########
Epoch: 17
Meta Train Loss: 1.2090237140655518
########
Epoch: 18
Meta Train Loss: 0.7103939056396484
########
Epoch: 19
Meta Train Loss: 0.9265090227127075
########
Epoch: 20
Meta Train Loss: 1.0202789306640625
########
Epoch: 21
Meta Train Loss: 0.8609505295753479
########
Epoch: 22
Meta Train Loss: 1.133296012878418
########
Epoch: 23
Meta Train Loss: 1.056979775428772
########
Epoch: 24
Meta Train Loss: 1.8631987571716309
########
Epoch: 25
Meta Train Loss: 0.9931709170341492
########
Epoch: 26
Meta Train Loss: 0.9578229188919067
########
Epoch: 27
Meta Train Loss: 1.0148053169250488
########
Epoch: 28
Meta Train Loss: 0.8533732891082764
########
Epoch: 29
Meta Train Loss: 0.7971553802490234
########
Epoch: 30
Meta Train Loss: 1.5133605003356934
########
Epoch: 31
Meta Train Loss: 0.7683780193328857
########
Epoch: 32
Meta Train Loss: 0.8534343242645264
########
Epoch: 33
Meta Train Loss: 0.8608860373497009
########
Epoch: 34
Meta Train Loss: 0.8676126599311829
########
Epoch: 35
Meta Train Loss: 0.7045602798461914
########
Epoch: 36
Meta Train Loss: 0.7576698064804077
########
Epoch: 37
Meta Train Loss: 0.7553948760032654
########
Epoch: 38
Meta Train Loss: 0.9856945276260376
########
Epoch: 39
Meta Train Loss: 0.9016587734222412
########
Epoch: 40
Meta Train Loss: 0.7595004439353943
########
Epoch: 41
Meta Train Loss: 0.5411038398742676
########
Epoch: 42
Meta Train Loss: 0.8264539241790771
########
Epoch: 43
Meta Train Loss: 0.7372175455093384
########
Epoch: 44
Meta Train Loss: 0.7293127775192261
########
Epoch: 45
Meta Train Loss: 0.6077568531036377
########
Epoch: 46
Meta Train Loss: 0.6179202795028687
########
Epoch: 47
Meta Train Loss: 0.73878014087677
########
Epoch: 48
Meta Train Loss: 0.9710537195205688
########
Epoch: 49
Meta Train Loss: 0.7966300845146179
########
Epoch: 50
Meta Train Loss: 0.7941235303878784
########
Epoch: 51
Meta Train Loss: 0.8436038494110107
########
Epoch: 52
Meta Train Loss: 0.6497681736946106
########
Epoch: 53
Meta Train Loss: 0.6756678223609924
########
Epoch: 54
Meta Train Loss: 1.4177286624908447
########
Epoch: 55
Meta Train Loss: 0.7653002738952637
########
Epoch: 56
Meta Train Loss: 0.8702367544174194
########
Epoch: 57
Meta Train Loss: 0.5792267918586731
########
Epoch: 58
Meta Train Loss: 0.7030970454216003
########
Epoch: 59
Meta Train Loss: 0.729859471321106
########
Epoch: 60
Meta Train Loss: 0.8707578182220459
########
Epoch: 61
Meta Train Loss: 0.9222787022590637
########
Epoch: 62
Meta Train Loss: 0.7518506646156311
########
Epoch: 63
Meta Train Loss: 0.5317584276199341
########
Epoch: 64
Meta Train Loss: 1.111034631729126
########
Epoch: 65
Meta Train Loss: 0.6176776885986328
########
Epoch: 66
Meta Train Loss: 0.6582115292549133
########
Epoch: 67
Meta Train Loss: 0.7754785418510437
########
Epoch: 68
Meta Train Loss: 1.040325403213501
########
Epoch: 69
Meta Train Loss: 0.8565755486488342
########
Epoch: 70
Meta Train Loss: 0.8574859499931335
########
Epoch: 71
Meta Train Loss: 1.3679531812667847
########
Epoch: 72
Meta Train Loss: 0.5734191536903381
########
Epoch: 73
Meta Train Loss: 0.7713720798492432
########
Epoch: 74
Meta Train Loss: 0.8143484592437744
########
Epoch: 75
Meta Train Loss: 1.0250775814056396
########
Epoch: 76
Meta Train Loss: 0.685536801815033
########
Epoch: 77
Meta Train Loss: 1.0502843856811523
########
Epoch: 78
Meta Train Loss: 0.6906507611274719
########
Epoch: 79
Meta Train Loss: 0.8299499750137329
########
Epoch: 80
Meta Train Loss: 0.6468936204910278
########
Epoch: 81
Meta Train Loss: 0.7370765209197998
########
Epoch: 82
Meta Train Loss: 0.7322829365730286
########
Epoch: 83
Meta Train Loss: 0.7276659607887268
########
Epoch: 84
Meta Train Loss: 0.6044535636901855
########
Epoch: 85
Meta Train Loss: 0.8259708285331726
########
Epoch: 86
Meta Train Loss: 0.5448333621025085
########
Epoch: 87
Meta Train Loss: 0.6191899180412292
########
Epoch: 88
Meta Train Loss: 0.6566269397735596
########
Epoch: 89
Meta Train Loss: 0.6414003372192383
########
Epoch: 90
Meta Train Loss: 0.8245862722396851
########
Epoch: 91
Meta Train Loss: 0.5881574153900146
########
Epoch: 92
Meta Train Loss: 0.6779252886772156
########
Epoch: 93
Meta Train Loss: 0.6684736609458923
########
Epoch: 94
Meta Train Loss: 0.970069408416748
########
Epoch: 95
Meta Train Loss: 0.7584264278411865
########
Epoch: 96
Meta Train Loss: 1.1200048923492432
########
Epoch: 97
Meta Train Loss: 0.6696396470069885
########
Epoch: 98
Meta Train Loss: 0.5116665959358215
########
Epoch: 99
Meta Train Loss: 0.6612488031387329
########
Epoch: 100
Meta Train Loss: 1.1148217916488647
########
Epoch: 101
Meta Train Loss: 0.6623458862304688
########
Epoch: 102
Meta Train Loss: 0.6057611703872681
########
Epoch: 103
Meta Train Loss: 0.624492347240448
########
Epoch: 104
Meta Train Loss: 0.6840199828147888
########
Epoch: 105
Meta Train Loss: 0.7906845808029175
########
Epoch: 106
Meta Train Loss: 0.6316888332366943
########
Epoch: 107
Meta Train Loss: 0.9034271836280823
########
Epoch: 108
Meta Train Loss: 0.8823822736740112
########
Epoch: 109
Meta Train Loss: 0.6973034739494324
########
Epoch: 110
Meta Train Loss: 0.9611440300941467
########
Epoch: 111
Meta Train Loss: 0.822770357131958
########
Epoch: 112
Meta Train Loss: 0.925223171710968
########
Epoch: 113
Meta Train Loss: 0.6117375493049622
########
Epoch: 114
Meta Train Loss: 0.746088981628418
########
Epoch: 115
Meta Train Loss: 0.6964560151100159
########
Epoch: 116
Meta Train Loss: 0.6526520252227783
########
Epoch: 117
Meta Train Loss: 0.767257809638977
########
Epoch: 118
Meta Train Loss: 0.5994587540626526
########
Epoch: 119
Meta Train Loss: 0.6286422610282898
########
Epoch: 120
Meta Train Loss: 0.6314789056777954
########
Epoch: 121
Meta Train Loss: 0.7291831970214844
########
Epoch: 122
Meta Train Loss: 0.7588300704956055
########
Epoch: 123
Meta Train Loss: 0.7197773456573486
########
Epoch: 124
Meta Train Loss: 0.9848421216011047
########
Epoch: 125
Meta Train Loss: 0.8866974115371704
########
Epoch: 126
Meta Train Loss: 0.5788598656654358
########
Epoch: 127
Meta Train Loss: 0.7061723470687866
########
Epoch: 128
Meta Train Loss: 0.8854954242706299
########
Epoch: 129
Meta Train Loss: 0.9211438894271851
########
Epoch: 130
Meta Train Loss: 0.6859278678894043
########
Epoch: 131
Meta Train Loss: 0.6859641671180725
########
Epoch: 132
Meta Train Loss: 0.9899938106536865
########
Epoch: 133
Meta Train Loss: 0.7006334066390991
########
Epoch: 134
Meta Train Loss: 0.7400462031364441
########
Epoch: 135
Meta Train Loss: 0.7718934416770935
########
Epoch: 136
Meta Train Loss: 0.8414344787597656
########
Epoch: 137
Meta Train Loss: 0.5594761967658997
########
Epoch: 138
Meta Train Loss: 0.8430501818656921
########
Epoch: 139
Meta Train Loss: 1.009167194366455
########
Epoch: 140
Meta Train Loss: 0.6637718677520752
########
Epoch: 141
Meta Train Loss: 0.9053139686584473
########
Epoch: 142
Meta Train Loss: 0.5713734030723572
########
Epoch: 143
Meta Train Loss: 0.8646736145019531
########
Epoch: 144
Meta Train Loss: 0.9082350730895996
########
Epoch: 145
Meta Train Loss: 0.6043623685836792
########
Epoch: 146
Meta Train Loss: 0.7453532218933105
########
Epoch: 147
Meta Train Loss: 0.8290057182312012
########
Epoch: 148
Meta Train Loss: 0.5894924402236938
########
Epoch: 149
Meta Train Loss: 0.5236452221870422
########
Epoch: 150
Meta Train Loss: 0.9559003710746765
########
Epoch: 151
Meta Train Loss: 0.8597697019577026
########
Epoch: 152
Meta Train Loss: 0.6687672734260559
########
Epoch: 153
Meta Train Loss: 0.5875809192657471
########
Epoch: 154
Meta Train Loss: 0.950709342956543
########
Epoch: 155
Meta Train Loss: 0.5639771223068237
########
Epoch: 156
Meta Train Loss: 0.5341333150863647
########
Epoch: 157
Meta Train Loss: 0.6160904169082642
########
Epoch: 158
Meta Train Loss: 0.7770967483520508
########
Epoch: 159
Meta Train Loss: 0.6124309301376343
########
Epoch: 160
Meta Train Loss: 0.7634506225585938
########
Epoch: 161
Meta Train Loss: 0.7803260087966919
########
Epoch: 162
Meta Train Loss: 0.8493481278419495
########
Epoch: 163
Meta Train Loss: 0.8597471117973328
########
Epoch: 164
Meta Train Loss: 0.819057047367096
########
Epoch: 165
Meta Train Loss: 0.6941068768501282
########
Epoch: 166
Meta Train Loss: 0.7144502401351929
########
Epoch: 167
Meta Train Loss: 0.8634836077690125
########
Epoch: 168
Meta Train Loss: 0.5234766006469727
########
Epoch: 169
Meta Train Loss: 0.9240895509719849
########
Epoch: 170
Meta Train Loss: 0.7448174953460693
########
Epoch: 171
Meta Train Loss: 0.6857390403747559
########
Epoch: 172
Meta Train Loss: 0.7020228505134583
########
Epoch: 173
Meta Train Loss: 0.7847591638565063
########
Epoch: 174
Meta Train Loss: 0.6838199496269226
########
Epoch: 175
Meta Train Loss: 0.5369553565979004
########
Epoch: 176
Meta Train Loss: 0.6969852447509766
########
Epoch: 177
Meta Train Loss: 0.542095422744751
########
Epoch: 178
Meta Train Loss: 0.7968668937683105
########
Epoch: 179
Meta Train Loss: 0.6574164628982544
########
Epoch: 180
Meta Train Loss: 0.7249103784561157
########
Epoch: 181
Meta Train Loss: 0.5839552283287048
########
Epoch: 182
Meta Train Loss: 0.6415445804595947
########
Epoch: 183
Meta Train Loss: 0.6861902475357056
########
Epoch: 184
Meta Train Loss: 0.5507135391235352
########
Epoch: 185
Meta Train Loss: 0.5533345341682434
########
Epoch: 186
Meta Train Loss: 0.4591752886772156
########
Epoch: 187
Meta Train Loss: 0.9430993795394897
########
Epoch: 188
Meta Train Loss: 0.6980396509170532
########
Epoch: 189
Meta Train Loss: 0.6514456868171692
########
Epoch: 190
Meta Train Loss: 0.5951184034347534
########
Epoch: 191
Meta Train Loss: 0.8692758083343506
########
Epoch: 192
Meta Train Loss: 0.5721114873886108
########
Epoch: 193
Meta Train Loss: 0.5012208819389343
########
Epoch: 194
Meta Train Loss: 0.6972396373748779
########
Epoch: 195
Meta Train Loss: 0.5662875175476074
########
Epoch: 196
Meta Train Loss: 0.4957387447357178
########
Epoch: 197
Meta Train Loss: 0.7305582761764526
########
Epoch: 198
Meta Train Loss: 1.3389149904251099
########
Epoch: 199
Meta Train Loss: 0.6507971286773682
########
Epoch: 200
Meta Train Loss: 0.7374927401542664
########
Epoch: 201
Meta Train Loss: 0.8594096302986145
########
Epoch: 202
Meta Train Loss: 0.5708525776863098
########
Epoch: 203
Meta Train Loss: 68403368.0
########
Epoch: 204
Meta Train Loss: 0.7410122156143188
########
Epoch: 205
Meta Train Loss: 0.9215508699417114
########
Epoch: 206
Meta Train Loss: 0.705800473690033
########
Epoch: 207
Meta Train Loss: 0.7746580839157104
########
Epoch: 208
Meta Train Loss: 0.8180367946624756
########
Epoch: 209
Meta Train Loss: 0.7869992256164551
########
Epoch: 210
Meta Train Loss: 0.8276100754737854
########
Epoch: 211
Meta Train Loss: 0.8153727650642395
########
Epoch: 212
Meta Train Loss: 0.6266049146652222
########
Epoch: 213
Meta Train Loss: 0.8291040062904358
########
Epoch: 214
Meta Train Loss: 0.5825953483581543
########
Epoch: 215
Meta Train Loss: 0.6699379086494446
########
Epoch: 216
Meta Train Loss: 0.6337240934371948
########
Epoch: 217
Meta Train Loss: 0.7433424592018127
########
Epoch: 218
Meta Train Loss: 0.6983952522277832
########
Epoch: 219
Meta Train Loss: 0.7996096014976501
########
Epoch: 220
Meta Train Loss: 0.7909612655639648
########
Epoch: 221
Meta Train Loss: 0.6185325384140015
########
Epoch: 222
Meta Train Loss: 0.4865031838417053
########
Epoch: 223
Meta Train Loss: 1.0701594352722168
########
Epoch: 224
Meta Train Loss: 0.7809114456176758
########
Epoch: 225
Meta Train Loss: 0.5766507387161255
########
Epoch: 226
Meta Train Loss: 0.6632107496261597
########
Epoch: 227
Meta Train Loss: 0.81533282995224
########
Epoch: 228
Meta Train Loss: 0.649246096611023
########
Epoch: 229
Meta Train Loss: 0.5566854476928711
########
Epoch: 230
Meta Train Loss: 0.5311117172241211
########
Epoch: 231
Meta Train Loss: 0.8067078590393066
########
Epoch: 232
Meta Train Loss: 0.6927663087844849
########
Epoch: 233
Meta Train Loss: 0.6136794090270996
########
Epoch: 234
Meta Train Loss: 0.6616778373718262
########
Epoch: 235
Meta Train Loss: 0.8795944452285767
########
Epoch: 236
Meta Train Loss: 0.6432525515556335
########
Epoch: 237
Meta Train Loss: 0.5162920355796814
########
Epoch: 238
Meta Train Loss: 0.8819511532783508
########
Epoch: 239
Meta Train Loss: 0.6040402054786682
########
Epoch: 240
Meta Train Loss: 0.6196154952049255
########
Epoch: 241
Meta Train Loss: 0.4669274687767029
########
Epoch: 242
Meta Train Loss: 0.5812538862228394
########
Epoch: 243
Meta Train Loss: 1.1636085510253906
########
Epoch: 244
Meta Train Loss: 0.6850678324699402
########
Epoch: 245
Meta Train Loss: 0.6791049838066101
########
Epoch: 246
Meta Train Loss: 0.724297046661377
########
Epoch: 247
Meta Train Loss: 0.7215496897697449
########
Epoch: 248
Meta Train Loss: 0.7849717140197754
########
Epoch: 249
Meta Train Loss: 0.6802247166633606
########
Epoch: 250
Meta Train Loss: 0.8029047250747681
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11057577: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Wed Nov 17 16:00:36 2021
Job was executed on host(s) <n-62-20-15>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Wed Nov 17 17:31:47 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Wed Nov 17 17:31:47 2021
Terminated at Wed Nov 17 18:22:49 2021
Results reported at Wed Nov 17 18:22:49 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/aglation-non_augmented
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=10
K_SHOT=5
ADAPTATION_STEPS=10
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=citibike-tripdata,citibike2014,GM,green,LYFT,TLC
LOG_DIR=/zhome/2b/7/117471/Thesis/ablation-study/non-augmented
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10

# citibike-tripdata,citibike2014,GM,green,LYFT,TLC,UBER,yellow

python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --exclude $EXCLUDE --gpu


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3036.16 sec.
    Max Memory :                                 2755 MB
    Average Memory :                             2663.82 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9533.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   3061 sec.
    Turnaround time :                            8533 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.11057577> for stderr output of this job.

