Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9972886443138123
########
Epoch: 2
Meta Train Loss: 1.1061768531799316
########
Epoch: 3
Meta Train Loss: 1.1761420965194702
########
Epoch: 4
Meta Train Loss: 0.848687469959259
########
Epoch: 5
Meta Train Loss: 1.0566551685333252
########
Epoch: 6
Meta Train Loss: 1.1075471639633179
########
Epoch: 7
Meta Train Loss: 1.3912122249603271
########
Epoch: 8
Meta Train Loss: 1.274249792098999
########
Epoch: 9
Meta Train Loss: 0.935488224029541
########
Epoch: 10
Meta Train Loss: 1.0188653469085693
########
Epoch: 11
Meta Train Loss: 1.1747262477874756
########
Epoch: 12
Meta Train Loss: 1.0394598245620728
########
Epoch: 13
Meta Train Loss: 0.9837466478347778
########
Epoch: 14
Meta Train Loss: 0.9572550058364868
########
Epoch: 15
Meta Train Loss: 1.0143444538116455
########
Epoch: 16
Meta Train Loss: 1.056917667388916
########
Epoch: 17
Meta Train Loss: 1.0319117307662964
########
Epoch: 18
Meta Train Loss: 1.0063719749450684
########
Epoch: 19
Meta Train Loss: 1.1770706176757812
########
Epoch: 20
Meta Train Loss: 0.7905275821685791
########
Epoch: 21
Meta Train Loss: 0.9757923483848572
########
Epoch: 22
Meta Train Loss: 1.2893725633621216
########
Epoch: 23
Meta Train Loss: 0.8659276366233826
########
Epoch: 24
Meta Train Loss: 0.9290439486503601
########
Epoch: 25
Meta Train Loss: 1.1676760911941528
########
Epoch: 26
Meta Train Loss: 0.8672289848327637
########
Epoch: 27
Meta Train Loss: 1.1168187856674194
########
Epoch: 28
Meta Train Loss: 0.8480249047279358
########
Epoch: 29
Meta Train Loss: 0.98207688331604
########
Epoch: 30
Meta Train Loss: 1.2033156156539917
########
Epoch: 31
Meta Train Loss: 1.2981061935424805
########
Epoch: 32
Meta Train Loss: 1.0377440452575684
########
Epoch: 33
Meta Train Loss: 0.9255234599113464
########
Epoch: 34
Meta Train Loss: 0.8133180141448975
########
Epoch: 35
Meta Train Loss: 1.101588249206543
########
Epoch: 36
Meta Train Loss: 0.7828076481819153
########
Epoch: 37
Meta Train Loss: 1.0175981521606445
########
Epoch: 38
Meta Train Loss: 1.010326623916626
########
Epoch: 39
Meta Train Loss: 0.8463456630706787
########
Epoch: 40
Meta Train Loss: 0.8217701315879822
########
Epoch: 41
Meta Train Loss: 1.1805205345153809
########
Epoch: 42
Meta Train Loss: 1.0546811819076538
########
Epoch: 43
Meta Train Loss: 1.0757333040237427
########
Epoch: 44
Meta Train Loss: 1.1838982105255127
########
Epoch: 45
Meta Train Loss: 16.09123420715332
########
Epoch: 46
Meta Train Loss: 0.6833377480506897
########
Epoch: 47
Meta Train Loss: 0.84170001745224
########
Epoch: 48
Meta Train Loss: 0.6003766655921936
########
Epoch: 49
Meta Train Loss: 0.8104623556137085
########
Epoch: 50
Meta Train Loss: 0.7306721806526184
########
Epoch: 51
Meta Train Loss: 0.6152988076210022
########
Epoch: 52
Meta Train Loss: 0.742017388343811
########
Epoch: 53
Meta Train Loss: 0.7438951730728149
########
Epoch: 54
Meta Train Loss: 0.7270079851150513
########
Epoch: 55
Meta Train Loss: 0.6547234058380127
########
Epoch: 56
Meta Train Loss: 0.6114299297332764
########
Epoch: 57
Meta Train Loss: 1.0655189752578735
########
Epoch: 58
Meta Train Loss: 8.819674491882324
########
Epoch: 59
Meta Train Loss: 0.7287037968635559
########
Epoch: 60
Meta Train Loss: 0.8383046388626099
########
Epoch: 61
Meta Train Loss: 0.4610098600387573
########
Epoch: 62
Meta Train Loss: 0.6288639307022095
########
Epoch: 63
Meta Train Loss: 0.565710186958313
########
Epoch: 64
Meta Train Loss: 32.66780471801758
########
Epoch: 65
Meta Train Loss: 0.6355133056640625
########
Epoch: 66
Meta Train Loss: 0.6443336606025696
########
Epoch: 67
Meta Train Loss: 0.7651636600494385
########
Epoch: 68
Meta Train Loss: 0.6954837441444397
########
Epoch: 69
Meta Train Loss: 0.6578308939933777
########
Epoch: 70
Meta Train Loss: 0.7067152261734009
########
Epoch: 71
Meta Train Loss: 0.7316832542419434
########
Epoch: 72
Meta Train Loss: 0.6978402733802795
########
Epoch: 73
Meta Train Loss: 0.5480693578720093
########
Epoch: 74
Meta Train Loss: 0.456784725189209
########
Epoch: 75
Meta Train Loss: 0.6398911476135254
########
Epoch: 76
Meta Train Loss: 0.7765937447547913
########
Epoch: 77
Meta Train Loss: 0.6106799244880676
########
Epoch: 78
Meta Train Loss: 0.8500103950500488
########
Epoch: 79
Meta Train Loss: 0.5811248421669006
########
Epoch: 80
Meta Train Loss: 0.44208434224128723
########
Epoch: 81
Meta Train Loss: 0.9647411108016968
########
Epoch: 82
Meta Train Loss: 0.7096840143203735
########
Epoch: 83
Meta Train Loss: 0.9066491723060608
########
Epoch: 84
Meta Train Loss: 0.9610049724578857
########
Epoch: 85
Meta Train Loss: 1.054774522781372
########
Epoch: 86
Meta Train Loss: 0.9052162766456604
########
Epoch: 87
Meta Train Loss: 0.6064243316650391
########
Epoch: 88
Meta Train Loss: 0.578380823135376
########
Epoch: 89
Meta Train Loss: 0.5426767468452454
########
Epoch: 90
Meta Train Loss: 0.6767592430114746
########
Epoch: 91
Meta Train Loss: 0.546205997467041
########
Epoch: 92
Meta Train Loss: 0.5555130243301392
########
Epoch: 93
Meta Train Loss: 0.47000107169151306
########
Epoch: 94
Meta Train Loss: 0.6175285577774048
########
Epoch: 95
Meta Train Loss: 0.6628499627113342
########
Epoch: 96
Meta Train Loss: 0.5651242136955261
########
Epoch: 97
Meta Train Loss: 0.8983816504478455
########
Epoch: 98
Meta Train Loss: 0.5438785552978516
########
Epoch: 99
Meta Train Loss: 0.515597403049469
########
Epoch: 100
Meta Train Loss: 0.6427600383758545
########
Epoch: 101
Meta Train Loss: 1447.4471435546875
########
Epoch: 102
Meta Train Loss: 0.8138049840927124
########
Epoch: 103
Meta Train Loss: 0.6536084413528442
########
Epoch: 104
Meta Train Loss: 0.4908331334590912
########
Epoch: 105
Meta Train Loss: 0.6275792121887207
########
Epoch: 106
Meta Train Loss: 0.5202504396438599
########
Epoch: 107
Meta Train Loss: 0.6403973698616028
########
Epoch: 108
Meta Train Loss: 0.6174489259719849
########
Epoch: 109
Meta Train Loss: 0.6521677374839783
########
Epoch: 110
Meta Train Loss: 0.5556275248527527
########
Epoch: 111
Meta Train Loss: 0.7334531545639038
########
Epoch: 112
Meta Train Loss: 0.6629836559295654
########
Epoch: 113
Meta Train Loss: 0.9665506482124329
########
Epoch: 114
Meta Train Loss: 0.5415601134300232
########
Epoch: 115
Meta Train Loss: 0.6646491885185242
########
Epoch: 116
Meta Train Loss: 0.4375839829444885
########
Epoch: 117
Meta Train Loss: 0.4219501316547394
########
Epoch: 118
Meta Train Loss: 0.7829759120941162
########
Epoch: 119
Meta Train Loss: 0.5439736843109131
########
Epoch: 120
Meta Train Loss: 0.6534031629562378
########
Epoch: 121
Meta Train Loss: 0.5637713670730591
########
Epoch: 122
Meta Train Loss: 0.5581846237182617
########
Epoch: 123
Meta Train Loss: 0.7653082609176636
########
Epoch: 124
Meta Train Loss: 0.7362905740737915
########
Epoch: 125
Meta Train Loss: 0.49199435114860535
########
Epoch: 126
Meta Train Loss: 0.5952295660972595
########
Epoch: 127
Meta Train Loss: 0.6306461095809937
########
Epoch: 128
Meta Train Loss: 0.6565788984298706
########
Epoch: 129
Meta Train Loss: 0.4684913158416748
########
Epoch: 130
Meta Train Loss: 0.7655332684516907
########
Epoch: 131
Meta Train Loss: 0.6428276896476746
########
Epoch: 132
Meta Train Loss: 0.5667215585708618
########
Epoch: 133
Meta Train Loss: 0.7803211808204651
########
Epoch: 134
Meta Train Loss: 0.689556896686554
########
Epoch: 135
Meta Train Loss: 0.7387324571609497
########
Epoch: 136
Meta Train Loss: 0.7010716795921326
########
Epoch: 137
Meta Train Loss: 0.5483769774436951
########
Epoch: 138
Meta Train Loss: 0.573634147644043
########
Epoch: 139
Meta Train Loss: 0.6502693295478821
########
Epoch: 140
Meta Train Loss: 0.6957122087478638
########
Epoch: 141
Meta Train Loss: 0.6087307929992676
########
Epoch: 142
Meta Train Loss: 0.554478645324707
########
Epoch: 143
Meta Train Loss: 0.6969137191772461
########
Epoch: 144
Meta Train Loss: 0.6090219616889954
########
Epoch: 145
Meta Train Loss: 0.7424269914627075
########
Epoch: 146
Meta Train Loss: 0.663105309009552
########
Epoch: 147
Meta Train Loss: 0.6625893712043762
########
Epoch: 148
Meta Train Loss: 0.6131906509399414
########
Epoch: 149
Meta Train Loss: 0.6531202793121338
########
Epoch: 150
Meta Train Loss: 0.7022110819816589
########
Epoch: 151
Meta Train Loss: 0.5976800918579102
########
Epoch: 152
Meta Train Loss: 0.6259339451789856
########
Epoch: 153
Meta Train Loss: 0.8553496599197388
########
Epoch: 154
Meta Train Loss: 0.6023145318031311
########
Epoch: 155
Meta Train Loss: 0.7312049865722656
########
Epoch: 156
Meta Train Loss: 1.0207518339157104
########
Epoch: 157
Meta Train Loss: 0.9867867827415466
########
Epoch: 158
Meta Train Loss: 0.5747981071472168
########
Epoch: 159
Meta Train Loss: 0.6128990650177002
########
Epoch: 160
Meta Train Loss: 0.7724090814590454
########
Epoch: 161
Meta Train Loss: 0.5765857100486755
########
Epoch: 162
Meta Train Loss: 0.5694863200187683
########
Epoch: 163
Meta Train Loss: 0.4793126881122589
########
Epoch: 164
Meta Train Loss: 0.6255900859832764
########
Epoch: 165
Meta Train Loss: 0.6588985919952393
########
Epoch: 166
Meta Train Loss: 0.5816525816917419
########
Epoch: 167
Meta Train Loss: 0.6266380548477173
########
Epoch: 168
Meta Train Loss: 0.7985253930091858
########
Epoch: 169
Meta Train Loss: 0.8712770342826843
########
Epoch: 170
Meta Train Loss: 0.5301252603530884
########
Epoch: 171
Meta Train Loss: 0.5295040011405945
########
Epoch: 172
Meta Train Loss: 0.6151060461997986
########
Epoch: 173
Meta Train Loss: 0.6245116591453552
########
Epoch: 174
Meta Train Loss: 1.0382894277572632
########
Epoch: 175
Meta Train Loss: 0.6238008141517639
########
Epoch: 176
Meta Train Loss: 0.5361356735229492
########
Epoch: 177
Meta Train Loss: 0.42174747586250305
########
Epoch: 178
Meta Train Loss: 0.672095000743866
########
Epoch: 179
Meta Train Loss: 0.512087345123291
########
Epoch: 180
Meta Train Loss: 0.6052764058113098
########
Epoch: 181
Meta Train Loss: 393.57818603515625
########
Epoch: 182
Meta Train Loss: 0.7725157141685486
########
Epoch: 183
Meta Train Loss: 0.5023614764213562
########
Epoch: 184
Meta Train Loss: 0.5428629517555237
########
Epoch: 185
Meta Train Loss: 0.7781004905700684
########
Epoch: 186
Meta Train Loss: 0.6252298951148987
########
Epoch: 187
Meta Train Loss: 0.6438687443733215
########
Epoch: 188
Meta Train Loss: 0.5484235286712646
########
Epoch: 189
Meta Train Loss: 0.7089840769767761
########
Epoch: 190
Meta Train Loss: 0.529008686542511
########
Epoch: 191
Meta Train Loss: 0.5432868599891663
########
Epoch: 192
Meta Train Loss: 0.3914676904678345
########
Epoch: 193
Meta Train Loss: 0.6003972887992859
########
Epoch: 194
Meta Train Loss: 0.6907031536102295
########
Epoch: 195
Meta Train Loss: 0.8389143943786621
########
Epoch: 196
Meta Train Loss: 0.46306559443473816
########
Epoch: 197
Meta Train Loss: 0.8030468821525574
########
Epoch: 198
Meta Train Loss: 0.593274712562561
########
Epoch: 199
Meta Train Loss: 0.47755977511405945
########
Epoch: 200
Meta Train Loss: 0.7487183213233948
########
Epoch: 201
Meta Train Loss: 0.5726343989372253
########
Epoch: 202
Meta Train Loss: 0.9253581166267395
########
Epoch: 203
Meta Train Loss: 0.8704494833946228
########
Epoch: 204
Meta Train Loss: 0.601607620716095
########
Epoch: 205
Meta Train Loss: 0.5653592348098755
########
Epoch: 206
Meta Train Loss: 0.7207664251327515
########
Epoch: 207
Meta Train Loss: 0.8772873282432556
########
Epoch: 208
Meta Train Loss: 0.5228957533836365
########
Epoch: 209
Meta Train Loss: 0.34280580282211304
########
Epoch: 210
Meta Train Loss: 0.5777113437652588
########
Epoch: 211
Meta Train Loss: 0.8954450488090515
########
Epoch: 212
Meta Train Loss: 0.4506933093070984
########
Epoch: 213
Meta Train Loss: 0.5848400592803955
########
Epoch: 214
Meta Train Loss: 0.5246348977088928
########
Epoch: 215
Meta Train Loss: 0.6237807273864746
########
Epoch: 216
Meta Train Loss: 0.7098843455314636
########
Epoch: 217
Meta Train Loss: 0.6251881122589111
########
Epoch: 218
Meta Train Loss: 0.48496556282043457
########
Epoch: 219
Meta Train Loss: 0.5877081155776978
########
Epoch: 220
Meta Train Loss: 0.5682658553123474
########
Epoch: 221
Meta Train Loss: 0.6701543927192688
########
Epoch: 222
Meta Train Loss: 0.6454278826713562
########
Epoch: 223
Meta Train Loss: 0.6183676719665527
########
Epoch: 224
Meta Train Loss: 0.5349907279014587
########
Epoch: 225
Meta Train Loss: 0.7189944386482239
########
Epoch: 226
Meta Train Loss: 0.6375947594642639
########
Epoch: 227
Meta Train Loss: 0.6810858249664307
########
Epoch: 228
Meta Train Loss: 0.6122220158576965
########
Epoch: 229
Meta Train Loss: 0.5370559692382812
########
Epoch: 230
Meta Train Loss: 0.6343439221382141
########
Epoch: 231
Meta Train Loss: 0.5403307676315308
########
Epoch: 232
Meta Train Loss: 0.7510230541229248
########
Epoch: 233
Meta Train Loss: 0.6886555552482605
########
Epoch: 234
Meta Train Loss: 0.6295650005340576
########
Epoch: 235
Meta Train Loss: 0.690439760684967
########
Epoch: 236
Meta Train Loss: 0.3869052231311798
########
Epoch: 237
Meta Train Loss: 0.9478867053985596
########
Epoch: 238
Meta Train Loss: 0.7115846276283264
########
Epoch: 239
Meta Train Loss: 0.5435252785682678
########
Epoch: 240
Meta Train Loss: 0.5301629304885864
########
Epoch: 241
Meta Train Loss: 0.6904405951499939
########
Epoch: 242
Meta Train Loss: 0.5849599838256836
########
Epoch: 243
Meta Train Loss: 0.5836002230644226
########
Epoch: 244
Meta Train Loss: 0.695070207118988
########
Epoch: 245
Meta Train Loss: 0.605301558971405
########
Epoch: 246
Meta Train Loss: 0.6104079484939575
########
Epoch: 247
Meta Train Loss: 0.5939536094665527
########
Epoch: 248
Meta Train Loss: 0.6550747156143188
########
Epoch: 249
Meta Train Loss: 0.4831569492816925
########
Epoch: 250
Meta Train Loss: 0.43041130900382996
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10585215: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Sun Oct 10 15:29:43 2021
Job was executed on host(s) <n-62-11-13>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Sun Oct 10 15:29:45 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Sun Oct 10 15:29:45 2021
Terminated at Sun Oct 10 20:29:24 2021
Results reported at Sun Oct 10 20:29:24 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/metalearning
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=8
K_SHOT=5
ADAPTATION_STEPS=5
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=GM2017
LOG_DIR=/zhome/2b/7/117471/Thesis/metalearning
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10


python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR --exclude $EXCLUDE \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --gpu






------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17942.75 sec.
    Max Memory :                                 4172 MB
    Average Memory :                             4160.57 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               8116.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   17978 sec.
    Turnaround time :                            17981 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10585215> for stderr output of this job.

