Starting:
/zhome/2b/7/117471/Thesis/data/processed/metalearning/GM2017-july-sep-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4913196265697479
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48468077182769775
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47472286224365234
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47000548243522644
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5015093088150024
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.45792290568351746
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5268295407295227
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49049586057662964
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5225096940994263
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47600463032722473
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48346707224845886
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48340898752212524
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4743730425834656
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47802409529685974
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4777967035770416
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.511479914188385
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5206958055496216
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48673707246780396
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.50029456615448
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49835389852523804
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4787641167640686
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4613126814365387
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4795505106449127
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48463815450668335
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48252132534980774
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47750580310821533
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.480193555355072
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4802429676055908
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4938352108001709
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.4085952341556549
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4736267328262329
Baseline loss: 0.1409626454114914
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.3872157633304596
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49877116084098816
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.3915470242500305
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47307538986206055
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.3939054608345032
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5134550333023071
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.4059733748435974
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4659588038921356
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.42082643508911133
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48775747418403625
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.2982938289642334
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48143020272254944
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.39911559224128723
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4862273335456848
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.39433765411376953
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4992206394672394
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.3960031270980835
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4805254638195038
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.40278950333595276
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5282882452011108
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.42100265622138977
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4891129434108734
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.3825943171977997
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4726654589176178
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.40393438935279846
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5004547834396362
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.3773747980594635
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4847627282142639
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.4029586911201477
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5025301575660706
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.3985308110713959
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4651482105255127
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.4126589596271515
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5200613141059875
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.32106614112854004
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4810735583305359
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.3948740065097809
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4845251739025116
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.4076516330242157
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49420365691185
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.3861585557460785
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48099321126937866
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.3844050168991089
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4806952476501465
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.3956628739833832
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4907013475894928
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.3991435170173645
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4806206226348877
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.38929253816604614
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48456746339797974
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.4310135841369629
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4826308488845825
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.39384278655052185
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4699253737926483
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.3919681906700134
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4967055320739746
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.4112519919872284
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5378560423851013
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.4797762632369995
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4701945185661316
Baseline loss: 0.1409626454114914
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.38996031880378723
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5126878023147583
Baseline loss: 0.1409626454114914
########
Epoch: 2
Meta Train Loss: 0.3867785632610321
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49449384212493896
Baseline loss: 0.1409626454114914
########
Epoch: 3
Meta Train Loss: 0.41454797983169556
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5114917755126953
Baseline loss: 0.1409626454114914
########
Epoch: 4
Meta Train Loss: 0.3962070047855377
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.46433010697364807
Baseline loss: 0.1409626454114914
########
Epoch: 5
Meta Train Loss: 0.3724464178085327
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48844850063323975
Baseline loss: 0.1409626454114914
########
Epoch: 6
Meta Train Loss: 0.38196617364883423
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4812367856502533
Baseline loss: 0.1409626454114914
########
Epoch: 7
Meta Train Loss: 0.4097723364830017
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4829212725162506
Baseline loss: 0.1409626454114914
########
Epoch: 8
Meta Train Loss: 0.3821958303451538
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49727296829223633
Baseline loss: 0.1409626454114914
########
Epoch: 9
Meta Train Loss: 0.3762175142765045
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.47334006428718567
Baseline loss: 0.1409626454114914
########
Epoch: 10
Meta Train Loss: 0.37847086787223816
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5035505890846252
Baseline loss: 0.1409626454114914
########
Epoch: 11
Meta Train Loss: 0.42243823409080505
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49399232864379883
Baseline loss: 0.1409626454114914
########
Epoch: 12
Meta Train Loss: 0.3966585099697113
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4786875545978546
Baseline loss: 0.1409626454114914
########
Epoch: 13
Meta Train Loss: 0.41473859548568726
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5032151937484741
Baseline loss: 0.1409626454114914
########
Epoch: 14
Meta Train Loss: 0.3489764630794525
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48455438017845154
Baseline loss: 0.1409626454114914
########
Epoch: 15
Meta Train Loss: 0.39173755049705505
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5043931603431702
Baseline loss: 0.1409626454114914
########
Epoch: 16
Meta Train Loss: 0.37836953997612
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.46529850363731384
Baseline loss: 0.1409626454114914
########
Epoch: 17
Meta Train Loss: 0.4397837817668915
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5199589133262634
Baseline loss: 0.1409626454114914
########
Epoch: 18
Meta Train Loss: 0.3786134719848633
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4781145751476288
Baseline loss: 0.1409626454114914
########
Epoch: 19
Meta Train Loss: 0.37699076533317566
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4798564314842224
Baseline loss: 0.1409626454114914
########
Epoch: 20
Meta Train Loss: 0.3799598515033722
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4901978671550751
Baseline loss: 0.1409626454114914
########
Epoch: 21
Meta Train Loss: 0.38304761052131653
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48250648379325867
Baseline loss: 0.1409626454114914
########
Epoch: 22
Meta Train Loss: 0.37770965695381165
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.48842376470565796
Baseline loss: 0.1409626454114914
########
Epoch: 23
Meta Train Loss: 0.40624260902404785
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4904199540615082
Baseline loss: 0.1409626454114914
########
Epoch: 24
Meta Train Loss: 0.39486005902290344
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4803016483783722
Baseline loss: 0.1409626454114914
########
Epoch: 25
Meta Train Loss: 0.393491268157959
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4906827509403229
Baseline loss: 0.1409626454114914
########
Epoch: 26
Meta Train Loss: 0.39145076274871826
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.483929842710495
Baseline loss: 0.1409626454114914
########
Epoch: 27
Meta Train Loss: 0.4117629826068878
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.46783167123794556
Baseline loss: 0.1409626454114914
########
Epoch: 28
Meta Train Loss: 0.4028792381286621
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.49324679374694824
Baseline loss: 0.1409626454114914
########
Epoch: 29
Meta Train Loss: 0.4102856516838074
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.5178250670433044
Baseline loss: 0.1409626454114914
########
Epoch: 30
Meta Train Loss: 0.40677037835121155
Finetuned loss: 0.13622617721557617
Trained Edgeconv loss: 0.13101226091384888
Untrained Edgeconv loss: 0.4812476634979248
Baseline loss: 0.1409626454114914
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/yellow-taxi2020-nov-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0367395877838135
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0925356149673462
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0577064752578735
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.06373929977417
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1150602102279663
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0464973449707031
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0627977848052979
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0525848865509033
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0459184646606445
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0344713926315308
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0597131252288818
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0344856977462769
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.037110686302185
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0706461668014526
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0345360040664673
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0421946048736572
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0594987869262695
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0885181427001953
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0594022274017334
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0573724508285522
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0453699827194214
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.071377158164978
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.035895586013794
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0463122129440308
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0550577640533447
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0443254709243774
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0731196403503418
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0485042333602905
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0451321601867676
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.860042154788971
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.052748203277588
Baseline loss: 1.3998377323150635
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.8405974507331848
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0550535917282104
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.846551239490509
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.5167441368103027
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.8335510492324829
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0592554807662964
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.8376668095588684
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0690261125564575
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.8886460661888123
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.097166895866394
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.838998019695282
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0416845083236694
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.8611292839050293
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1053632497787476
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.8890166282653809
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1382558345794678
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.8356859087944031
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.071251630783081
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.8670830726623535
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0482174158096313
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.834139883518219
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0698989629745483
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.8596174120903015
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0896519422531128
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.8434280157089233
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0398235321044922
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.8897433280944824
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.042319893836975
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.8688708543777466
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0372028350830078
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.8794997930526733
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0887629985809326
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.8416903614997864
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1045148372650146
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.8624768257141113
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.045534610748291
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.8438394665718079
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0487666130065918
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.8400499820709229
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.059910535812378
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.8378952741622925
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0467429161071777
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.8576445579528809
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0861936807632446
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.9184080362319946
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.068466067314148
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.8691735863685608
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0453299283981323
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.8717554211616516
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0499024391174316
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.8388792872428894
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0842026472091675
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.8354548215866089
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.03531813621521
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.8496824502944946
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0493797063827515
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.8386527895927429
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0500694513320923
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.8336785435676575
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.068167805671692
Baseline loss: 1.3998377323150635
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.8476066589355469
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0809810161590576
Baseline loss: 1.3998377323150635
########
Epoch: 2
Meta Train Loss: 0.8335772752761841
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0552451610565186
Baseline loss: 1.3998377323150635
########
Epoch: 3
Meta Train Loss: 0.8408957123756409
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.042864203453064
Baseline loss: 1.3998377323150635
########
Epoch: 4
Meta Train Loss: 0.8406916856765747
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0407249927520752
Baseline loss: 1.3998377323150635
########
Epoch: 5
Meta Train Loss: 0.8510318398475647
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.093662977218628
Baseline loss: 1.3998377323150635
########
Epoch: 6
Meta Train Loss: 0.8331131935119629
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0382810831069946
Baseline loss: 1.3998377323150635
########
Epoch: 7
Meta Train Loss: 0.85438472032547
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0290471315383911
Baseline loss: 1.3998377323150635
########
Epoch: 8
Meta Train Loss: 0.8351009488105774
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1210832595825195
Baseline loss: 1.3998377323150635
########
Epoch: 9
Meta Train Loss: 0.8515890836715698
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0771502256393433
Baseline loss: 1.3998377323150635
########
Epoch: 10
Meta Train Loss: 0.8547111749649048
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0711619853973389
Baseline loss: 1.3998377323150635
########
Epoch: 11
Meta Train Loss: 0.8370873928070068
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0638564825057983
Baseline loss: 1.3998377323150635
########
Epoch: 12
Meta Train Loss: 0.8460103273391724
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0473953485488892
Baseline loss: 1.3998377323150635
########
Epoch: 13
Meta Train Loss: 0.8807417154312134
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0673482418060303
Baseline loss: 1.3998377323150635
########
Epoch: 14
Meta Train Loss: 0.8501140475273132
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0438495874404907
Baseline loss: 1.3998377323150635
########
Epoch: 15
Meta Train Loss: 0.861268162727356
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0569738149642944
Baseline loss: 1.3998377323150635
########
Epoch: 16
Meta Train Loss: 0.862775444984436
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0636283159255981
Baseline loss: 1.3998377323150635
########
Epoch: 17
Meta Train Loss: 0.8400157690048218
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.083478569984436
Baseline loss: 1.3998377323150635
########
Epoch: 18
Meta Train Loss: 0.8503037691116333
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.066695213317871
Baseline loss: 1.3998377323150635
########
Epoch: 19
Meta Train Loss: 0.8500158190727234
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.1163530349731445
Baseline loss: 1.3998377323150635
########
Epoch: 20
Meta Train Loss: 0.8630818128585815
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0454879999160767
Baseline loss: 1.3998377323150635
########
Epoch: 21
Meta Train Loss: 0.8442712426185608
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0484472513198853
Baseline loss: 1.3998377323150635
########
Epoch: 22
Meta Train Loss: 0.8375318050384521
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0480380058288574
Baseline loss: 1.3998377323150635
########
Epoch: 23
Meta Train Loss: 0.8481915593147278
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0329419374465942
Baseline loss: 1.3998377323150635
########
Epoch: 24
Meta Train Loss: 0.8374108076095581
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.042651891708374
Baseline loss: 1.3998377323150635
########
Epoch: 25
Meta Train Loss: 0.8387139439582825
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0681577920913696
Baseline loss: 1.3998377323150635
########
Epoch: 26
Meta Train Loss: 0.8587259650230408
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0614871978759766
Baseline loss: 1.3998377323150635
########
Epoch: 27
Meta Train Loss: 0.8358442187309265
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.06205153465271
Baseline loss: 1.3998377323150635
########
Epoch: 28
Meta Train Loss: 0.8549383878707886
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0437017679214478
Baseline loss: 1.3998377323150635
########
Epoch: 29
Meta Train Loss: 0.8391433954238892
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0410797595977783
Baseline loss: 1.3998377323150635
########
Epoch: 30
Meta Train Loss: 0.8330880999565125
Finetuned loss: 0.8310510516166687
Trained Edgeconv loss: 0.8055968880653381
Untrained Edgeconv loss: 1.0458673238754272
Baseline loss: 1.3998377323150635
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/LYFT2014-july-sep-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.351136565208435
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.364587426185608
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3620916604995728
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3517546653747559
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3812215328216553
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.351784348487854
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.372826099395752
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3584662675857544
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.392983317375183
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3519669771194458
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3598724603652954
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3530893325805664
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3497776985168457
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.352480173110962
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3481740951538086
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3970847129821777
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.387257695198059
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3743022680282593
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.386022925376892
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3681336641311646
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3543410301208496
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3466107845306396
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.349501132965088
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3599059581756592
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3558595180511475
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3462951183319092
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3597713708877563
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.359640121459961
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3626939058303833
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1720517873764038
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3463332653045654
Baseline loss: 1.6722253561019897
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1866496801376343
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.4630424976348877
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.1886957883834839
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.5045241117477417
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.1775845289230347
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3621416091918945
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.1807072162628174
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3520368337631226
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.180321455001831
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3751190900802612
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1758646965026855
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.356095790863037
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1814746856689453
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3787310123443604
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.1903682947158813
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.386190414428711
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.1772178411483765
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3696192502975464
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.1863179206848145
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.350421667098999
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1735275983810425
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.354491949081421
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.1765363216400146
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3465276956558228
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.2190673351287842
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3752427101135254
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1743048429489136
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3386539220809937
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.1924039125442505
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3791424036026
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1721739768981934
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3594557046890259
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.187519907951355
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3638969659805298
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1902203559875488
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.37740159034729
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1726760864257812
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3813773393630981
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1830062866210938
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3773229122161865
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.1784191131591797
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3663640022277832
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1808017492294312
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3576003313064575
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1724656820297241
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.371535062789917
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.181105136871338
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3731589317321777
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1780246496200562
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3602852821350098
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.1762943267822266
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3528040647506714
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 2.2739009857177734
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.343813419342041
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1795332431793213
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.38218092918396
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1754310131072998
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3945938348770142
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1859945058822632
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3613184690475464
Baseline loss: 1.6722253561019897
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.1726152896881104
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3770314455032349
Baseline loss: 1.6722253561019897
########
Epoch: 2
Meta Train Loss: 1.188683271408081
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.4178249835968018
Baseline loss: 1.6722253561019897
########
Epoch: 3
Meta Train Loss: 1.182715892791748
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3741531372070312
Baseline loss: 1.6722253561019897
########
Epoch: 4
Meta Train Loss: 1.181898593902588
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3488333225250244
Baseline loss: 1.6722253561019897
########
Epoch: 5
Meta Train Loss: 1.1700489521026611
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.375807285308838
Baseline loss: 1.6722253561019897
########
Epoch: 6
Meta Train Loss: 1.1692103147506714
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3566068410873413
Baseline loss: 1.6722253561019897
########
Epoch: 7
Meta Train Loss: 1.1791054010391235
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3550424575805664
Baseline loss: 1.6722253561019897
########
Epoch: 8
Meta Train Loss: 1.192461609840393
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.387000560760498
Baseline loss: 1.6722253561019897
########
Epoch: 9
Meta Train Loss: 1.2219990491867065
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3618980646133423
Baseline loss: 1.6722253561019897
########
Epoch: 10
Meta Train Loss: 1.172458529472351
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.362350344657898
Baseline loss: 1.6722253561019897
########
Epoch: 11
Meta Train Loss: 1.1847705841064453
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3541810512542725
Baseline loss: 1.6722253561019897
########
Epoch: 12
Meta Train Loss: 1.169918179512024
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3462326526641846
Baseline loss: 1.6722253561019897
########
Epoch: 13
Meta Train Loss: 1.1952069997787476
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3626900911331177
Baseline loss: 1.6722253561019897
########
Epoch: 14
Meta Train Loss: 1.1942775249481201
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3383350372314453
Baseline loss: 1.6722253561019897
########
Epoch: 15
Meta Train Loss: 1.176550269126892
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3636683225631714
Baseline loss: 1.6722253561019897
########
Epoch: 16
Meta Train Loss: 1.1815770864486694
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3522698879241943
Baseline loss: 1.6722253561019897
########
Epoch: 17
Meta Train Loss: 1.1800236701965332
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.362234354019165
Baseline loss: 1.6722253561019897
########
Epoch: 18
Meta Train Loss: 1.1784160137176514
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3605856895446777
Baseline loss: 1.6722253561019897
########
Epoch: 19
Meta Train Loss: 1.1853548288345337
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.369855284690857
Baseline loss: 1.6722253561019897
########
Epoch: 20
Meta Train Loss: 1.1699398756027222
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3763970136642456
Baseline loss: 1.6722253561019897
########
Epoch: 21
Meta Train Loss: 1.1756789684295654
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3643898963928223
Baseline loss: 1.6722253561019897
########
Epoch: 22
Meta Train Loss: 1.1801419258117676
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3625304698944092
Baseline loss: 1.6722253561019897
########
Epoch: 23
Meta Train Loss: 1.1721181869506836
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3689197301864624
Baseline loss: 1.6722253561019897
########
Epoch: 24
Meta Train Loss: 1.1738733053207397
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.35868501663208
Baseline loss: 1.6722253561019897
########
Epoch: 25
Meta Train Loss: 1.1732256412506104
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.362076997756958
Baseline loss: 1.6722253561019897
########
Epoch: 26
Meta Train Loss: 1.17402184009552
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.351067304611206
Baseline loss: 1.6722253561019897
########
Epoch: 27
Meta Train Loss: 1.16994047164917
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3398915529251099
Baseline loss: 1.6722253561019897
########
Epoch: 28
Meta Train Loss: 1.1704139709472656
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.3817704916000366
Baseline loss: 1.6722253561019897
########
Epoch: 29
Meta Train Loss: 1.1719999313354492
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.374391794204712
Baseline loss: 1.6722253561019897
########
Epoch: 30
Meta Train Loss: 1.1712008714675903
Finetuned loss: 1.1657803058624268
Trained Edgeconv loss: 1.1889253854751587
Untrained Edgeconv loss: 1.349432110786438
Baseline loss: 1.6722253561019897
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/UBER2015-jan-june-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1094002723693848
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1082464456558228
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1170425415039062
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0970484018325806
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1170803308486938
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1079479455947876
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1239495277404785
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.116360068321228
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.143099069595337
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0959763526916504
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1031986474990845
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0998107194900513
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1118310689926147
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1136574745178223
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0977327823638916
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1084295511245728
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1154847145080566
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1150368452072144
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1178457736968994
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.110300898551941
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1019232273101807
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.104276180267334
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0957742929458618
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1134897470474243
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.117621660232544
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1022162437438965
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1115645170211792
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1216938495635986
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1047388315200806
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7377680540084839
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0958901643753052
Baseline loss: 0.9849832057952881
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7464540600776672
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.2082481384277344
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7523477673530579
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.3918737173080444
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7374118566513062
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.121272325515747
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 4.86879825592041
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1069326400756836
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7411990761756897
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1255491971969604
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.740938663482666
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1030471324920654
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7411461472511292
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.108771800994873
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.749141275882721
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1351268291473389
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.7456675171852112
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1021052598953247
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7405640482902527
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1113660335540771
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7423410415649414
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1298807859420776
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7539328336715698
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0996979475021362
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7527146339416504
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1076172590255737
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7399412989616394
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0943689346313477
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7417717576026917
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.105380654335022
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7669736742973328
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1111347675323486
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7358948588371277
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1314445734024048
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7364104390144348
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0953060388565063
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7423930764198303
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1463052034378052
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.8432031869888306
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0988703966140747
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.7599378228187561
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.104200839996338
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7416644096374512
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1050342321395874
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7418163418769836
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1058764457702637
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7379341125488281
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1011043787002563
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7751688957214355
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1004775762557983
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7386525273323059
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.109983205795288
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7645403146743774
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0881366729736328
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.785437285900116
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1179217100143433
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7678610682487488
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1054491996765137
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7801697850227356
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.098599910736084
Baseline loss: 0.9849832057952881
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.7457915544509888
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.116676926612854
Baseline loss: 0.9849832057952881
########
Epoch: 2
Meta Train Loss: 0.7343870401382446
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.122564673423767
Baseline loss: 0.9849832057952881
########
Epoch: 3
Meta Train Loss: 0.7375801801681519
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1106131076812744
Baseline loss: 0.9849832057952881
########
Epoch: 4
Meta Train Loss: 0.7441854476928711
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1058335304260254
Baseline loss: 0.9849832057952881
########
Epoch: 5
Meta Train Loss: 0.7422087788581848
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.116265892982483
Baseline loss: 0.9849832057952881
########
Epoch: 6
Meta Train Loss: 0.7495810985565186
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1117111444473267
Baseline loss: 0.9849832057952881
########
Epoch: 7
Meta Train Loss: 0.7541530132293701
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1122888326644897
Baseline loss: 0.9849832057952881
########
Epoch: 8
Meta Train Loss: 0.7621747255325317
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1230878829956055
Baseline loss: 0.9849832057952881
########
Epoch: 9
Meta Train Loss: 0.741818368434906
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0996439456939697
Baseline loss: 0.9849832057952881
########
Epoch: 10
Meta Train Loss: 0.7394078373908997
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.111531138420105
Baseline loss: 0.9849832057952881
########
Epoch: 11
Meta Train Loss: 0.7608311772346497
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1258472204208374
Baseline loss: 0.9849832057952881
########
Epoch: 12
Meta Train Loss: 0.7349145412445068
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0974220037460327
Baseline loss: 0.9849832057952881
########
Epoch: 13
Meta Train Loss: 0.7313789129257202
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1008206605911255
Baseline loss: 0.9849832057952881
########
Epoch: 14
Meta Train Loss: 0.7419418692588806
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0955718755722046
Baseline loss: 0.9849832057952881
########
Epoch: 15
Meta Train Loss: 0.7351241707801819
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1068577766418457
Baseline loss: 0.9849832057952881
########
Epoch: 16
Meta Train Loss: 0.7618462443351746
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.109782099723816
Baseline loss: 0.9849832057952881
########
Epoch: 17
Meta Train Loss: 0.7364850640296936
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1149622201919556
Baseline loss: 0.9849832057952881
########
Epoch: 18
Meta Train Loss: 0.7443094253540039
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0969070196151733
Baseline loss: 0.9849832057952881
########
Epoch: 19
Meta Train Loss: 0.7478917241096497
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1213655471801758
Baseline loss: 0.9849832057952881
########
Epoch: 20
Meta Train Loss: 0.751947820186615
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1003940105438232
Baseline loss: 0.9849832057952881
########
Epoch: 21
Meta Train Loss: 0.7320336103439331
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1024646759033203
Baseline loss: 0.9849832057952881
########
Epoch: 22
Meta Train Loss: 0.7312830686569214
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0996414422988892
Baseline loss: 0.9849832057952881
########
Epoch: 23
Meta Train Loss: 0.7440291047096252
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1065094470977783
Baseline loss: 0.9849832057952881
########
Epoch: 24
Meta Train Loss: 0.7479890584945679
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0993492603302002
Baseline loss: 0.9849832057952881
########
Epoch: 25
Meta Train Loss: 0.7704651355743408
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0973927974700928
Baseline loss: 0.9849832057952881
########
Epoch: 26
Meta Train Loss: 0.7395240664482117
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1097816228866577
Baseline loss: 0.9849832057952881
########
Epoch: 27
Meta Train Loss: 0.7578989863395691
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0899345874786377
Baseline loss: 0.9849832057952881
########
Epoch: 28
Meta Train Loss: 0.7480869889259338
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1204102039337158
Baseline loss: 0.9849832057952881
########
Epoch: 29
Meta Train Loss: 0.7458372116088867
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.1084299087524414
Baseline loss: 0.9849832057952881
########
Epoch: 30
Meta Train Loss: 0.7540631294250488
Finetuned loss: 0.701749324798584
Trained Edgeconv loss: 0.6685996055603027
Untrained Edgeconv loss: 1.0961195230484009
Baseline loss: 0.9849832057952881
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/TLC2018-FHV-aug-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9376985430717468
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9456560611724854
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9484923481941223
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9548320174217224
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0030452013015747
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9553759098052979
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0115059614181519
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9924414753913879
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0275096893310547
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9550331830978394
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9645947217941284
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9517157673835754
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9801419377326965
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9699686765670776
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9436296224594116
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9776069521903992
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0482620000839233
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.97818922996521
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0306373834609985
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9534464478492737
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9468361735343933
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9421424269676208
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.948642373085022
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9673512578010559
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9707230925559998
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9678338766098022
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9787893295288086
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9615800976753235
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9569540023803711
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.47380727529525757
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9459384083747864
Baseline loss: 0.44635626673698425
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.48548221588134766
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.1634166240692139
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.6076323390007019
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.6659659147262573
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.7347045540809631
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0480287075042725
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.5861476063728333
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9398606419563293
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.4294244945049286
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9550673365592957
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.682616651058197
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.965360701084137
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.581882655620575
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9509850740432739
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.8012454509735107
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0135180950164795
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.6762933135032654
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0089393854141235
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.4422944188117981
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.951797366142273
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.7746529579162598
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9922735095024109
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.652418315410614
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9726737141609192
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.5104092955589294
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.990964412689209
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.5031205415725708
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9445204734802246
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.4678572714328766
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.993283212184906
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.4920821487903595
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9638488292694092
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.5468093752861023
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.961573600769043
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.4112476706504822
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.967115044593811
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.602474570274353
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.033969521522522
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.49029839038848877
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9620233178138733
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.5006634593009949
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9684577584266663
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.48121634125709534
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0056325197219849
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.4308548867702484
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9621095061302185
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.4740791618824005
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9490589499473572
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.4122791588306427
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9567437767982483
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.5008763670921326
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9476877450942993
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.4238465130329132
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9357256293296814
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.4683949649333954
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9804133176803589
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.5165045261383057
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.040377140045166
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.6284024715423584
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9611321687698364
Baseline loss: 0.44635626673698425
########
Shuffling data...
Epoch: 1
Meta Train Loss: 0.427330881357193
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0167369842529297
Baseline loss: 0.44635626673698425
########
Epoch: 2
Meta Train Loss: 0.4881395995616913
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0062897205352783
Baseline loss: 0.44635626673698425
########
Epoch: 3
Meta Train Loss: 0.5168956518173218
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0049793720245361
Baseline loss: 0.44635626673698425
########
Epoch: 4
Meta Train Loss: 0.4740898609161377
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9473339915275574
Baseline loss: 0.44635626673698425
########
Epoch: 5
Meta Train Loss: 0.4274325966835022
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0449224710464478
Baseline loss: 0.44635626673698425
########
Epoch: 6
Meta Train Loss: 0.4332427978515625
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9543829560279846
Baseline loss: 0.44635626673698425
########
Epoch: 7
Meta Train Loss: 0.4735393226146698
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9404504895210266
Baseline loss: 0.44635626673698425
########
Epoch: 8
Meta Train Loss: 0.5283860564231873
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9540181159973145
Baseline loss: 0.44635626673698425
########
Epoch: 9
Meta Train Loss: 0.48038601875305176
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9459859132766724
Baseline loss: 0.44635626673698425
########
Epoch: 10
Meta Train Loss: 0.4426327347755432
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9713848829269409
Baseline loss: 0.44635626673698425
########
Epoch: 11
Meta Train Loss: 0.562657356262207
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9646061062812805
Baseline loss: 0.44635626673698425
########
Epoch: 12
Meta Train Loss: 0.5391572713851929
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9571534395217896
Baseline loss: 0.44635626673698425
########
Epoch: 13
Meta Train Loss: 0.46614497900009155
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9727481007575989
Baseline loss: 0.44635626673698425
########
Epoch: 14
Meta Train Loss: 0.5758832693099976
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9834448099136353
Baseline loss: 0.44635626673698425
########
Epoch: 15
Meta Train Loss: 0.42045754194259644
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9682859182357788
Baseline loss: 0.44635626673698425
########
Epoch: 16
Meta Train Loss: 0.5856953263282776
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 1.0042365789413452
Baseline loss: 0.44635626673698425
########
Epoch: 17
Meta Train Loss: 0.500646710395813
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.943162202835083
Baseline loss: 0.44635626673698425
########
Epoch: 18
Meta Train Loss: 0.500320315361023
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9831402897834778
Baseline loss: 0.44635626673698425
########
Epoch: 19
Meta Train Loss: 0.5346119999885559
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9749258756637573
Baseline loss: 0.44635626673698425
########
Epoch: 20
Meta Train Loss: 0.4430762827396393
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9561448693275452
Baseline loss: 0.44635626673698425
########
Epoch: 21
Meta Train Loss: 0.4151059091091156
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9470775127410889
Baseline loss: 0.44635626673698425
########
Epoch: 22
Meta Train Loss: 0.4699985980987549
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9616639018058777
Baseline loss: 0.44635626673698425
########
Epoch: 23
Meta Train Loss: 0.4778293967247009
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9796543121337891
Baseline loss: 0.44635626673698425
########
Epoch: 24
Meta Train Loss: 0.452388733625412
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9479050040245056
Baseline loss: 0.44635626673698425
########
Epoch: 25
Meta Train Loss: 0.4591597020626068
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9748316407203674
Baseline loss: 0.44635626673698425
########
Epoch: 26
Meta Train Loss: 0.5449724197387695
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9665645360946655
Baseline loss: 0.44635626673698425
########
Epoch: 27
Meta Train Loss: 0.47279343008995056
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.960852324962616
Baseline loss: 0.44635626673698425
########
Epoch: 28
Meta Train Loss: 0.4321984648704529
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.963448166847229
Baseline loss: 0.44635626673698425
########
Epoch: 29
Meta Train Loss: 0.431735098361969
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.9850603342056274
Baseline loss: 0.44635626673698425
########
Epoch: 30
Meta Train Loss: 0.5854426622390747
Finetuned loss: 0.4390462636947632
Trained Edgeconv loss: 0.3770890235900879
Untrained Edgeconv loss: 0.964184045791626
Baseline loss: 0.44635626673698425
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/T-Drive-taxi-pickups-GRID.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0882344245910645
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0953550338745117
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0905945301055908
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0958781242370605
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1076310873031616
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.095656156539917
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0908740758895874
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0945639610290527
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0902705192565918
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0949831008911133
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0948439836502075
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0897184610366821
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1024367809295654
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1110785007476807
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0954254865646362
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1225769519805908
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0995169878005981
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.093998670578003
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.088780403137207
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1116056442260742
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1104191541671753
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.098863124847412
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1044684648513794
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0996330976486206
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1075698137283325
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0952157974243164
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1193848848342896
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0897400379180908
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1217654943466187
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.119136095046997
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0968173742294312
Baseline loss: 2.267239809036255
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.107548475265503
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1268386840820312
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.0889837741851807
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1435502767562866
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.1139354705810547
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1422853469848633
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.0928443670272827
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1414093971252441
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.098685622215271
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1807223558425903
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.0960466861724854
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1113930940628052
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.1698698997497559
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0943506956100464
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.1084719896316528
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1107125282287598
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.1435374021530151
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.088630199432373
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.0895644426345825
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1131603717803955
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.1057581901550293
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0908639430999756
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.1423101425170898
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.10078763961792
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.0959774255752563
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1047663688659668
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.0817545652389526
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.088086485862732
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.0894755125045776
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.158198595046997
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.1182544231414795
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1010500192642212
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.0968856811523438
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1062968969345093
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.1138039827346802
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1240227222442627
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.1179709434509277
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0997117757797241
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.104364275932312
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1207051277160645
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.1277559995651245
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1158628463745117
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.1161648035049438
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1208022832870483
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.0923476219177246
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1041985750198364
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.0907583236694336
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0839602947235107
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.1527858972549438
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0937933921813965
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.1606658697128296
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.122739553451538
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.152225375175476
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0915368795394897
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.0890660285949707
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.205994963645935
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.0980675220489502
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.110926628112793
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.1152985095977783
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0962979793548584
Baseline loss: 2.267239809036255
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.096221685409546
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.095345377922058
Baseline loss: 2.267239809036255
########
Epoch: 2
Meta Train Loss: 1.088585615158081
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1391658782958984
Baseline loss: 2.267239809036255
########
Epoch: 3
Meta Train Loss: 1.0957164764404297
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1165398359298706
Baseline loss: 2.267239809036255
########
Epoch: 4
Meta Train Loss: 1.0928677320480347
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1131563186645508
Baseline loss: 2.267239809036255
########
Epoch: 5
Meta Train Loss: 1.096471905708313
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1163017749786377
Baseline loss: 2.267239809036255
########
Epoch: 6
Meta Train Loss: 1.0839264392852783
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1366585493087769
Baseline loss: 2.267239809036255
########
Epoch: 7
Meta Train Loss: 1.0928102731704712
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0960736274719238
Baseline loss: 2.267239809036255
########
Epoch: 8
Meta Train Loss: 1.0900180339813232
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1105613708496094
Baseline loss: 2.267239809036255
########
Epoch: 9
Meta Train Loss: 1.0882561206817627
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0868538618087769
Baseline loss: 2.267239809036255
########
Epoch: 10
Meta Train Loss: 1.090810775756836
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.109000563621521
Baseline loss: 2.267239809036255
########
Epoch: 11
Meta Train Loss: 1.0913889408111572
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0884088277816772
Baseline loss: 2.267239809036255
########
Epoch: 12
Meta Train Loss: 1.0918030738830566
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1030315160751343
Baseline loss: 2.267239809036255
########
Epoch: 13
Meta Train Loss: 1.0910096168518066
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0925345420837402
Baseline loss: 2.267239809036255
########
Epoch: 14
Meta Train Loss: 1.0948799848556519
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.084969162940979
Baseline loss: 2.267239809036255
########
Epoch: 15
Meta Train Loss: 1.097840428352356
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1270427703857422
Baseline loss: 2.267239809036255
########
Epoch: 16
Meta Train Loss: 1.0980507135391235
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.106986403465271
Baseline loss: 2.267239809036255
########
Epoch: 17
Meta Train Loss: 1.101690411567688
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0895668268203735
Baseline loss: 2.267239809036255
########
Epoch: 18
Meta Train Loss: 1.0986106395721436
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.126460313796997
Baseline loss: 2.267239809036255
########
Epoch: 19
Meta Train Loss: 1.0976251363754272
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0999846458435059
Baseline loss: 2.267239809036255
########
Epoch: 20
Meta Train Loss: 1.097161889076233
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1170214414596558
Baseline loss: 2.267239809036255
########
Epoch: 21
Meta Train Loss: 1.0953834056854248
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1092873811721802
Baseline loss: 2.267239809036255
########
Epoch: 22
Meta Train Loss: 1.1065868139266968
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0913671255111694
Baseline loss: 2.267239809036255
########
Epoch: 23
Meta Train Loss: 1.0896728038787842
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1091582775115967
Baseline loss: 2.267239809036255
########
Epoch: 24
Meta Train Loss: 1.0891976356506348
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0834227800369263
Baseline loss: 2.267239809036255
########
Epoch: 25
Meta Train Loss: 1.1113433837890625
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0926282405853271
Baseline loss: 2.267239809036255
########
Epoch: 26
Meta Train Loss: 1.0908464193344116
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1140841245651245
Baseline loss: 2.267239809036255
########
Epoch: 27
Meta Train Loss: 1.1256953477859497
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0906596183776855
Baseline loss: 2.267239809036255
########
Epoch: 28
Meta Train Loss: 1.08634352684021
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1524014472961426
Baseline loss: 2.267239809036255
########
Epoch: 29
Meta Train Loss: 1.084560513496399
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.1120939254760742
Baseline loss: 2.267239809036255
########
Epoch: 30
Meta Train Loss: 1.094590187072754
Finetuned loss: 1.0889883041381836
Trained Edgeconv loss: 1.0735780000686646
Untrained Edgeconv loss: 1.0981119871139526
Baseline loss: 2.267239809036255
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/GM2017-july-sep-REGION.pkl
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.099570393562317
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1149252653121948
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1041107177734375
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0980936288833618
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.117270588874817
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0930697917938232
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1336179971694946
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1110997200012207
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.145999789237976
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0989538431167603
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.105137586593628
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1046712398529053
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.095217227935791
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1006029844284058
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0945173501968384
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1323504447937012
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1281001567840576
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1082134246826172
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.122503638267517
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1143656969070435
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1095802783966064
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0941896438598633
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0971653461456299
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1100536584854126
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1027902364730835
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0998166799545288
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0977116823196411
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.108788251876831
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.114214539527893
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0786575078964233
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0996463298797607
Baseline loss: 2.165649890899658
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0821833610534668
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1342592239379883
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0536620616912842
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1137100458145142
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0595734119415283
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1569150686264038
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0613117218017578
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0965209007263184
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.049174427986145
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1146228313446045
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0997637510299683
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1250135898590088
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0546993017196655
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1042028665542603
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0798367261886597
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1201907396316528
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0725749731063843
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.109058141708374
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.0633835792541504
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.154278039932251
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0637449026107788
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1186463832855225
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.0565046072006226
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0886439085006714
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0477540493011475
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1290128231048584
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.070165991783142
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1007448434829712
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.046871304512024
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1277166604995728
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0823853015899658
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0961260795593262
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.0615360736846924
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1367652416229248
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.0527374744415283
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1104037761688232
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.0523937940597534
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1098579168319702
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0606833696365356
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1283085346221924
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.057618260383606
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1063790321350098
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0472626686096191
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1008189916610718
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.056876540184021
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1179604530334473
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.130118727684021
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.115677833557129
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0525929927825928
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1032909154891968
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.068150281906128
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1054130792617798
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0667082071304321
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0912501811981201
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.0504299402236938
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1280463933944702
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.0728036165237427
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.178254246711731
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0736130475997925
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1000523567199707
Baseline loss: 2.165649890899658
########
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0743296146392822
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1321715116500854
Baseline loss: 2.165649890899658
########
Epoch: 2
Meta Train Loss: 1.0501919984817505
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.121982216835022
Baseline loss: 2.165649890899658
########
Epoch: 3
Meta Train Loss: 1.0571197271347046
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1076523065567017
Baseline loss: 2.165649890899658
########
Epoch: 4
Meta Train Loss: 1.0586637258529663
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0997436046600342
Baseline loss: 2.165649890899658
########
Epoch: 5
Meta Train Loss: 1.05374014377594
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.108595848083496
Baseline loss: 2.165649890899658
########
Epoch: 6
Meta Train Loss: 1.0535597801208496
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.109322190284729
Baseline loss: 2.165649890899658
########
Epoch: 7
Meta Train Loss: 1.0537172555923462
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1111786365509033
Baseline loss: 2.165649890899658
########
Epoch: 8
Meta Train Loss: 1.0527080297470093
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.109344244003296
Baseline loss: 2.165649890899658
########
Epoch: 9
Meta Train Loss: 1.0528759956359863
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1015549898147583
Baseline loss: 2.165649890899658
########
Epoch: 10
Meta Train Loss: 1.0565941333770752
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1165696382522583
Baseline loss: 2.165649890899658
########
Epoch: 11
Meta Train Loss: 1.0627915859222412
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1397191286087036
Baseline loss: 2.165649890899658
########
Epoch: 12
Meta Train Loss: 1.064412236213684
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.093827486038208
Baseline loss: 2.165649890899658
########
Epoch: 13
Meta Train Loss: 1.0559818744659424
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1043540239334106
Baseline loss: 2.165649890899658
########
Epoch: 14
Meta Train Loss: 1.0521318912506104
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1121433973312378
Baseline loss: 2.165649890899658
########
Epoch: 15
Meta Train Loss: 1.0507608652114868
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0953803062438965
Baseline loss: 2.165649890899658
########
Epoch: 16
Meta Train Loss: 1.0526405572891235
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.111222267150879
Baseline loss: 2.165649890899658
########
Epoch: 17
Meta Train Loss: 1.064095139503479
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1598068475723267
Baseline loss: 2.165649890899658
########
Epoch: 18
Meta Train Loss: 1.0512254238128662
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0929356813430786
Baseline loss: 2.165649890899658
########
Epoch: 19
Meta Train Loss: 1.054050326347351
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.101125717163086
Baseline loss: 2.165649890899658
########
Epoch: 20
Meta Train Loss: 1.0512651205062866
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1084672212600708
Baseline loss: 2.165649890899658
########
Epoch: 21
Meta Train Loss: 1.059548020362854
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1009048223495483
Baseline loss: 2.165649890899658
########
Epoch: 22
Meta Train Loss: 1.0585620403289795
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0996185541152954
Baseline loss: 2.165649890899658
########
Epoch: 23
Meta Train Loss: 1.0556787252426147
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1066126823425293
Baseline loss: 2.165649890899658
########
Epoch: 24
Meta Train Loss: 1.0604350566864014
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1025751829147339
Baseline loss: 2.165649890899658
########
Epoch: 25
Meta Train Loss: 1.0535975694656372
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.104678750038147
Baseline loss: 2.165649890899658
########
Epoch: 26
Meta Train Loss: 1.0590401887893677
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1207255125045776
Baseline loss: 2.165649890899658
########
Epoch: 27
Meta Train Loss: 1.0697954893112183
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0945326089859009
Baseline loss: 2.165649890899658
########
Epoch: 28
Meta Train Loss: 1.055637001991272
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1085172891616821
Baseline loss: 2.165649890899658
########
Epoch: 29
Meta Train Loss: 1.0617778301239014
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.1033262014389038
Baseline loss: 2.165649890899658
########
Epoch: 30
Meta Train Loss: 1.0570462942123413
Finetuned loss: 1.0248332023620605
Trained Edgeconv loss: 1.0405535697937012
Untrained Edgeconv loss: 1.0955324172973633
Baseline loss: 2.165649890899658
########
/zhome/2b/7/117471/Thesis/data/processed/metalearning/UBER2015-jan-june-REGION.pkl
Shuffling data...

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 10567597: <compare> in cluster <dcc> Exited

Job <compare> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Tue Oct  5 17:28:00 2021
Job was executed on host(s) <n-62-11-16>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Tue Oct  5 17:28:02 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Tue Oct  5 17:28:02 2021
Terminated at Tue Oct  5 17:43:18 2021
Results reported at Tue Oct  5 17:43:18 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J compare #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate


python /zhome/2b/7/117471/Thesis/src/models/compare_metalearning.py


------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   909.96 sec.
    Max Memory :                                 2624 MB
    Average Memory :                             2557.56 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9664.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   973 sec.
    Turnaround time :                            918 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.10567597> for stderr output of this job.

