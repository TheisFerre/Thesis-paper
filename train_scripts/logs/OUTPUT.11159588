Starting:
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 0.9053429961204529
########
Epoch: 2
Meta Train Loss: 0.7989545464515686
########
Epoch: 3
Meta Train Loss: 1.0711567401885986
########
Epoch: 4
Meta Train Loss: 1.1959737539291382
########
Epoch: 5
Meta Train Loss: 1.0342997312545776
########
Epoch: 6
Meta Train Loss: 1.007209062576294
########
Epoch: 7
Meta Train Loss: 728991360.0
########
Epoch: 8
Meta Train Loss: 1.2502776384353638
########
Epoch: 9
Meta Train Loss: 1.0375064611434937
########
Epoch: 10
Meta Train Loss: 1.162740707397461
########
Epoch: 11
Meta Train Loss: 0.9773425459861755
########
Epoch: 12
Meta Train Loss: 1.169582724571228
########
Epoch: 13
Meta Train Loss: 0.9056872725486755
########
Epoch: 14
Meta Train Loss: 1.0940625667572021
########
Epoch: 15
Meta Train Loss: 137038610432.0
########
Epoch: 16
Meta Train Loss: 0.9366524815559387
########
Epoch: 17
Meta Train Loss: 0.910147488117218
########
Epoch: 18
Meta Train Loss: 1.1001381874084473
########
Epoch: 19
Meta Train Loss: 0.9574586153030396
########
Epoch: 20
Meta Train Loss: 0.9417011141777039
########
Epoch: 21
Meta Train Loss: 0.7176292538642883
########
Epoch: 22
Meta Train Loss: 0.9053499102592468
########
Epoch: 23
Meta Train Loss: 1.2715506553649902
########
Epoch: 24
Meta Train Loss: 1.0198549032211304
########
Epoch: 25
Meta Train Loss: 1.1972001791000366
########
Epoch: 26
Meta Train Loss: 1.2990492582321167
########
Epoch: 27
Meta Train Loss: 1.0626966953277588
########
Epoch: 28
Meta Train Loss: 1.167884349822998
########
Epoch: 29
Meta Train Loss: 1.341927409172058
########
Epoch: 30
Meta Train Loss: 0.9444661140441895
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11159588: <METALEARN> in cluster <dcc> Exited

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Thu Nov 25 10:59:09 2021
Job was executed on host(s) <n-62-20-11>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Thu Nov 25 11:38:57 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Thu Nov 25 11:38:57 2021
Terminated at Thu Nov 25 12:55:47 2021
Results reported at Thu Nov 25 12:55:47 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 04:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/ablation-augmented
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=10
K_SHOT=5
ADAPTATION_STEPS=10
EPOCHS=150
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=citibike-tripdata-GRID,TLC2018-FHV-aug-REGION,citibike2014-tripdata-GRID,GM,yellow-taxi2020-nov-REGION,green,UBER2015-jan-june-GRID,LYFT,TLC2018-FHV-GRID,citibike2014-tripdata-REGION,UBER2015-jan-june-REGION
LOG_DIR=/zhome/2b/7/117471/Thesis/ablation-study/augmented
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10

# citibike-tripdata-GRID,TLC2018-FHV-aug-REGION,citibike2014-tripdata-GRID,GM,yellow-taxi2020-nov-REGION,green,UBER2015-jan-june-GRID,LYFT,TLC2018-FHV-GRID,citibike2014-tripdata-REGION,UBER2015-jan-june-REGION,yellow-taxi2020-nov-GRID

python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --exclude $EXCLUDE --gpu


------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   4567.70 sec.
    Max Memory :                                 3616 MB
    Average Memory :                             3522.95 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               8672.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   4611 sec.
    Turnaround time :                            6998 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.11159588> for stderr output of this job.

