Starting:
Shuffling data...
Shuffling data...
Epoch: 1
Meta Train Loss: 1.0574841499328613
########
Epoch: 2
Meta Train Loss: 0.9496967196464539
########
Epoch: 3
Meta Train Loss: 1.058355689048767
########
Epoch: 4
Meta Train Loss: 0.9057364463806152
########
Epoch: 5
Meta Train Loss: 0.9600553512573242
########
Epoch: 6
Meta Train Loss: 1.320970892906189
########
Epoch: 7
Meta Train Loss: 0.6733897924423218
########
Epoch: 8
Meta Train Loss: 0.7925664782524109
########
Epoch: 9
Meta Train Loss: 0.9907748699188232
########
Epoch: 10
Meta Train Loss: 0.9556511640548706
########
Epoch: 11
Meta Train Loss: 0.878449022769928
########
Epoch: 12
Meta Train Loss: 0.7719511389732361
########
Epoch: 13
Meta Train Loss: 1.4619464874267578
########
Epoch: 14
Meta Train Loss: 0.9864660501480103
########
Epoch: 15
Meta Train Loss: 0.921128511428833
########
Epoch: 16
Meta Train Loss: 0.6186972260475159
########
Epoch: 17
Meta Train Loss: 0.754630446434021
########
Epoch: 18
Meta Train Loss: 1.0349406003952026
########
Epoch: 19
Meta Train Loss: 0.7964639067649841
########
Epoch: 20
Meta Train Loss: 1.1567881107330322
########
Epoch: 21
Meta Train Loss: 1.182643175125122
########
Epoch: 22
Meta Train Loss: 1.3151578903198242
########
Epoch: 23
Meta Train Loss: 0.9387267827987671
########
Epoch: 24
Meta Train Loss: 0.7535731792449951
########
Epoch: 25
Meta Train Loss: 0.9701869487762451
########
Epoch: 26
Meta Train Loss: 1.157099962234497
########
Epoch: 27
Meta Train Loss: 1.1357485055923462
########
Epoch: 28
Meta Train Loss: 0.949431300163269
########
Epoch: 29
Meta Train Loss: 1.404462218284607
########
Epoch: 30
Meta Train Loss: 0.9606533646583557
########
Epoch: 31
Meta Train Loss: 0.9538793563842773
########
Epoch: 32
Meta Train Loss: 0.9709464311599731
########
Epoch: 33
Meta Train Loss: 1.3150814771652222
########
Epoch: 34
Meta Train Loss: 0.6120317578315735
########
Epoch: 35
Meta Train Loss: 1.794899582862854
########
Epoch: 36
Meta Train Loss: 0.562149167060852
########
Epoch: 37
Meta Train Loss: 1.4534053802490234
########
Epoch: 38
Meta Train Loss: 1.0278346538543701
########
Epoch: 39
Meta Train Loss: 0.8712811470031738
########
Epoch: 40
Meta Train Loss: 0.8531180620193481
########
Epoch: 41
Meta Train Loss: 0.9591530561447144
########
Epoch: 42
Meta Train Loss: 1.0352015495300293
########
Epoch: 43
Meta Train Loss: 1.167476773262024
########
Epoch: 44
Meta Train Loss: 1.1111552715301514
########
Epoch: 45
Meta Train Loss: 0.6802040934562683
########
Epoch: 46
Meta Train Loss: 0.8853156566619873
########
Epoch: 47
Meta Train Loss: 0.6872533559799194
########
Epoch: 48
Meta Train Loss: 0.9338275194168091
########
Epoch: 49
Meta Train Loss: 0.8926143646240234
########
Epoch: 50
Meta Train Loss: 0.6780035495758057
########
Epoch: 51
Meta Train Loss: 0.8675463199615479
########
Epoch: 52
Meta Train Loss: 0.8718193769454956
########
Epoch: 53
Meta Train Loss: 0.8789211511611938
########
Epoch: 54
Meta Train Loss: 1.0167691707611084
########
Epoch: 55
Meta Train Loss: 0.8545814752578735
########
Epoch: 56
Meta Train Loss: 0.7321667671203613
########
Epoch: 57
Meta Train Loss: 0.8297367095947266
########
Epoch: 58
Meta Train Loss: 0.9165085554122925
########
Epoch: 59
Meta Train Loss: 0.7108726501464844
########
Epoch: 60
Meta Train Loss: 0.9514999985694885
########
Epoch: 61
Meta Train Loss: 0.5565705299377441
########
Epoch: 62
Meta Train Loss: 0.5584355592727661
########
Epoch: 63
Meta Train Loss: 0.8513860106468201
########
Epoch: 64
Meta Train Loss: 0.9220567941665649
########
Epoch: 65
Meta Train Loss: 0.672551691532135
########
Epoch: 66
Meta Train Loss: 0.48172008991241455
########
Epoch: 67
Meta Train Loss: 0.5324715375900269
########
Epoch: 68
Meta Train Loss: 0.7911964654922485
########
Epoch: 69
Meta Train Loss: 0.9564377069473267
########
Epoch: 70
Meta Train Loss: 1.3312785625457764
########
Epoch: 71
Meta Train Loss: 0.8029794096946716
########
Epoch: 72
Meta Train Loss: 0.7758462429046631
########
Epoch: 73
Meta Train Loss: 0.630566418170929
########
Epoch: 74
Meta Train Loss: 0.554100513458252
########
Epoch: 75
Meta Train Loss: 0.5520089864730835
########
Epoch: 76
Meta Train Loss: 0.6985840797424316
########
Epoch: 77
Meta Train Loss: 0.6804858446121216
########
Epoch: 78
Meta Train Loss: 0.6892226338386536
########
Epoch: 79
Meta Train Loss: 0.662340521812439
########
Epoch: 80
Meta Train Loss: 0.9112060070037842
########
Epoch: 81
Meta Train Loss: 0.668829083442688
########
Epoch: 82
Meta Train Loss: 0.7049076557159424
########
Epoch: 83
Meta Train Loss: 0.7517584562301636
########
Epoch: 84
Meta Train Loss: 1.0606575012207031
########
Epoch: 85
Meta Train Loss: 0.6397263407707214
########
Epoch: 86
Meta Train Loss: 0.684685230255127
########
Epoch: 87
Meta Train Loss: 1.2009822130203247
########
Epoch: 88
Meta Train Loss: 1.207881212234497
########
Epoch: 89
Meta Train Loss: 0.8729807138442993
########
Epoch: 90
Meta Train Loss: 0.7975529432296753
########
Epoch: 91
Meta Train Loss: 0.8491213321685791
########
Epoch: 92
Meta Train Loss: 0.9379660487174988
########
Epoch: 93
Meta Train Loss: 0.8230503797531128
########
Epoch: 94
Meta Train Loss: 0.7663480043411255
########
Epoch: 95
Meta Train Loss: 0.5956811904907227
########
Epoch: 96
Meta Train Loss: 1.037705659866333
########
Epoch: 97
Meta Train Loss: 0.9904108047485352
########
Epoch: 98
Meta Train Loss: 0.7645123600959778
########
Epoch: 99
Meta Train Loss: 0.7756429314613342
########
Epoch: 100
Meta Train Loss: 0.550879716873169
########
Epoch: 101
Meta Train Loss: 1.077435851097107
########
Epoch: 102
Meta Train Loss: 0.7769417762756348
########
Epoch: 103
Meta Train Loss: 1.0027284622192383
########
Epoch: 104
Meta Train Loss: 0.6534824371337891
########
Epoch: 105
Meta Train Loss: 0.7963318228721619
########
Epoch: 106
Meta Train Loss: 0.7457020282745361
########
Epoch: 107
Meta Train Loss: 0.6571098566055298
########
Epoch: 108
Meta Train Loss: 0.6288290023803711
########
Epoch: 109
Meta Train Loss: 1.368098497390747
########
Epoch: 110
Meta Train Loss: 0.7644424438476562
########
Epoch: 111
Meta Train Loss: 0.5644146800041199
########
Epoch: 112
Meta Train Loss: 0.6316527128219604
########
Epoch: 113
Meta Train Loss: 0.4786021113395691
########
Epoch: 114
Meta Train Loss: 0.8647642135620117
########
Epoch: 115
Meta Train Loss: 2.1629395484924316
########
Epoch: 116
Meta Train Loss: 0.5585432052612305
########
Epoch: 117
Meta Train Loss: 0.5567874908447266
########
Epoch: 118
Meta Train Loss: 0.9793131351470947
########
Epoch: 119
Meta Train Loss: 0.6461319327354431
########
Epoch: 120
Meta Train Loss: 0.7075046896934509
########
Epoch: 121
Meta Train Loss: 0.8193808794021606
########
Epoch: 122
Meta Train Loss: 0.593460202217102
########
Epoch: 123
Meta Train Loss: 0.8237754702568054
########
Epoch: 124
Meta Train Loss: 0.7575011253356934
########
Epoch: 125
Meta Train Loss: 0.5324833393096924
########
Epoch: 126
Meta Train Loss: 1.2619036436080933
########
Epoch: 127
Meta Train Loss: 0.7544898390769958
########
Epoch: 128
Meta Train Loss: 0.6620903015136719
########
Epoch: 129
Meta Train Loss: 0.48890256881713867
########
Epoch: 130
Meta Train Loss: 0.766585111618042
########
Epoch: 131
Meta Train Loss: 0.5077741146087646
########
Epoch: 132
Meta Train Loss: 0.5543991327285767
########
Epoch: 133
Meta Train Loss: 1.565866470336914
########
Epoch: 134
Meta Train Loss: 0.9341181516647339
########
Epoch: 135
Meta Train Loss: 0.6281898021697998
########
Epoch: 136
Meta Train Loss: 0.7862198948860168
########
Epoch: 137
Meta Train Loss: 0.48524564504623413
########
Epoch: 138
Meta Train Loss: 1.0834391117095947
########
Epoch: 139
Meta Train Loss: 0.6543169617652893
########
Epoch: 140
Meta Train Loss: 0.9519524574279785
########
Epoch: 141
Meta Train Loss: 0.7269703149795532
########
Epoch: 142
Meta Train Loss: 0.8091530799865723
########
Epoch: 143
Meta Train Loss: 0.8306331038475037
########
Epoch: 144
Meta Train Loss: 0.4067397117614746
########
Epoch: 145
Meta Train Loss: 0.7100353240966797
########
Epoch: 146
Meta Train Loss: 0.9438302516937256
########
Epoch: 147
Meta Train Loss: 0.7956237196922302
########
Epoch: 148
Meta Train Loss: 0.5817265510559082
########
Epoch: 149
Meta Train Loss: 0.8518668413162231
########
Epoch: 150
Meta Train Loss: 0.6535295844078064
########
Epoch: 151
Meta Train Loss: 0.7998014688491821
########
Epoch: 152
Meta Train Loss: 0.8909013867378235
########
Epoch: 153
Meta Train Loss: 0.43839478492736816
########
Epoch: 154
Meta Train Loss: 0.6136325001716614
########
Epoch: 155
Meta Train Loss: 0.45578697323799133
########
Epoch: 156
Meta Train Loss: 0.7876598834991455
########
Epoch: 157
Meta Train Loss: 0.6743230819702148
########
Epoch: 158
Meta Train Loss: 0.5121713876724243
########
Epoch: 159
Meta Train Loss: 0.7835400104522705
########
Epoch: 160
Meta Train Loss: 0.5958350896835327
########
Epoch: 161
Meta Train Loss: 0.40183937549591064
########
Epoch: 162
Meta Train Loss: 0.655577540397644
########
Epoch: 163
Meta Train Loss: 0.457670658826828
########
Epoch: 164
Meta Train Loss: 1.3147724866867065
########
Epoch: 165
Meta Train Loss: 0.49113965034484863
########
Epoch: 166
Meta Train Loss: 0.8966555595397949
########
Epoch: 167
Meta Train Loss: 0.7016981840133667
########
Epoch: 168
Meta Train Loss: 0.5620838403701782
########
Epoch: 169
Meta Train Loss: 1.1017038822174072
########
Epoch: 170
Meta Train Loss: 0.6573830842971802
########
Epoch: 171
Meta Train Loss: 0.5466461777687073
########
Epoch: 172
Meta Train Loss: 0.9565825462341309
########
Epoch: 173
Meta Train Loss: 0.9333347082138062
########
Epoch: 174
Meta Train Loss: 0.6546333432197571
########
Epoch: 175
Meta Train Loss: 0.6851704120635986
########
Epoch: 176
Meta Train Loss: 1.2650905847549438
########
Epoch: 177
Meta Train Loss: 0.8335949182510376
########
Epoch: 178
Meta Train Loss: 0.556586742401123
########
Epoch: 179
Meta Train Loss: 0.7151272296905518
########
Epoch: 180
Meta Train Loss: 0.6417776346206665
########
Epoch: 181
Meta Train Loss: 0.5946246981620789
########
Epoch: 182
Meta Train Loss: 0.7872586250305176
########
Epoch: 183
Meta Train Loss: 0.9393860697746277
########
Epoch: 184
Meta Train Loss: 0.7471375465393066
########
Epoch: 185
Meta Train Loss: 0.8084930181503296
########
Epoch: 186
Meta Train Loss: 0.5922796726226807
########
Epoch: 187
Meta Train Loss: 0.7424523830413818
########
Epoch: 188
Meta Train Loss: 0.6488091945648193
########
Epoch: 189
Meta Train Loss: 0.6771314740180969
########
Epoch: 190
Meta Train Loss: 0.739845871925354
########
Epoch: 191
Meta Train Loss: 0.7900989055633545
########
Epoch: 192
Meta Train Loss: 0.6049442291259766
########
Epoch: 193
Meta Train Loss: 1.007414698600769
########
Epoch: 194
Meta Train Loss: 2.068734645843506
########
Epoch: 195
Meta Train Loss: 0.532918393611908
########
Epoch: 196
Meta Train Loss: 0.8441463708877563
########
Epoch: 197
Meta Train Loss: 0.5911776423454285
########
Epoch: 198
Meta Train Loss: 0.6358944177627563
########
Epoch: 199
Meta Train Loss: 1.0532289743423462
########
Epoch: 200
Meta Train Loss: 0.8815798163414001
########
Epoch: 201
Meta Train Loss: 0.8703022003173828
########
Epoch: 202
Meta Train Loss: 1.1264302730560303
########
Epoch: 203
Meta Train Loss: 0.7747006416320801
########
Epoch: 204
Meta Train Loss: 0.7565932273864746
########
Epoch: 205
Meta Train Loss: 1.0692335367202759
########
Epoch: 206
Meta Train Loss: 0.6561473608016968
########
Epoch: 207
Meta Train Loss: 0.7658950090408325
########
Epoch: 208
Meta Train Loss: 1.9512251615524292
########
Epoch: 209
Meta Train Loss: 0.511642336845398
########
Epoch: 210
Meta Train Loss: 0.8291008472442627
########
Epoch: 211
Meta Train Loss: 0.7821420431137085
########
Epoch: 212
Meta Train Loss: 0.9439001083374023
########
Epoch: 213
Meta Train Loss: 0.9119596481323242
########
Epoch: 214
Meta Train Loss: 0.6653055548667908
########
Epoch: 215
Meta Train Loss: 0.9217394590377808
########
Epoch: 216
Meta Train Loss: 0.8905419111251831
########
Epoch: 217
Meta Train Loss: 0.7207755446434021
########
Epoch: 218
Meta Train Loss: 0.7002434730529785
########
Epoch: 219
Meta Train Loss: 0.4380428194999695
########
Epoch: 220
Meta Train Loss: 0.5552372932434082
########
Epoch: 221
Meta Train Loss: 0.5299088954925537
########
Epoch: 222
Meta Train Loss: 0.7472107410430908
########
Epoch: 223
Meta Train Loss: 0.5100431442260742
########
Epoch: 224
Meta Train Loss: 0.6081523895263672
########
Epoch: 225
Meta Train Loss: 0.757719099521637
########
Epoch: 226
Meta Train Loss: 0.7392318248748779
########
Epoch: 227
Meta Train Loss: 0.6574046611785889
########
Epoch: 228
Meta Train Loss: 1.029547095298767
########
Epoch: 229
Meta Train Loss: 0.680640459060669
########
Epoch: 230
Meta Train Loss: 0.7619003653526306
########
Epoch: 231
Meta Train Loss: 0.5944533348083496
########
Epoch: 232
Meta Train Loss: 0.7209600210189819
########
Epoch: 233
Meta Train Loss: 0.6040353178977966
########
Epoch: 234
Meta Train Loss: 0.7829747200012207
########
Epoch: 235
Meta Train Loss: 1.0016013383865356
########
Epoch: 236
Meta Train Loss: 0.8192452192306519
########
Epoch: 237
Meta Train Loss: 0.4815303385257721
########
Epoch: 238
Meta Train Loss: 0.6346358060836792
########
Epoch: 239
Meta Train Loss: 0.7563080787658691
########
Epoch: 240
Meta Train Loss: 0.7629213333129883
########
Epoch: 241
Meta Train Loss: 0.6323195099830627
########
Epoch: 242
Meta Train Loss: 1.04995596408844
########
Epoch: 243
Meta Train Loss: 0.7329012155532837
########
Epoch: 244
Meta Train Loss: 0.7092658281326294
########
Epoch: 245
Meta Train Loss: 0.9839164018630981
########
Epoch: 246
Meta Train Loss: 0.3554381728172302
########
Epoch: 247
Meta Train Loss: 0.7665561437606812
########
Epoch: 248
Meta Train Loss: 0.5621634721755981
########
Epoch: 249
Meta Train Loss: 0.9019360542297363
########
Epoch: 250
Meta Train Loss: 0.7071471214294434
########

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 11057552: <METALEARN> in cluster <dcc> Done

Job <METALEARN> was submitted from host <gbarlogin1> by user <tfehjo> in cluster <dcc> at Wed Nov 17 16:00:25 2021
Job was executed on host(s) <n-62-11-13>, in queue <gpuv100>, as user <tfehjo> in cluster <dcc> at Wed Nov 17 17:31:21 2021
</zhome/2b/7/117471> was used as the home directory.
</zhome/2b/7/117471/Thesis/train_scripts> was used as the working directory.
Started at Wed Nov 17 17:31:21 2021
Terminated at Wed Nov 17 17:55:09 2021
Results reported at Wed Nov 17 17:55:09 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J METALEARN #The name the job will get
#BSUB -q gpuv100 #The queue the job will be committed to, here the GPU enabled queue
#BSUB -gpu "num=1:mode=exclusive_process" #How the job will be run on the VM, here I request 1 GPU with exclusive access i.e. only my c #BSUB -n 1 How many CPU cores my job request
#BSUB -W 24:00 #The maximum runtime my job have note that the queuing might enable shorter jobs earlier due to scheduling.
#BSUB -R "span[hosts=1]" #How many nodes the job requests
#BSUB -R "rusage[mem=12GB]" #How much RAM the job should have access to
#BSUB -R "select[gpu32gb]" #For requesting the extra big GPU w. 32GB of VRAM
#BSUB -o logs/OUTPUT.%J #Log file
#BSUB -e logs/ERROR.%J #Error log file
echo "Starting:"

cd ~/Thesis/metalearning
#cd /Users/theisferre/Documents/SPECIALE/Thesis/src/models

source ~/Thesis/venv-thesis/bin/activate

DATA_DIR=/zhome/2b/7/117471/Thesis/data/processed/aglation-non_augmented
TRAIN_SIZE=0.9
BATCH_TASK_SIZE=10
K_SHOT=5
ADAPTATION_STEPS=10
EPOCHS=250
ADAPT_LR=0.05
META_LR=0.001
EXCLUDE=citibike-tripdata,citibike2014,GM,green,LYFT,TLC,UBER
LOG_DIR=/zhome/2b/7/117471/Thesis/ablation-study/non-augmented
HIDDEN_SIZE=46
DROPOUT_P=0.2
NODE_OUT_FEATURES=10

# citibike-tripdata,citibike2014,GM,green,LYFT,TLC,UBER,yellow

python /zhome/2b/7/117471/Thesis/src/models/train_meta.py --data_dir $DATA_DIR --train_size $TRAIN_SIZE --batch_task_size $BATCH_TASK_SIZE \
--k_shot $K_SHOT --adaptation_steps $ADAPTATION_STEPS --epochs $EPOCHS --adapt_lr $ADAPT_LR --meta_lr $META_LR --log_dir $LOG_DIR \
--hidden_size $HIDDEN_SIZE --dropout_p $DROPOUT_P --node_out_features $NODE_OUT_FEATURES --exclude $EXCLUDE --gpu


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1422.24 sec.
    Max Memory :                                 2497 MB
    Average Memory :                             2496.79 MB
    Total Requested Memory :                     12288.00 MB
    Delta Memory :                               9791.00 MB
    Max Swap :                                   5 MB
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   1428 sec.
    Turnaround time :                            6884 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ERROR.11057552> for stderr output of this job.

